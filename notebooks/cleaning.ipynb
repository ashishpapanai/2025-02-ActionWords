{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c76810f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4089fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa0d096",
   "metadata": {},
   "source": [
    "## Data loading and extracting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1a96dc",
   "metadata": {},
   "source": [
    "Loading .dta and mapping files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4104e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapping = pd.read_csv(\"../data/common_question_mapping.csv\")\n",
    "with pd.io.stata.StataReader(\"../data/GESIS/2002.dta\", convert_categoricals=True) as rdr:\n",
    "    cols = [c for c in rdr.variable_labels().keys() if c not in [\"v241\",\"v247\"]]\n",
    "    dta_2002 = rdr.read(columns=cols)\n",
    "with pd.io.stata.StataReader(\"../data/GESIS/2012.dta\", convert_categoricals=True) as rdr:\n",
    "    cols = [c for c in rdr.variable_labels().keys() if c not in {\"ISCO88\", \"SPISCO88\"}]\n",
    "    dta_2012 = rdr.read(columns=cols)\n",
    "\n",
    "\n",
    "dta_2022 = pd.read_stata(\"../data/GESIS/2022.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efba0f4",
   "metadata": {},
   "source": [
    "Extracting relevant columns from every survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13ec9927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2002: (46638, 47)\n",
      "df_2012: (61754, 47)\n",
      "df_2022: (45762, 47)\n"
     ]
    }
   ],
   "source": [
    "df_2002 = dta_2002.copy()\n",
    "df_2012 = dta_2012.copy()\n",
    "df_2022 = dta_2022.copy()\n",
    "\n",
    "all_common_vars = df_mapping['COMMON_VAR'].dropna().unique()\n",
    "\n",
    "cols_2002 = [col for col in df_mapping['var_02'].dropna() if col in df_2002.columns]\n",
    "df_2002_subset = df_2002[cols_2002].copy()\n",
    "rename_map_2002 = dict(zip(\n",
    "    df_mapping['var_02'].dropna(),\n",
    "    df_mapping.loc[df_mapping['var_02'].notna(), 'COMMON_VAR']\n",
    "))\n",
    "df_2002_subset = df_2002_subset.rename(columns=rename_map_2002)\n",
    "\n",
    "cols_2012 = [col for col in df_mapping['var_12'].dropna() if col in df_2012.columns]\n",
    "df_2012_subset = df_2012[cols_2012].copy()\n",
    "rename_map_2012 = dict(zip(\n",
    "    df_mapping['var_12'].dropna(),\n",
    "    df_mapping.loc[df_mapping['var_12'].notna(), 'COMMON_VAR']\n",
    "))\n",
    "df_2012_subset = df_2012_subset.rename(columns=rename_map_2012)\n",
    "\n",
    "cols_2022 = [col for col in df_mapping['var_22'].dropna() if col in df_2022.columns]\n",
    "df_2022_subset = df_2022[cols_2022].copy()\n",
    "rename_map_2022 = dict(zip(\n",
    "    df_mapping['var_22'].dropna(),\n",
    "    df_mapping.loc[df_mapping['var_22'].notna(), 'COMMON_VAR']\n",
    "))\n",
    "df_2022_subset = df_2022_subset.rename(columns=rename_map_2022)\n",
    "\n",
    "df_2002 = pd.DataFrame(index=df_2002_subset.index)\n",
    "df_2012 = pd.DataFrame(index=df_2012_subset.index)\n",
    "df_2022 = pd.DataFrame(index=df_2022_subset.index)\n",
    "\n",
    "for common_var in all_common_vars:\n",
    "    # For 2002\n",
    "    if common_var in df_2002_subset.columns:\n",
    "        df_2002[common_var] = df_2002_subset[common_var]\n",
    "    else:\n",
    "        df_2002[common_var] = None\n",
    "    \n",
    "    # For 2012\n",
    "    if common_var in df_2012_subset.columns:\n",
    "        df_2012[common_var] = df_2012_subset[common_var]\n",
    "    else:\n",
    "        df_2012[common_var] = None\n",
    "    \n",
    "    # For 2022\n",
    "    if common_var in df_2022_subset.columns:\n",
    "        df_2022[common_var] = df_2022_subset[common_var]\n",
    "    else:\n",
    "        df_2022[common_var] = None\n",
    "\n",
    "print(f\"df_2002: {df_2002.shape}\")\n",
    "print(f\"df_2012: {df_2012.shape}\")\n",
    "print(f\"df_2022: {df_2022.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f8a26",
   "metadata": {},
   "source": [
    "## Equality Score data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7379f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_add_2002 = ['v4', 'v5', 'v6', 'v7', 'v8', 'v11']\n",
    "cols_to_add_2012 = ['V5', 'V6', 'V7', 'V8', 'V9', 'V11']\n",
    "cols_to_add_2022 = ['v1', 'v2', 'v3', 'v4', 'v5', 'v6']\n",
    "\n",
    "for col in cols_to_add_2002:\n",
    "    if col in dta_2002.columns:\n",
    "        df_2002[col] = dta_2002[col]\n",
    "\n",
    "for col in cols_to_add_2012:\n",
    "    if col in dta_2012.columns:\n",
    "        df_2012[col] = dta_2012[col]\n",
    "\n",
    "for col in cols_to_add_2022:\n",
    "    if col in dta_2022.columns:\n",
    "        df_2022[col] = dta_2022[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57800a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "likert_map = {\n",
    "    \"Strongly agree\": 5,\n",
    "    \"Agree\": 4,\n",
    "    \"Neither agree nor disagree\": 3,\n",
    "    \"Disagree\": 2,\n",
    "    \"Strongly disagree\": 1,\n",
    "    \"1. Strongly agree\": 5,\n",
    "    \"2. Agree\": 4,\n",
    "    \"3. Neither agree nor disagree\": 3,\n",
    "    \"4. Disagree\": 2,\n",
    "    \"5. Strongly disagree\": 1,\n",
    "}\n",
    "\n",
    "def add_numeric_and_egal_columns(df, cols, reverse_cols, invalid_values=None,\n",
    "                                 num_suffix=\"_num\", egal_suffix=\"_egal\"):\n",
    "    \"\"\"\n",
    "    Keeps original columns intact.\n",
    "    Adds:\n",
    "      - <col>_num  : numeric 1..5 (NaN for invalid/missing)\n",
    "      - <col>_egal : egalitarian-coded where higher = more egalitarian\n",
    "                    (reverse-coded if col in reverse_cols)\n",
    "    \"\"\"\n",
    "    if invalid_values is None:\n",
    "        invalid_values = []\n",
    "\n",
    "    for col in cols:\n",
    "        num_col = f\"{col}{num_suffix}\"\n",
    "        df[num_col] = df[col].replace(invalid_values, np.nan).map(likert_map)\n",
    "\n",
    "        egal_col = f\"{col}{egal_suffix}\"\n",
    "        if col in reverse_cols:\n",
    "            df[egal_col] = df[num_col].apply(lambda x: (6 - x) if pd.notnull(x) else np.nan)\n",
    "        else:\n",
    "            df[egal_col] = df[num_col]\n",
    "        df.drop(num_col, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fa440f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_2002 = ['v4', 'v5', 'v6', 'v7', 'v8', 'v11']\n",
    "reverse_2002 = ['v5', 'v6', 'v7', 'v8', 'v11']\n",
    "\n",
    "cols_2012 = ['V5', 'V6', 'V7', 'V8', 'V9', 'V11']\n",
    "reverse_2012 = ['V6', 'V7', 'V8', 'V9', 'V11']\n",
    "\n",
    "cols_2022 = ['v1', 'v2', 'v3', 'v4', 'v5', 'v6']\n",
    "reverse_2022 = ['v2', 'v3', 'v4', 'v5', 'v6']\n",
    "\n",
    "df_2002 = add_numeric_and_egal_columns(\n",
    "    df_2002,\n",
    "    cols=cols_2002,\n",
    "    reverse_cols=reverse_2002,\n",
    "    invalid_values=[],\n",
    ")\n",
    "df_2012 = add_numeric_and_egal_columns(\n",
    "    df_2012,\n",
    "    cols=cols_2012,\n",
    "    reverse_cols=reverse_2012,\n",
    "    invalid_values=[],\n",
    ")\n",
    "df_2022 = add_numeric_and_egal_columns(\n",
    "    df_2022,\n",
    "    cols=cols_2022,\n",
    "    reverse_cols=reverse_2022,\n",
    "    invalid_values=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb896f",
   "metadata": {},
   "source": [
    "## Cleaning and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e9346",
   "metadata": {},
   "source": [
    "### `urban_rural`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbedbd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "URBAN_RURAL_ORDER = [\"Urban\", \"Suburban\", \"Town\", \"Rural\"]\n",
    "\n",
    "def clean_urban_rural(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "\n",
    "    s = str(val).strip().lower()\n",
    "\n",
    "    if s.startswith(\"-\"):\n",
    "        return None\n",
    "    if any(k in s for k in [\"no answer\", \"don't know\", \"dont know\", \"refused\", \"not available\", \"nap\"]):\n",
    "        return None\n",
    "    if \"other\" in s:\n",
    "        return None\n",
    "    if (\"town\" in s or \"small city\" in s) and ('suburb' not in s):\n",
    "        return \"Town\"\n",
    "    if \"suburb\" in s or \"outskirts\" in s:\n",
    "        return \"Suburban\"\n",
    "    if \"big city\" in s or \"large city\" in s or re.fullmatch(r\"a big city\", s):\n",
    "        return \"Urban\"\n",
    "    if \"urban\" in s:\n",
    "        return \"Urban\"\n",
    "    if any(k in s for k in [\"country village\", \"village\", \"farm\", \"home in the country\", \"countryside\", \"country\"]):\n",
    "        return \"Rural\"\n",
    "\n",
    "    return None\n",
    "\n",
    "df_2002['urban_rural'] = df_2002['urban_rural'].apply(clean_urban_rural)\n",
    "df_2012['urban_rural'] = df_2012['urban_rural'].apply(clean_urban_rural)\n",
    "df_2022['urban_rural'] = df_2022['urban_rural'].apply(clean_urban_rural)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41332154",
   "metadata": {},
   "source": [
    "### `spouse_work_status` and `work_status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fc49e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "UNIFORM_ORDER = [\n",
    "    \"Paid work\",\n",
    "    \"Unemployed\",\n",
    "    \"Education\",\n",
    "    \"Apprentice/Trainee\",\n",
    "    \"Sick/Disabled\",\n",
    "    \"Retired\",\n",
    "    \"Domestic work\",\n",
    "    \"Help family member\",\n",
    "    \"Military/Community service\",\n",
    "    \"Other\",\n",
    "    \"DK/No answer\",\n",
    "    \"NAP\",\n",
    "]\n",
    "\n",
    "cat_type = CategoricalDtype(categories=UNIFORM_ORDER, ordered=True)\n",
    "\n",
    "RE_NEGCODE = re.compile(r\"^\\s*-\\d+\\s*[\\.\\:]\")\n",
    "RE_NAP     = re.compile(r\"\\bnap\\b|\\bnot applicable\\b\", re.I)\n",
    "RE_DKNA    = re.compile(r\"don't know|dont know|no answer|refused|not available\", re.I)\n",
    "\n",
    "RE_UNEMP   = re.compile(r\"\\bunemploy(ed|ment)?\\b\", re.I)\n",
    "RE_PAID    = re.compile(\n",
    "    r\"\\bin paid work\\b|\\bemployed\\b|\\bself[-\\s]?employ(ed|ment)?\\b|\\bfull[-\\s]?time\\b|\\bpart[-\\s]?time\\b|\\bf\\-t\\b|\\bp\\-t\\b|\\bmain job\\b\",\n",
    "    re.I\n",
    ")\n",
    "RE_HELPFAM = re.compile(r\"help(ing)?\\s+family\", re.I)\n",
    "RE_EDU     = re.compile(r\"\\bin education\\b|\\bstud(ent|t)?\\b|\\bschool\\b|\\beduc(at|ation)\\b|\\bvocat\", re.I)\n",
    "RE_APPR    = re.compile(r\"\\bapprentice\\b|\\btrainee\\b\", re.I)\n",
    "RE_SICK    = re.compile(r\"permanently sick|\\bdisabled\\b\", re.I)\n",
    "RE_RET     = re.compile(r\"\\bretired\\b\", re.I)\n",
    "RE_DOM     = re.compile(r\"\\bdomestic work\\b|\\bhousewife\\b|\\bhome duties\\b\", re.I)\n",
    "RE_MIL     = re.compile(r\"military service|community service|compulsory military\", re.I)\n",
    "RE_OTHER   = re.compile(r\"\\bother\\b|\\both\\b|not in (the )?labou?r force\", re.I)\n",
    "\n",
    "def _std_status(x) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"DK/No answer\"\n",
    "\n",
    "    s = str(x).strip()\n",
    "\n",
    "    if RE_NEGCODE.match(s):\n",
    "        if RE_NAP.search(s):\n",
    "            return \"NAP\"\n",
    "        return \"DK/No answer\"\n",
    "\n",
    "    s_l = s.lower()\n",
    "\n",
    "    if RE_NAP.search(s_l):\n",
    "        return \"NAP\"\n",
    "    if RE_DKNA.search(s_l):\n",
    "        return \"DK/No answer\"\n",
    "    if RE_UNEMP.search(s_l):\n",
    "        return \"Unemployed\"\n",
    "    if RE_HELPFAM.search(s_l):\n",
    "        return \"Help family member\"\n",
    "    if RE_EDU.search(s_l):\n",
    "        return \"Education\"\n",
    "    if RE_APPR.search(s_l):\n",
    "        return \"Apprentice/Trainee\"\n",
    "    if RE_SICK.search(s_l):\n",
    "        return \"Sick/Disabled\"\n",
    "    if RE_RET.search(s_l):\n",
    "        return \"Retired\"\n",
    "    if RE_DOM.search(s_l):\n",
    "        return \"Domestic work\"\n",
    "    if RE_MIL.search(s_l):\n",
    "        return \"Military/Community service\"\n",
    "    if RE_PAID.search(s_l):\n",
    "        return \"Paid work\"\n",
    "    if RE_OTHER.search(s_l):\n",
    "        return \"Other\"\n",
    "\n",
    "    return \"Other\"\n",
    "\n",
    "for _df in [df_2002, df_2012, df_2022]:\n",
    "    _df[\"work_status_std\"] = _df[\"work_status\"].map(_std_status)\n",
    "    _df[\"spouse_work_status_std\"] = _df[\"spouse_work_status\"].map(_std_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05efd856",
   "metadata": {},
   "source": [
    "### `sex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca062265",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"1. Male\": \"Male\",\n",
    "           \"2. Female\": \"Female\",\n",
    "           \"Male\": \"Male\",\n",
    "           \"Female\":\"Female\",\n",
    "           \"No answer\":np.nan,\n",
    "           '-9. No answer':np.nan}\n",
    "\n",
    "df_2002[\"sex\"] = df_2002[\"sex\"].map(mapping).astype(str)\n",
    "df_2012[\"sex\"] = df_2012[\"sex\"].map(mapping).astype(str)\n",
    "df_2022[\"sex\"] = df_2022[\"sex\"].map(mapping).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f6e148",
   "metadata": {},
   "source": [
    "### `code_income_control`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "275229bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_for_income_control_2002(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    elif x == 'I manage all the money':\n",
    "        return \"Financial control is with the respondent\"\n",
    "    elif x == \"Spouse,partner manages money\":\n",
    "        return \"Financial control is with the partner\"\n",
    "    elif x in ['We pool all the money', 'We pool some money']:\n",
    "        return \"Financial control is shared\"\n",
    "    elif x == 'Each keep own money separate':\n",
    "        return \"Financial control is separate\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def code_for_income_control_2012(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    elif x == 'I manage all and give partner his share':\n",
    "        return \"Financial control is with the respondent\"\n",
    "    elif x == 'Partner manages all and gives me my share':\n",
    "        return \"Financial control is with the partner\"\n",
    "    elif x in ['We pool all money, each take out', 'We pool some money, rest separate']:\n",
    "        return \"Financial control is shared\"\n",
    "    elif x == 'We each keep own money separate':\n",
    "        return \"Financial control is separate\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def code_for_income_control_2022(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    elif x == '1. I manage all and give partner his share':\n",
    "        return \"Financial control is with the respondent\"\n",
    "    elif x == '2. Partner manages all and gives me my share':\n",
    "        return \"Financial control is with the partner\"\n",
    "    elif x in ['3. We pool all money, each take out', '4. We pool some money, rest separate']:\n",
    "        return \"Financial control is shared\"\n",
    "    elif x == '5. We each keep own money separate':\n",
    "        return \"Financial control is separate\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df_2002['code_income_control'] = df_2002['code_income_control'].apply(code_for_income_control_2002)\n",
    "df_2012['code_income_control'] = df_2012['code_income_control'].apply(code_for_income_control_2012)\n",
    "df_2022['code_income_control'] = df_2022['code_income_control'].apply(code_for_income_control_2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902262e8",
   "metadata": {},
   "source": [
    "### `code_for_higher_income`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b4b0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_for_higher_income_2012(x):\n",
    "    if x == 'NAP, no partner (3 (AT,BE,CH,CL,ES,IN,IS,KR,NL,NO,PL,SK,US:2,3;AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)':\n",
    "        return None\n",
    "    elif x in [\"I have a much higher income\", \"I have a higher income\t\"]:\n",
    "        return \"Respondent has higher income\"\n",
    "    elif x in ['My spouse/ partner has a higher income', 'My spouse/ partner has a much higher income']:\n",
    "        return \"Partner has higher income\"\n",
    "    elif x == \"I have no income\":\n",
    "        return \"Respondent has no income\"\n",
    "    elif x == 'My spouse/ partner has no income':\n",
    "        return \"Partner has no income\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def code_for_higher_income_2002(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    elif x in [\"I have much higher income\", \"I have a higher income\"]:\n",
    "        return \"Respondent has higher income\"\n",
    "    elif x in [\"Spouse has higher income\", \"Spouse has much higher income\"]:\n",
    "        return \"Partner has higher income\"\n",
    "    elif x == \"I have no income\":\n",
    "        return \"Respondent has no income\"\n",
    "    elif x == \"Spouse has no income\":\n",
    "        return \"Partner has no income\"\n",
    "    elif x == \"We have about the same income\":\n",
    "        return \"Same income\"\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "## Not available for 2022\n",
    "\n",
    "df_2002['code_higher_income'] = df_2002['code_higher_income'].apply(code_for_higher_income_2002)\n",
    "df_2012['code_higher_income'] = df_2012['code_higher_income'].apply(code_for_higher_income_2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b5e3a",
   "metadata": {},
   "source": [
    "### `marital`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16d9b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_marital_status(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    if 'refused' in val_str or 'no answer' in val_str or val_str.startswith('-'):\n",
    "        return None\n",
    "    if 'civil partnership' in val_str and 'never' not in val_str and \"separate\" not in val_str:\n",
    "        return \"Civil partnership\"\n",
    "    if ('married' in val_str or 'marr' in val_str) and 'civil partnership' not in val_str:\n",
    "        if 'never' not in val_str and 'separated' not in val_str and 'divorced' not in val_str:\n",
    "            return \"Married\"\n",
    "    if 'widow' in val_str or 'died' in val_str:\n",
    "        return \"Widowed\"\n",
    "    if 'divorced' in val_str or 'legally separated' in val_str:\n",
    "        return \"Divorced\"\n",
    "    if 'separated' in val_str and 'divorced' not in val_str and 'legally separated' not in val_str:\n",
    "        return \"Separated\"\n",
    "    if 'single' in val_str or 'never' in val_str:\n",
    "        return \"Single\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "df_2002[\"marital\"] = df_2002[\"marital\"].apply(clean_marital_status)\n",
    "df_2012[\"marital\"] = df_2012[\"marital\"].apply(clean_marital_status)\n",
    "df_2022[\"marital\"] = df_2022[\"marital\"].apply(clean_marital_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9376826e",
   "metadata": {},
   "source": [
    "### `SPWRKHRS`, `wrk_hrs`, `SP_HH_FAM`, `HH_FAM`, `SP_HH` and `hh_wrk_hrs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4346ae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_work_hours(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "\n",
    "    s = str(val).strip().lower()\n",
    "\n",
    "    if re.match(r\"^\\s*-\\d+\", s):\n",
    "        return None\n",
    "    if any(k in s for k in [\n",
    "        \"nap\", \"no answer\", \"don't know\", \"refused\", \"not available\",\n",
    "        \"can't choose\", \"time varies\", \"does not apply\", \"not applicable\"\n",
    "    ]):\n",
    "        return None\n",
    "    if any(k in s for k in [\"none, no hour\", \"none, no hours\", \"no hour\", \"no hours\", \"0. none\"]):\n",
    "        return 0\n",
    "    if \"one hour\" in s or s.startswith(\"1. 1 hour\") or s == \"1 hour\":\n",
    "        return 1\n",
    "    if \"96\" in s or \"95\" in s or \"hours and more\" in s or \"hrs a more\" in s:\n",
    "        return 95\n",
    "    m = re.search(r\"(\\d+\\.?\\d*)\", s)\n",
    "    if m:\n",
    "        num = float(m.group(1))\n",
    "        return int(num) if num <= 95 else 95\n",
    "\n",
    "    return None\n",
    "\n",
    "hour_vars = [\"SPWRKHRS\", \"wrk_hrs\", \"SP_HH_FAM\", \"HH_FAM\", \"SP_HH\", \"hh_wrk_hrs\"]\n",
    "for var in hour_vars:\n",
    "    for df, year in zip([df_2002, df_2012, df_2022],[2002, 2012, 2002]):\n",
    "        df[var] = df[var].apply(clean_work_hours).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1852eb51",
   "metadata": {},
   "source": [
    "### `educ_4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "838b46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_education_educ_4(val, year):\n",
    "    \"\"\"\n",
    "    Standardize education into 4 harmonized categories across waves.\n",
    "    Returns label string directly.\n",
    "    \"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing values\n",
    "    missing_patterns = [\n",
    "        r\"no answer\", r\"don't know\", r\"cant choose\", r\"can't choose\",\n",
    "        r\"not classifiable\", r\"not codable\"\n",
    "    ]\n",
    "    miss_re = re.compile(\"|\".join(missing_patterns), flags=re.IGNORECASE)\n",
    "    if miss_re.search(val_str) or val_str.startswith('-'):\n",
    "        return None\n",
    "\n",
    "    # --- 2002: \"University degree completed\", \"Higher secondary completed\", etc. ---\n",
    "    if year == 2002:\n",
    "        if \"no formal\" in val_str or \"lowest formal\" in val_str:\n",
    "            return \"No/Primary\"\n",
    "        if \"higher secondary completed\" in val_str:\n",
    "            return \"Secondary\"\n",
    "        if \"above lowest\" in val_str or \"above higher sec\" in val_str:\n",
    "            return \"Post-sec / Short tertiary\"\n",
    "        if \"university degree completed\" in val_str:\n",
    "            return \"University+\"\n",
    "        return None\n",
    "\n",
    "    # --- 2012: Primary / lower secondary / upper secondary / tertiary levels ---\n",
    "    elif year == 2012:\n",
    "        if \"no formal education\" in val_str or \"primary\" in val_str:\n",
    "            return \"No/Primary\"\n",
    "        if \"lower secondary\" in val_str or \"upper secondary\" in val_str:\n",
    "            return \"Secondary\"\n",
    "        if \"post secondary, non-tertiary\" in val_str or \"lower level tertiary\" in val_str:\n",
    "            return \"Post-sec / Short tertiary\"\n",
    "        if \"upper level tertiary\" in val_str or \"master\" in val_str or \"dr\" in val_str or \"phd\" in val_str:\n",
    "            return \"University+\"\n",
    "        return None\n",
    "\n",
    "    # --- 2022: numeric-coded labels 0..8 embedded in strings ---\n",
    "    elif year == 2022:\n",
    "        match = re.search(r\"^\\s*([0-9]+)\", val_str)\n",
    "        if match:\n",
    "            code = int(match.group(1))\n",
    "            if code in [0, 1]:\n",
    "                return \"No/Primary\"\n",
    "            elif code in [2, 3]:\n",
    "                return \"Secondary\"\n",
    "            elif code in [4, 5]:\n",
    "                return \"Post-sec / Short tertiary\"\n",
    "            elif code in [6, 7, 8]:\n",
    "                return \"University+\"\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68c914e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002['educ_4_label'] = df_2002['educ_4_label'].apply(lambda x: clean_education_educ_4(x, 2002))\n",
    "df_2012['educ_4_label'] = df_2012['educ_4_label'].apply(lambda x: clean_education_educ_4(x, 2012))\n",
    "df_2022['educ_4_label'] = df_2022['educ_4_label'].apply(lambda x: clean_education_educ_4(x, 2022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7a393d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_map = {\n",
    "    \"No/Primary\": 0,\n",
    "    \"Secondary\": 1,\n",
    "    \"Post-sec / Short tertiary\": 2,\n",
    "    \"University+\": 3\n",
    "}\n",
    "df_2002[\"educ_4\"] = df_2002[\"educ_4_label\"].map(edu_map)\n",
    "df_2012[\"educ_4\"] = df_2012[\"educ_4_label\"].map(edu_map)\n",
    "df_2022[\"educ_4\"] = df_2022[\"educ_4_label\"].map(edu_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7822bba8",
   "metadata": {},
   "source": [
    "### `SP_DEGREE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d493bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spouse_education(df, year, educ_col, new_col):\n",
    "    d = df.copy()\n",
    "    s = d[educ_col].astype(str).str.strip()\n",
    "\n",
    "    missing_patterns = [\n",
    "        r\"^-9\", r\"^-8\", r\"^-4\", r\"^-1\", r\"no answer\", r\"don't know\", r\"cant choose\", \n",
    "        r\"can't choose\", r\"not classifiable\", r\"not codable\", r\"nap\", r\"not available\"\n",
    "    ]\n",
    "    miss_re = re.compile(\"|\".join(missing_patterns), flags=re.IGNORECASE)\n",
    "    s = s.mask(s.str.contains(miss_re, na=False), np.nan)\n",
    "\n",
    "    if year == 2002:\n",
    "        def map_2002(x):\n",
    "            if pd.isna(x): return np.nan\n",
    "            x = x.lower()\n",
    "            if \"no formal\" in x or \"lowest formal\" in x:\n",
    "                return 0\n",
    "            if \"higher secondary completed\" in x:\n",
    "                return 1\n",
    "            if \"above lowest\" in x or \"above higher sec\" in x:\n",
    "                return 2\n",
    "            if \"university degree completed\" in x:\n",
    "                return 3\n",
    "            return np.nan\n",
    "\n",
    "        d[new_col] = s.map(map_2002)\n",
    "\n",
    "    elif year == 2012:\n",
    "        def map_2012(x):\n",
    "            if pd.isna(x): return np.nan\n",
    "            x = x.lower()\n",
    "            if \"no formal education\" in x or \"primary\" in x:\n",
    "                return 0\n",
    "            if \"lower secondary\" in x or \"upper secondary\" in x:\n",
    "                return 1\n",
    "            if \"post secondary, non-tertiary\" in x or \"lower level tertiary\" in x or \"short-cycle tertiary\" in x:\n",
    "                return 2\n",
    "            if \"upper level tertiary\" in x or \"master\" in x or \"dr.\" in x or \"phd\" in x:\n",
    "                return 3\n",
    "            return np.nan\n",
    "\n",
    "        d[new_col] = s.map(map_2012)\n",
    "\n",
    "    elif year == 2022:\n",
    "        code = pd.to_numeric(s.str.extract(r\"^\\s*([0-9]+)\")[0], errors=\"coerce\")\n",
    "\n",
    "        d[new_col] = np.select(\n",
    "            [\n",
    "                code.isna(),\n",
    "                code.isin([0, 1]),\n",
    "                code.isin([2, 3]),\n",
    "                code.isin([4, 5]),\n",
    "                code.isin([6, 7, 8]),\n",
    "            ],\n",
    "            [np.nan, 0, 1, 2, 3],\n",
    "            default=np.nan\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"year must be one of {2002, 2012, 2022}\")\n",
    "\n",
    "    labels = {\n",
    "        0: \"No/Primary\",\n",
    "        1: \"Secondary\",\n",
    "        2: \"Post-sec / Short tertiary\",\n",
    "        3: \"University+\",\n",
    "    }\n",
    "    d[new_col + \"_label\"] = d[new_col].map(labels)\n",
    "\n",
    "    return d\n",
    "\n",
    "df_2002 = clean_spouse_education(df_2002, 2002, \"SP_DEGREE\", \"SP_DEGREE_clean\")\n",
    "df_2012 = clean_spouse_education(df_2012, 2012, \"SP_DEGREE\", \"SP_DEGREE_clean\")\n",
    "df_2022 = clean_spouse_education(df_2022, 2022, \"SP_DEGREE\", \"SP_DEGREE_clean\")\n",
    "\n",
    "df_2002[\"SP_DEGREE\"] = df_2002[\"SP_DEGREE_clean_label\"]\n",
    "df_2012[\"SP_DEGREE\"] = df_2012[\"SP_DEGREE_clean_label\"]\n",
    "df_2022[\"SP_DEGREE\"] = df_2022[\"SP_DEGREE_clean_label\"]\n",
    "\n",
    "df_2002.drop([\"SP_DEGREE_clean\", \"SP_DEGREE_clean_label\"], axis=1, inplace=True)\n",
    "df_2012.drop([\"SP_DEGREE_clean\", \"SP_DEGREE_clean_label\"], axis=1, inplace=True)\n",
    "df_2022.drop([\"SP_DEGREE_clean\", \"SP_DEGREE_clean_label\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ef27d",
   "metadata": {},
   "source": [
    "### `LIVWOMAR`,`MEWH`,`HW_FULFIL`,`WO_WANT`,`WW_FAM_SUFFER`,`WW_CHILD_SUFFER` and `WW_WARM` (Likert-scale variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c1d8c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_likert_5(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', 'nap', \"can't choose\", 'not available']):\n",
    "        return None\n",
    "    \n",
    "    if 'strongly agree' in val_str or val_str.startswith('1.'):\n",
    "        return \"Strongly agree\"\n",
    "    if ('agree' in val_str and 'disagree' not in val_str and 'neither' not in val_str) or val_str.startswith('2.'):\n",
    "        return \"Agree\"\n",
    "    if 'neither' in val_str or val_str.startswith('3.'):\n",
    "        return \"Neither agree nor disagree\"\n",
    "    if ('disagree' in val_str and 'strongly' not in val_str) or val_str.startswith('4.'):\n",
    "        return \"Disagree\"\n",
    "    if 'strongly disagree' in val_str or val_str.startswith('5.'):\n",
    "        return \"Strongly disagree\"\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12cb3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "likert_vars = ['LIVWOMAR','MEWH','HW_FULFIL','WO_WANT','WW_FAM_SUFFER','WW_CHILD_SUFFER','WW_WARM']\n",
    "for var in likert_vars:\n",
    "    for df, year in zip([df_2002, df_2012, df_2022], [2002, 2012, 2002]):\n",
    "        df[var] = df[var].apply(clean_likert_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc5255",
   "metadata": {},
   "source": [
    "### `TOPBOT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d463c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_topbot(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    if any(x in val_str for x in [\"don't know\", 'no answer', 'refused', 'not available']):\n",
    "        return None\n",
    "    \n",
    "    if 'lowest' in val_str or 'bottom' in val_str or '01' in val_str or val_str.startswith('1.'):\n",
    "        return 1\n",
    "    if 'highest' in val_str or 'top' in val_str or '10' in val_str:\n",
    "        return 10\n",
    "    \n",
    "    match = re.search(r'(\\d+)', val_str)\n",
    "    if match:\n",
    "        num = int(match.group(1))\n",
    "        if 1 <= num <= 10:\n",
    "            return num\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44955354",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002[\"TOPBOT\"] = df_2002[\"TOPBOT\"].apply(clean_topbot)\n",
    "df_2012[\"TOPBOT\"] = df_2012[\"TOPBOT\"].apply(clean_topbot)\n",
    "df_2022[\"TOPBOT\"] = df_2022[\"TOPBOT\"].apply(clean_topbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be875980",
   "metadata": {},
   "source": [
    "### `WWYKS` and `WWYKUS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e84857e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_work_preference(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", \"can't choose\"]):\n",
    "        return None\n",
    "    if 'women should decide' in val_str or 'women shld decide' in val_str or val_str.startswith('4.'):\n",
    "        return \"Women should decide\"\n",
    "    if 'full-time' in val_str or 'full time' in val_str or val_str.startswith('1.'):\n",
    "        return \"Work full-time\"\n",
    "    if 'part-time' in val_str or 'part time' in val_str or val_str.startswith('2.'):\n",
    "        return \"Work part-time\"\n",
    "    if 'stay at home' in val_str or val_str.startswith('3.'):\n",
    "        return \"Stay at home\"\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6bf9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002[\"WWYKS\"] = df_2002[\"WWYKS\"].apply(clean_work_preference)\n",
    "df_2012[\"WWYKS\"] = df_2012[\"WWYKS\"].apply(clean_work_preference)\n",
    "df_2022[\"WWYKS\"] = df_2022[\"WWYKS\"].apply(clean_work_preference)\n",
    "\n",
    "df_2002[\"WWYKUS\"] = df_2002[\"WWYKUS\"].apply(clean_work_preference)\n",
    "df_2012[\"WWYKUS\"] = df_2012[\"WWYKUS\"].apply(clean_work_preference)\n",
    "df_2022[\"WWYKUS\"] = df_2022[\"WWYKUS\"].apply(clean_work_preference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e632015d",
   "metadata": {},
   "source": [
    "### `MOMORFAF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dabacbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_parent_suit(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", \"can't choose\"]):\n",
    "        return None\n",
    "    \n",
    "    if 'strongly agree' in val_str or 'mothers and fathers are equally' in val_str or val_str.startswith('3.'):\n",
    "        return \"Equally suited\"\n",
    "    \n",
    "    if ('agree' in val_str and 'strongly' not in val_str and 'neither' not in val_str and 'disagree' not in val_str) or \\\n",
    "       'mothers are somewhat better' in val_str or val_str.startswith('2.'):\n",
    "        return \"Mothers somewhat better\"\n",
    "    \n",
    "    if 'mothers are much better' in val_str or val_str.startswith('1.'):\n",
    "        return \"Mothers much better\"\n",
    "    \n",
    "    if 'fathers are somewhat better' in val_str or val_str.startswith('4.'):\n",
    "        return \"Fathers somewhat better\"\n",
    "    \n",
    "    if 'strongly disagree' in val_str or 'fathers are much better' in val_str or val_str.startswith('5.'):\n",
    "        return \"Fathers much better\"\n",
    "    \n",
    "    if 'neither' in val_str or 'disagree' in val_str:\n",
    "        return \"Equally suited\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "df_2002[\"MOMORFAF\"] = df_2002[\"MOMORFAF\"].apply(clean_parent_suit)\n",
    "df_2012[\"MOMORFAF\"] = df_2012[\"MOMORFAF\"].apply(clean_parent_suit)\n",
    "df_2022[\"MOMORFAF\"] = df_2022[\"MOMORFAF\"].apply(clean_parent_suit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bbc87e",
   "metadata": {},
   "source": [
    "### `HHTODD`, `HHCHILDR`, `HHADULT` and `HOMPOP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52f50c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_household_count(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    if any(x in val_str for x in ['no answer', 'refused', 'nap', 'not available']):\n",
    "        return None\n",
    "    \n",
    "    if any(x in val_str for x in ['no children', 'no toddlers', 'no adults', 'no persons']):\n",
    "        return 0\n",
    "    \n",
    "    if 'one child' in val_str or 'one toddler' in val_str or 'one adult' in val_str or 'one person' in val_str:\n",
    "        return 1\n",
    "    \n",
    "    match = re.search(r'(\\d+)', val_str)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "721c4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "household_count_vars = [\"HHTODD\", \"HHCHILDR\", \"HHADULT\", \"HOMPOP\"]\n",
    "\n",
    "for var in household_count_vars:\n",
    "    for df, year in zip([df_2002, df_2012, df_2022], [2002, 2012, 2002]):\n",
    "        df[var] = df[var].apply(clean_household_count).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb95b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HHADULT for 2012 by subtracting children and toddlers from home population\n",
    "df_2012['HHADULT'] = df_2012['HOMPOP'] - df_2012['HHCHILDR'] - df_2012['HHTODD']\n",
    "df_2012=df_2012[df_2012['HHADULT']>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3966fb1a",
   "metadata": {},
   "source": [
    "### `FAM_DIF`, `DIFF_CONC_WORK`, `HH_TIRED` and `WORK_TIRED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "520f0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_frequency(val):\n",
    "    if pd.isna(val):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', \"doesn't apply\", 'nap', 'not available', \"can't choose\"]):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    if 'several times a week' in val_str or val_str.startswith('1.'):\n",
    "        return \"Several times a week\"\n",
    "    \n",
    "    if 'several times a month' in val_str or val_str.startswith('2.'):\n",
    "        return \"Several times a month\"\n",
    "    \n",
    "    if 'once or twice' in val_str or val_str.startswith('3.'):\n",
    "        return \"Once or twice\"\n",
    "    \n",
    "    if 'never' in val_str or val_str.startswith('4.'):\n",
    "        return \"Never\"\n",
    "    \n",
    "    return \"NAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adbdf9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_vars = [\"FAM_DIF\", \"DIFF_CONC_WORK\", \"HH_TIRED\", \"WORK_TIRED\"]\n",
    "for var in frequency_vars:\n",
    "    for df, year in zip([df_2002, df_2012, df_2022], [2002, 2012, 2022]):\n",
    "        if year == 2002:\n",
    "            df[var] = df[var].astype('string')\n",
    "            df[var] = df[var].apply(clean_frequency)\n",
    "        else:\n",
    "            df[var] = df[var].apply(clean_frequency).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d69e4c",
   "metadata": {},
   "source": [
    "### `SHARE_HH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "784de3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fairness_share(val):\n",
    "    if pd.isna(val):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', 'nap', \"can't choose\"]):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    if 'much more' in val_str or val_str.startswith('1.'):\n",
    "        return \"Much more than fair share\"\n",
    "    \n",
    "    if ('bit more' in val_str or 'a bit more' in val_str) or val_str.startswith('2.'):\n",
    "        return \"Bit more than fair share\"\n",
    "    \n",
    "    if 'roughly my fair share' in val_str or ('fair share' in val_str and 'more' not in val_str and 'less' not in val_str) or val_str.startswith('3.'):\n",
    "        return \"Fair share\"\n",
    "    \n",
    "    if ('bit less' in val_str or 'a bit less' in val_str) or val_str.startswith('4.'):\n",
    "        return \"Bit less than fair share\"\n",
    "    \n",
    "    if 'much less' in val_str or val_str.startswith('5.'):\n",
    "        return \"Much less than fair share\"\n",
    "    \n",
    "    return \"NAP\"\n",
    "\n",
    "df_2002[\"SHARE_HH\"] = df_2002[\"SHARE_HH\"].astype('string').apply(clean_fairness_share)\n",
    "df_2012[\"SHARE_HH\"] = df_2012[\"SHARE_HH\"].apply(clean_fairness_share).astype('string')\n",
    "df_2022[\"SHARE_HH\"] = df_2022[\"SHARE_HH\"].apply(clean_fairness_share).astype('string')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6b7b5",
   "metadata": {},
   "source": [
    "### `DIV_HH_COOK`,`DIV_HH_CLEAN`,`DIV_HH_GROC`,`DIV_HH_CARE` and `DIV_HH_LAUND`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab49a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_task_div(val):\n",
    "    if pd.isna(val):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing/NAP\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', 'nap', \"can't choose\"]):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    # Third person first\n",
    "    if 'third person' in val_str or val_str.startswith('6.'):\n",
    "        return \"Third person\"\n",
    "    \n",
    "    # Always respondent/me\n",
    "    if ('always me' in val_str or 'always respondent' in val_str) or val_str.startswith('1.'):\n",
    "        return \"Always respondent\"\n",
    "    \n",
    "    # Usually respondent/me\n",
    "    if ('usually me' in val_str or 'usually respondent' in val_str) or val_str.startswith('2.'):\n",
    "        return \"Usually respondent\"\n",
    "    \n",
    "    # About equal\n",
    "    if 'about equal' in val_str or 'both together' in val_str or 'both equally' in val_str or val_str.startswith('3.'):\n",
    "        return \"About equal\"\n",
    "    \n",
    "    # Usually partner\n",
    "    if ('usually' in val_str and ('spouse' in val_str or 'partner' in val_str)) or val_str.startswith('4.'):\n",
    "        return \"Usually partner\"\n",
    "    \n",
    "    # Always partner\n",
    "    if ('always' in val_str and ('spouse' in val_str or 'partner' in val_str)) or val_str.startswith('5.'):\n",
    "        return \"Always partner\"\n",
    "    \n",
    "    return \"NAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d9c58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_hh_vars = ['DIV_HH_COOK','DIV_HH_CLEAN','DIV_HH_GROC','DIV_HH_CARE','DIV_HH_LAUND']\n",
    "\n",
    "for var in div_hh_vars:\n",
    "    for df, year in zip([df_2002, df_2012, df_2022], [2002, 2012, 2002]):\n",
    "        if year == 2002:\n",
    "            df[var] = df[var].astype('string')\n",
    "            df[var] = df[var].apply(clean_task_div)\n",
    "        else:\n",
    "            df[var] = df[var].apply(clean_task_div).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b0ff2",
   "metadata": {},
   "source": [
    "### `LIFE_HAP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37373ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_happiness(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", \"can't choose\"]):\n",
    "        return None\n",
    "    \n",
    "    if 'completely happy' in val_str or val_str.startswith('1.'):\n",
    "        return \"Completely happy\"\n",
    "    if 'very happy' in val_str or val_str.startswith('2.'):\n",
    "        return \"Very happy\"\n",
    "    if 'fairly happy' in val_str or val_str.startswith('3.'):\n",
    "        return \"Fairly happy\"\n",
    "    if 'neither' in val_str or val_str.startswith('4.'):\n",
    "        return \"Neither happy nor unhappy\"\n",
    "    if 'fairly unhappy' in val_str or val_str.startswith('5.'):\n",
    "        return \"Fairly unhappy\"\n",
    "    if 'very unhappy' in val_str or val_str.startswith('6.'):\n",
    "        return \"Very unhappy\"\n",
    "    if 'completely unhappy' in val_str or val_str.startswith('7.'):\n",
    "        return \"Completely unhappy\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "df_2002[\"LIFE_HAP\"] = df_2002[\"LIFE_HAP\"].apply(clean_happiness)\n",
    "df_2012[\"LIFE_HAP\"] = df_2012[\"LIFE_HAP\"].apply(clean_happiness) \n",
    "df_2022[\"LIFE_HAP\"] = df_2022[\"LIFE_HAP\"].apply(clean_happiness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ad9332",
   "metadata": {},
   "source": [
    "### `HH_WEEKEND`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "648c39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weekend_decision(val):\n",
    "    if pd.isna(val):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', 'nap', \"can't choose\"]):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    if 'always me' in val_str or 'mostly me' in val_str or val_str.startswith('1.'):\n",
    "        return \"Always respondent\"\n",
    "    \n",
    "    if 'usually me' in val_str or val_str.startswith('2.'):\n",
    "        return \"Usually respondent\"\n",
    "    \n",
    "    if 'we decide together' in val_str or 'about equal' in val_str or 'both together' in val_str or val_str.startswith('3.'):\n",
    "        return \"About equal\"\n",
    "    \n",
    "    if ('usually' in val_str and ('spouse' in val_str or 'partner' in val_str)) or val_str.startswith('4.'):\n",
    "        return \"Usually partner\"\n",
    "    \n",
    "    if ('always' in val_str and ('spouse' in val_str or 'partner' in val_str)) or 'mostly my spouse' in val_str or val_str.startswith('5.'):\n",
    "        return \"Always partner\"\n",
    "    \n",
    "    if 'third person' in val_str or 'someone else' in val_str or val_str.startswith('6.'):\n",
    "        return \"Third person\"\n",
    "    \n",
    "    if 'sometimes' in val_str:\n",
    "        return \"About equal\"\n",
    "    \n",
    "    return \"NAP\"\n",
    "df_2002[\"HH_WEEKEND\"] = df_2002[\"HH_WEEKEND\"].astype('string').apply(clean_weekend_decision)\n",
    "df_2012[\"HH_WEEKEND\"] = df_2012[\"HH_WEEKEND\"].apply(clean_weekend_decision).astype('string')\n",
    "df_2022[\"HH_WEEKEND\"] = df_2022[\"HH_WEEKEND\"].apply(clean_weekend_decision).astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635f74bb",
   "metadata": {},
   "source": [
    "### `COHAB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80c9c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cohab(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    if any(x in val_str for x in ['no answer', 'refused', 'not available']):\n",
    "        return None\n",
    "    \n",
    "    if 'yes' in val_str and 'same household' in val_str or val_str.startswith('1.'):\n",
    "        return \"Partner, same household\"\n",
    "    \n",
    "    if 'yes' in val_str and \"don't live\" in val_str or val_str.startswith('2.'):\n",
    "        return \"Partner, different household\"\n",
    "    \n",
    "    if 'no partner' in val_str or val_str.startswith('3.'):\n",
    "        return \"No partner\"\n",
    "    \n",
    "    if val_str == 'yes':\n",
    "        return \"Partner, same household\"\n",
    "    if val_str == 'no':\n",
    "        return \"No partner\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "df_2002[\"COHAB\"] = df_2002[\"COHAB\"].apply(clean_cohab)\n",
    "df_2012[\"COHAB\"] = df_2012[\"COHAB\"].apply(clean_cohab) \n",
    "df_2022[\"COHAB\"] = df_2022[\"COHAB\"].apply(clean_cohab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dca4c63",
   "metadata": {},
   "source": [
    "### `C_ALPHAN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90d6aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_country(val):\n",
    "    \"\"\"Extract standardized country code.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).upper()\n",
    "    \n",
    "    # Extract 2-letter ISO code at start or after dash\n",
    "    match = re.match(r'(\\d+\\.\\s*)?([A-Z]{2})', val_str)\n",
    "    if match:\n",
    "        return match.group(2)\n",
    "    \n",
    "    return val_str[:2] if len(val_str) >= 2 else None\n",
    "\n",
    "df_2002[\"C_ALPHAN\"] = df_2002[\"C_ALPHAN\"].apply(clean_country)\n",
    "df_2012[\"C_ALPHAN\"] = df_2012[\"C_ALPHAN\"].apply(clean_country) \n",
    "df_2022[\"C_ALPHAN\"] = df_2022[\"C_ALPHAN\"].apply(clean_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646292ad",
   "metadata": {},
   "source": [
    "### `age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb05dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_age = {\n",
    "    \"Don't know\",\n",
    "    \"No answer\",\n",
    "    \"Refused\",\n",
    "    \"Not available\",\n",
    "}\n",
    "\n",
    "def clean_age(val):\n",
    "    if val is None:\n",
    "        return None\n",
    "    s = str(val)\n",
    "    if s in invalid_age:\n",
    "        return None\n",
    "    import re\n",
    "    m = re.search(r\"\\d+\", s)\n",
    "    return int(m.group()) if m else None\n",
    "\n",
    "df_2002[\"age\"] = df_2002[\"age\"].apply(clean_age).astype(float)\n",
    "df_2012[\"age\"] = df_2012[\"age\"].apply(clean_age).astype(float)\n",
    "df_2022[\"age\"] = df_2022[\"age\"].apply(clean_age).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2ec10c",
   "metadata": {},
   "source": [
    "Create age bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c80ba90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002[\"age_bin\"] = pd.cut(\n",
    "    df_2002[\"age\"],\n",
    "    bins=[0, 17, 25, 35, 45, 55, 65, 75, 100],\n",
    "    labels=[\"<18\",\"18-25\", \"26-35\", \"36-45\", \"46-55\", \"56-65\", \"66-75\", \"75+\"]\n",
    ")\n",
    "\n",
    "df_2012[\"age_bin\"] = pd.cut(\n",
    "    df_2012[\"age\"],\n",
    "    bins=[0, 17, 25, 35, 45, 55, 65, 75, 100],\n",
    "    labels=[\"<18\", \"18-25\", \"26-35\", \"36-45\", \"46-55\", \"56-65\", \"66-75\", \"75+\"]\n",
    ")\n",
    "\n",
    "df_2022[\"age_bin\"] = pd.cut(\n",
    "    df_2022[\"age\"],\n",
    "    bins=[0, 17, 25, 35, 45, 55, 65, 75, 100],\n",
    "    labels=[\"<18\", \"18-25\", \"26-35\", \"36-45\", \"46-55\", \"56-65\", \"66-75\", \"75+\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a53f76",
   "metadata": {},
   "source": [
    "### Remove rows with more than 60% null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23d8f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002 = df_2002[df_2002.isnull().mean(axis=1) <= 0.6]\n",
    "df_2012 = df_2012[df_2012.isnull().mean(axis=1) <= 0.6]\n",
    "df_2022 = df_2022[df_2022.isnull().mean(axis=1) <= 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ed91107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2002: (46618, 63)\n",
      "df_2012: (58464, 63)\n",
      "df_2022: (45762, 63)\n"
     ]
    }
   ],
   "source": [
    "print(f\"df_2002: {df_2002.shape}\")\n",
    "print(f\"df_2012: {df_2012.shape}\")\n",
    "print(f\"df_2022: {df_2022.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538bfdfb",
   "metadata": {},
   "source": [
    "### Remove rows where any of columns, which are used to construct equality score, are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fae2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002.dropna(subset=['v4_egal', 'v5_egal', 'v6_egal', 'v7_egal', 'v8_egal', 'v11_egal'], inplace=True)\n",
    "df_2012.dropna(subset=['V5_egal', 'V6_egal', 'V7_egal', 'V8_egal', 'V9_egal', 'V11_egal'], inplace=True)\n",
    "df_2022.dropna(subset=['v1_egal', 'v2_egal', 'v3_egal', 'v4_egal', 'v5_egal', 'v6_egal'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3bd97d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2002: (40395, 63)\n",
      "df_2012: (49884, 63)\n",
      "df_2022: (40768, 63)\n"
     ]
    }
   ],
   "source": [
    "print(f\"df_2002: {df_2002.shape}\")\n",
    "print(f\"df_2012: {df_2012.shape}\")\n",
    "print(f\"df_2022: {df_2022.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9ffac",
   "metadata": {},
   "source": [
    "### Remove rows where household adult population is more than total household population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d4d467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_2002, df_2012, df_2022]:\n",
    "    if \"HOMPOP\" in df.columns and \"HHADULT\" in df.columns:\n",
    "        df.drop(df[df[\"HOMPOP\"] < df[\"HHADULT\"]].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8293b1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2002: (40374, 63)\n",
      "df_2012: (49884, 63)\n",
      "df_2022: (40714, 63)\n"
     ]
    }
   ],
   "source": [
    "print(f\"df_2002: {df_2002.shape}\")\n",
    "print(f\"df_2012: {df_2012.shape}\")\n",
    "print(f\"df_2022: {df_2022.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f07375b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002.to_csv(\"../data/cleaned_csv/2002.csv\", index=False)\n",
    "df_2012.to_csv(\"../data/cleaned_csv/2012.csv\", index=False)\n",
    "df_2022.to_csv(\"../data/cleaned_csv/2022.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
