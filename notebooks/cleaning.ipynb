{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ef5159e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9a7cec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.io.stata.StataReader(\"../dta files/2012.dta\", convert_categoricals=True) as rdr:\n",
    "    cols = [c for c in rdr.variable_labels().keys() if c not in {\"ISCO88\", \"SPISCO88\"}]\n",
    "    df_2012 = rdr.read(columns=cols)\n",
    "\n",
    "with pd.io.stata.StataReader(\"../dta files/2002.dta\", convert_categoricals=True) as rdr:\n",
    "    cols = [c for c in rdr.variable_labels().keys() if c not in [\"v241\",\"v247\"]]\n",
    "    df_2002 = rdr.read(columns=cols)\n",
    "\n",
    "df_2022 = pd.read_stata(\"../dta files/2022.dta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8116037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002_clean = pd.read_csv(\"../data/final_csv/2002_final.csv\")\n",
    "df_2012_clean = pd.read_csv(\"../data/final_csv/2012_final.csv\")\n",
    "df_2022_clean = pd.read_csv(\"../data/final_csv/2022_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "14c4c75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(series):\n",
    "    \"\"\"\n",
    "    Normalize a numeric series to 0-1 range using min-max scaling.\n",
    "    \"\"\"\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "# Apply to eg_score columns\n",
    "df_2002_clean['eg_score_norm'] = normalize_column(df_2002_clean['eg_score'])\n",
    "df_2012_clean['eg_score_norm'] = normalize_column(df_2012_clean['eg_score'])\n",
    "df_2022_clean['eg_score_norm'] = normalize_column(df_2022_clean['eg_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de75a5",
   "metadata": {},
   "source": [
    " hh_work_hours_respondent:\n",
    "    category: \"behavior_time_use\"\n",
    "    years:\n",
    "      \"2002\": {name: \"v36\", question: \"Q9a\"}\n",
    "      \"2012\": {name: \"v37\", question: \"Q16a\"}\n",
    "      \"2022\": {name: \"v34\", question: \"Q15a\"}\n",
    "  hh_work_hours_partner:\n",
    "    category: \"behavior_time_use\"\n",
    "    years:\n",
    "      \"2002\": {name: \"v37\", question: \"Q9b\"}\n",
    "      \"2012\": {name: \"v39\", question: \"Q17a\"}\n",
    "      \"2022\": {name: \"v36\", question: \"Q16a\"}\n",
    "  task_laundry:\n",
    "    category: \"behavior_task_division\"\n",
    "    years:\n",
    "      \"2002\": {name: \"v30\", question: \"Q8a\"}\n",
    "      \"2012\": {name: \"v42\", question: \"Q19a\"}\n",
    "      \"2022\": {name: \"v39\", question: \"Q18a\"}\n",
    "  task_care_sick:\n",
    "    category: \"behavior_task_division\"\n",
    "    years:\n",
    "      \"2002\": {name: \"v32\", question: \"Q8c\"}\n",
    "      \"2012\": {name: \"v44\", question: \"Q19c\"}\n",
    "      \"2022\": {name: \"v41\", question: \"Q18c\"}\n",
    "  task_grocery:\n",
    "    category: \"behavior_task_division\"\n",
    "    years:\n",
    "      \"2002\": {name: \"v33\", question: \"Q8d\"}\n",
    "      \"2012\": {name: \"v45\", question: \"Q19d\"}\n",
    "      \"2022\": {name: \"v42\", question: \"Q18d\"}\n",
    "  task_cleaning:\n",
    "    category: \"behavior_task_division\"\n",
    "    years:\n",
    "      \"2002\": {name: \"v34\", question: \"Q8e\"}\n",
    "      \"2012\": {name: \"v46\", question: \"Q19e\"}\n",
    "      \"2022\": {name: \"v43\", question: \"Q18e\"}\n",
    "  task_meals:\n",
    "    category: \"behavior_task_division\"\n",
    "    years:\n",
    "      \"2002\": {name: \"v35\", question: \"Q8f\"}\n",
    "      \"2012\": {name: \"v47\", question: \"Q19f\"}\n",
    "      \"2022\": {name: \"v44\", question: \"Q18f\"}\n",
    "  task_fairness:\n",
    "    category: \"behavior_task_division\"\n",
    "    years:\n",
    "      \"2002\": {name: \"v38\", question: \"Q10\"}\n",
    "      \"2012\": {name: \"v48\", question: \"Q20\"}\n",
    "      \"2022\": {name: \"v45\", question: \"Q19\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bda9e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Variable: hh_hrs_resp\n",
      "============================================================\n",
      "\n",
      "--- 2002 ---\n",
      "Index([   '1 hour or less than 1 hr',                       '2 hrs',\n",
      "                                 3.0,                           4.0,\n",
      "                                 5.0,                           6.0,\n",
      "                                 7.0,                           8.0,\n",
      "                                 9.0,                          10.0,\n",
      "                                11.0,                          12.0,\n",
      "                                13.0,                          14.0,\n",
      "                                15.0,                          16.0,\n",
      "                                17.0,                          18.0,\n",
      "                                19.0,                          20.0,\n",
      "                                21.0,                          22.0,\n",
      "                                23.0,                          24.0,\n",
      "                                25.0,                          26.0,\n",
      "                                27.0,                          28.0,\n",
      "                                29.0,                          30.0,\n",
      "                                31.0,                          32.0,\n",
      "                                33.0,                          34.0,\n",
      "                                35.0,                          36.0,\n",
      "                                37.0,                          38.0,\n",
      "                                39.0,                          40.0,\n",
      "                                41.0,                          42.0,\n",
      "                                43.0,                          44.0,\n",
      "                                45.0,                          46.0,\n",
      "                                47.0,                          48.0,\n",
      "                                49.0,                          50.0,\n",
      "                                51.0,                          52.0,\n",
      "                                54.0,                          55.0,\n",
      "                                56.0,                          57.0,\n",
      "                                58.0,                          59.0,\n",
      "                                60.0,                          62.0,\n",
      "                                63.0,                          64.0,\n",
      "                                65.0,                          66.0,\n",
      "                                67.0,                          68.0,\n",
      "                                70.0,                          71.0,\n",
      "                                72.0,                          74.0,\n",
      "                                75.0,                          76.0,\n",
      "                                77.0,                          78.0,\n",
      "                                80.0,                          82.0,\n",
      "                                84.0,                          85.0,\n",
      "                                86.0,                          87.0,\n",
      "                                88.0,                          90.0,\n",
      "                                91.0,                          94.0,\n",
      "       '95 hrs a more,US:96+,BR:98+',               'None, no hour'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2012 ---\n",
      "Index([   'None, no hours, does not apply',\n",
      "              '1 hour or less than 1 hour',\n",
      "                                 '2 hours',\n",
      "                                 '3 hours',\n",
      "                                         4,\n",
      "                                         5,\n",
      "                                         6,\n",
      "                                         7,\n",
      "                                         8,\n",
      "                                         9,\n",
      "                                        10,\n",
      "                                        11,\n",
      "                                        12,\n",
      "                                        13,\n",
      "                                        14,\n",
      "                                        15,\n",
      "                                        16,\n",
      "                                        17,\n",
      "                                        18,\n",
      "                                        19,\n",
      "                                        20,\n",
      "                                        21,\n",
      "                                        22,\n",
      "                                        23,\n",
      "                                        24,\n",
      "                                        25,\n",
      "                                        26,\n",
      "                                        27,\n",
      "                                        28,\n",
      "                                        29,\n",
      "                                        30,\n",
      "                                        31,\n",
      "                                        32,\n",
      "                                        33,\n",
      "                                        34,\n",
      "                                        35,\n",
      "                                        36,\n",
      "                                        37,\n",
      "                                        38,\n",
      "                                        39,\n",
      "                                        40,\n",
      "                                        41,\n",
      "                                        42,\n",
      "                                        43,\n",
      "                                        44,\n",
      "                                        45,\n",
      "                                        46,\n",
      "                                        47,\n",
      "                                        48,\n",
      "                                        49,\n",
      "                                        50,\n",
      "                                        51,\n",
      "                                        52,\n",
      "                                        53,\n",
      "                                        54,\n",
      "                                        55,\n",
      "                                        56,\n",
      "                                        57,\n",
      "                                        58,\n",
      "                                        59,\n",
      "                                        60,\n",
      "                                        62,\n",
      "                                        63,\n",
      "                                        64,\n",
      "                                        65,\n",
      "                                        66,\n",
      "                                        67,\n",
      "                                        68,\n",
      "                                        70,\n",
      "                                        71,\n",
      "                                        72,\n",
      "                                        73,\n",
      "                                        74,\n",
      "                                        75,\n",
      "                                        76,\n",
      "                                        77,\n",
      "                                        78,\n",
      "                                        80,\n",
      "                                        82,\n",
      "                                        84,\n",
      "                                        85,\n",
      "                                        86,\n",
      "                                        87,\n",
      "                                        89,\n",
      "                                        90,\n",
      "                                        91,\n",
      "                                        92,\n",
      "                                        93,\n",
      "                                        94,\n",
      "                       '95 hours and more',\n",
      "            'Don't know, BG: can't choose',\n",
      "       'No answer, CA: no answer, refused'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2022 ---\n",
      "Index(['-9. No answer; HR, IS: DK/NA; ES, HU: Can't Ch/NA; LT: NA/DK/Hard to say; PL: Hard to say/NA; TW: Can't choose',\n",
      "                                                                                                    '0. None, no hours',\n",
      "                                                                                                            '1. 1 hour',\n",
      "                                                                                                                      2,\n",
      "                                                                                                                      3,\n",
      "                                                                                                                      4,\n",
      "                                                                                                                      5,\n",
      "                                                                                                                      6,\n",
      "                                                                                                                      7,\n",
      "                                                                                                                      8,\n",
      "                                                                                                                      9,\n",
      "                                                                                                                     10,\n",
      "                                                                                                                     11,\n",
      "                                                                                                                     12,\n",
      "                                                                                                                     13,\n",
      "                                                                                                                     14,\n",
      "                                                                                                                     15,\n",
      "                                                                                                                     16,\n",
      "                                                                                                                     17,\n",
      "                                                                                                                     18,\n",
      "                                                                                                                     19,\n",
      "                                                                                                                     20,\n",
      "                                                                                                                     21,\n",
      "                                                                                                                     22,\n",
      "                                                                                                                     23,\n",
      "                                                                                                                     24,\n",
      "                                                                                                                     25,\n",
      "                                                                                                                     26,\n",
      "                                                                                                                     27,\n",
      "                                                                                                                     28,\n",
      "                                                                                                                     29,\n",
      "                                                                                                                     30,\n",
      "                                                                                                                     31,\n",
      "                                                                                                                     32,\n",
      "                                                                                                                     33,\n",
      "                                                                                                                     34,\n",
      "                                                                                                                     35,\n",
      "                                                                                                                     36,\n",
      "                                                                                                                     37,\n",
      "                                                                                                                     38,\n",
      "                                                                                                                     39,\n",
      "                                                                                                                     40,\n",
      "                                                                                                                     41,\n",
      "                                                                                                                     42,\n",
      "                                                                                                                     43,\n",
      "                                                                                                                     44,\n",
      "                                                                                                                     45,\n",
      "                                                                                                                     46,\n",
      "                                                                                                                     47,\n",
      "                                                                                                                     48,\n",
      "                                                                                                                     49,\n",
      "                                                                                                                     50,\n",
      "                                                                                                                     52,\n",
      "                                                                                                                     53,\n",
      "                                                                                                                     54,\n",
      "                                                                                                                     55,\n",
      "                                                                                                                     56,\n",
      "                                                                                                                     58,\n",
      "                                                                                                                     59,\n",
      "                                                                                                                     60,\n",
      "                                                                                                                     61,\n",
      "                                                                                                                     62,\n",
      "                                                                                                                     63,\n",
      "                                                                                                                     64,\n",
      "                                                                                                                     65,\n",
      "                                                                                                                     66,\n",
      "                                                                                                                     67,\n",
      "                                                                                                                     68,\n",
      "                                                                                                                     70,\n",
      "                                                                                                                     71,\n",
      "                                                                                                                     72,\n",
      "                                                                                                                     73,\n",
      "                                                                                                                     74,\n",
      "                                                                                                                     75,\n",
      "                                                                                                                     76,\n",
      "                                                                                                                     78,\n",
      "                                                                                                                     80,\n",
      "                                                                                                                     82,\n",
      "                                                                                                                     83,\n",
      "                                                                                                                     84,\n",
      "                                                                                                                     85,\n",
      "                                                                                                                     86,\n",
      "                                                                                                                     88,\n",
      "                                                                                                                     90,\n",
      "                                                                                                                     91,\n",
      "                                                                                                                     94,\n",
      "                                                                                                '95. 95 hours and more'],\n",
      "      dtype='object')\n",
      "\n",
      "============================================================\n",
      "Variable: hh_hrs_partner\n",
      "============================================================\n",
      "\n",
      "--- 2002 ---\n",
      "Index([   '1 hour or less than 1 hr',                       '2 hrs',\n",
      "                                 3.0,                           4.0,\n",
      "                                 5.0,                           6.0,\n",
      "                                 7.0,                           8.0,\n",
      "                                 9.0,                          10.0,\n",
      "                                11.0,                          12.0,\n",
      "                                13.0,                          14.0,\n",
      "                                15.0,                          16.0,\n",
      "                                17.0,                          18.0,\n",
      "                                19.0,                          20.0,\n",
      "                                21.0,                          22.0,\n",
      "                                23.0,                          24.0,\n",
      "                                25.0,                          26.0,\n",
      "                                27.0,                          28.0,\n",
      "                                29.0,                          30.0,\n",
      "                                31.0,                          32.0,\n",
      "                                33.0,                          34.0,\n",
      "                                35.0,                          36.0,\n",
      "                                37.0,                          38.0,\n",
      "                                39.0,                          40.0,\n",
      "                                41.0,                          42.0,\n",
      "                                43.0,                          44.0,\n",
      "                                45.0,                          46.0,\n",
      "                                47.0,                          48.0,\n",
      "                                49.0,                          50.0,\n",
      "                                51.0,                          52.0,\n",
      "                                54.0,                          55.0,\n",
      "                                56.0,                          58.0,\n",
      "                                59.0,                          60.0,\n",
      "                                62.0,                          63.0,\n",
      "                                64.0,                          65.0,\n",
      "                                66.0,                          68.0,\n",
      "                                69.0,                          70.0,\n",
      "                                71.0,                          72.0,\n",
      "                                73.0,                          74.0,\n",
      "                                75.0,                          76.0,\n",
      "                                77.0,                          80.0,\n",
      "                                84.0,                          85.0,\n",
      "                                88.0,                          90.0,\n",
      "                                91.0,                          93.0,\n",
      "       '95 hrs a more,US:96+,BR:98+',               'None, no hour'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2012 ---\n",
      "Index(['NAP, no partner (3 (AR,AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)',\n",
      "                                                                                                 '1 hour or less than 1 hour',\n",
      "                                                                                                                    '2 hours',\n",
      "                                                                                                                    '3 hours',\n",
      "                                                                                                                            4,\n",
      "                                                                                                                            5,\n",
      "                                                                                                                            6,\n",
      "                                                                                                                            7,\n",
      "                                                                                                                            8,\n",
      "                                                                                                                            9,\n",
      "                                                                                                                           10,\n",
      "                                                                                                                           11,\n",
      "                                                                                                                           12,\n",
      "                                                                                                                           13,\n",
      "                                                                                                                           14,\n",
      "                                                                                                                           15,\n",
      "                                                                                                                           16,\n",
      "                                                                                                                           17,\n",
      "                                                                                                                           18,\n",
      "                                                                                                                           19,\n",
      "                                                                                                                           20,\n",
      "                                                                                                                           21,\n",
      "                                                                                                                           22,\n",
      "                                                                                                                           23,\n",
      "                                                                                                                           24,\n",
      "                                                                                                                           25,\n",
      "                                                                                                                           26,\n",
      "                                                                                                                           27,\n",
      "                                                                                                                           28,\n",
      "                                                                                                                           29,\n",
      "                                                                                                                           30,\n",
      "                                                                                                                           31,\n",
      "                                                                                                                           32,\n",
      "                                                                                                                           33,\n",
      "                                                                                                                           34,\n",
      "                                                                                                                           35,\n",
      "                                                                                                                           36,\n",
      "                                                                                                                           37,\n",
      "                                                                                                                           38,\n",
      "                                                                                                                           39,\n",
      "                                                                                                                           40,\n",
      "                                                                                                                           41,\n",
      "                                                                                                                           42,\n",
      "                                                                                                                           43,\n",
      "                                                                                                                           44,\n",
      "                                                                                                                           45,\n",
      "                                                                                                                           46,\n",
      "                                                                                                                           47,\n",
      "                                                                                                                           48,\n",
      "                                                                                                                           49,\n",
      "                                                                                                                           50,\n",
      "                                                                                                                           51,\n",
      "                                                                                                                           52,\n",
      "                                                                                                                           54,\n",
      "                                                                                                                           55,\n",
      "                                                                                                                           56,\n",
      "                                                                                                                           57,\n",
      "                                                                                                                           58,\n",
      "                                                                                                                           60,\n",
      "                                                                                                                           61,\n",
      "                                                                                                                           62,\n",
      "                                                                                                                           63,\n",
      "                                                                                                                           64,\n",
      "                                                                                                                           65,\n",
      "                                                                                                                           66,\n",
      "                                                                                                                           68,\n",
      "                                                                                                                           69,\n",
      "                                                                                                                           70,\n",
      "                                                                                                                           71,\n",
      "                                                                                                                           72,\n",
      "                                                                                                                           74,\n",
      "                                                                                                                           75,\n",
      "                                                                                                                           76,\n",
      "                                                                                                                           77,\n",
      "                                                                                                                           78,\n",
      "                                                                                                                           80,\n",
      "                                                                                                                           81,\n",
      "                                                                                                                           84,\n",
      "                                                                                                                           85,\n",
      "                                                                                                                           86,\n",
      "                                                                                                                           90,\n",
      "                                                                                                                           91,\n",
      "                                                                                                                           92,\n",
      "                                                                                                                           94,\n",
      "                                                                                                          '95 hours and more',\n",
      "                                                                                                             'None, no hours',\n",
      "                                                                      'Don't know, BG: can't choose, KR: don't know, refused',\n",
      "                                                                                          'No answer, CA: no answer, refused'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2022 ---\n",
      "Index([                            '-9. No answer; HR, IS: DK/NA; ES, HU, TW: Can't Ch/NA; LT: NA/DK/Hard to say; PL: Hard to say/NA',\n",
      "       '-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL',\n",
      "                                                                                                                  '0. None, no hours',\n",
      "                                                                                                                          '1. 1 hour',\n",
      "                                                                                                                                  2.0,\n",
      "                                                                                                                                  3.0,\n",
      "                                                                                                                                  3.5,\n",
      "                                                                                                                                  4.0,\n",
      "                                                                                                                                  5.0,\n",
      "                                                                                                                                  6.0,\n",
      "                                                                                                                                  7.0,\n",
      "                                                                                                                                  8.0,\n",
      "                                                                                                                                  9.0,\n",
      "                                                                                                                                 10.0,\n",
      "                                                                                                                                 11.0,\n",
      "                                                                                                                                 12.0,\n",
      "                                                                                                                                 13.0,\n",
      "                                                                                                                                 14.0,\n",
      "                                                                                                                                 15.0,\n",
      "                                                                                                                                 16.0,\n",
      "                                                                                                                                 17.0,\n",
      "                                                                                                                                 18.0,\n",
      "                                                                                                                                 19.0,\n",
      "                                                                                                                                 20.0,\n",
      "                                                                                                                                 21.0,\n",
      "                                                                                                                                 22.0,\n",
      "                                                                                                                                 23.0,\n",
      "                                                                                                                                 24.0,\n",
      "                                                                                                                                 25.0,\n",
      "                                                                                                                                 26.0,\n",
      "                                                                                                                                 27.0,\n",
      "                                                                                                                                 28.0,\n",
      "                                                                                                                                 29.0,\n",
      "                                                                                                                                 30.0,\n",
      "                                                                                                                                 31.0,\n",
      "                                                                                                                                 32.0,\n",
      "                                                                                                                                 33.0,\n",
      "                                                                                                                                 34.0,\n",
      "                                                                                                                                 35.0,\n",
      "                                                                                                                                 36.0,\n",
      "                                                                                                                                 37.0,\n",
      "                                                                                                                                 38.0,\n",
      "                                                                                                                                 39.0,\n",
      "                                                                                                                                 40.0,\n",
      "                                                                                                                                 41.0,\n",
      "                                                                                                                                 42.0,\n",
      "                                                                                                                                 43.0,\n",
      "                                                                                                                                 44.0,\n",
      "                                                                                                                                 45.0,\n",
      "                                                                                                                                 46.0,\n",
      "                                                                                                                                 47.0,\n",
      "                                                                                                                                 48.0,\n",
      "                                                                                                                                 49.0,\n",
      "                                                                                                                                 50.0,\n",
      "                                                                                                                                 51.0,\n",
      "                                                                                                                                 52.0,\n",
      "                                                                                                                                 54.0,\n",
      "                                                                                                                                 55.0,\n",
      "                                                                                                                                 56.0,\n",
      "                                                                                                                                 58.0,\n",
      "                                                                                                                                 59.0,\n",
      "                                                                                                                                 60.0,\n",
      "                                                                                                                                 61.0,\n",
      "                                                                                                                                 62.0,\n",
      "                                                                                                                                 63.0,\n",
      "                                                                                                                                 64.0,\n",
      "                                                                                                                                 65.0,\n",
      "                                                                                                                                 66.0,\n",
      "                                                                                                                                 68.0,\n",
      "                                                                                                                                 69.0,\n",
      "                                                                                                                                 70.0,\n",
      "                                                                                                                                 72.0,\n",
      "                                                                                                                                 74.0,\n",
      "                                                                                                                                 75.0,\n",
      "                                                                                                                                 76.0,\n",
      "                                                                                                                                 80.0,\n",
      "                                                                                                                                 82.0,\n",
      "                                                                                                                                 84.0,\n",
      "                                                                                                                                 88.0,\n",
      "                                                                                                                                 90.0,\n",
      "                                                                                                              '95. 95 hours and more'],\n",
      "      dtype='object')\n",
      "\n",
      "============================================================\n",
      "Variable: task_laundry\n",
      "============================================================\n",
      "\n",
      "--- 2002 ---\n",
      "Index(['Always me,PL:the woman', 'Usually me,PL:the woman',\n",
      "       'About equal o both together', 'Usually my spouse,partner,PL:the man',\n",
      "       'Always my spouse,partner,PL:the man', 'Done by a third person'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2012 ---\n",
      "Index(['NAP, no partner (3 (AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3, AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)',\n",
      "       'Always me', 'Usually me', 'About equal or both together',\n",
      "       'Usually my spouse/ partner', 'Always my spouse/ partner',\n",
      "       'Is done by a third person', 'Can't choose, KR:DK,ref., NL:DK',\n",
      "       'No answer'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2022 ---\n",
      "Index(['-9. No answer; ES: Can't choose/ No answer', '-8. Can't choose',\n",
      "       '-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL',\n",
      "       '1. Always me', '2. Usually me', '3. About equal or both together',\n",
      "       '4. Usually my spouse/partner', '5. Always my spouse/partner',\n",
      "       '6. Is done by a third person'],\n",
      "      dtype='object')\n",
      "\n",
      "============================================================\n",
      "Variable: task_care_sick\n",
      "============================================================\n",
      "\n",
      "--- 2002 ---\n",
      "Index(['Always me,PL:the woman', 'Usually me,PL:the woman',\n",
      "       'About equal o both together', 'Usually my spouse,partner,PL:the man',\n",
      "       'Always my spouse,partner,PL:the man', 'Done by a third person'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2012 ---\n",
      "Index(['NAP, no partner (3 (AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)',\n",
      "       'Always me', 'Usually me', 'About equal or both together',\n",
      "       'Usually my spouse/ partner', 'Always my spouse/ partner',\n",
      "       'Is done by a third person', 'Can't choose, KR:DK,ref., NL:DK',\n",
      "       'No answer'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2022 ---\n",
      "Index(['-9. No answer; ES: Can't choose/ No answer; TW: NAP (e.g. no sick people to be cared for)',\n",
      "       '-8. Can't choose',\n",
      "       '-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL',\n",
      "       '1. Always me', '2. Usually me', '3. About equal or both together',\n",
      "       '4. Usually my spouse/partner', '5. Always my spouse/partner',\n",
      "       '6. Is done by a third person'],\n",
      "      dtype='object')\n",
      "\n",
      "============================================================\n",
      "Variable: task_grocery\n",
      "============================================================\n",
      "\n",
      "--- 2002 ---\n",
      "Index(['Always me,PL:the woman', 'Usually me,PL:the woman',\n",
      "       'About equal o both together', 'Usually my spouse,partner,PL:the man',\n",
      "       'Always my spouse,partner,PL:the man', 'Done by a third person'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2012 ---\n",
      "Index(['NAP, no partner (3 (AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)',\n",
      "       'Always me', 'Usually me', 'About equal or both together',\n",
      "       'Usually my spouse/ partner', 'Always my spouse/ partner',\n",
      "       'Is done by a third person', 'Can't choose, KR:DK,ref., NL:DK',\n",
      "       'No answer'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2022 ---\n",
      "Index(['-9. No answer; ES: Can't choose/ No answer', '-8. Can't choose',\n",
      "       '-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL',\n",
      "       '1. Always me', '2. Usually me', '3. About equal or both together',\n",
      "       '4. Usually my spouse/partner', '5. Always my spouse/partner',\n",
      "       '6. Is done by a third person'],\n",
      "      dtype='object')\n",
      "\n",
      "============================================================\n",
      "Variable: task_cleaning\n",
      "============================================================\n",
      "\n",
      "--- 2002 ---\n",
      "Index(['Always me,PL:the woman', 'Usually me,PL:the woman',\n",
      "       'About equal o both together', 'Usually my spouse,partner,PL:the man',\n",
      "       'Always my spouse,partner,PL:the man', 'Done by a third person'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2012 ---\n",
      "Index(['NAP, no partner (3 (AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)',\n",
      "       'Always me', 'Usually me', 'About equal or both together',\n",
      "       'Usually my spouse/ partner', 'Always my spouse/ partner',\n",
      "       'Is done by a third person', 'Can't choose, KR:DK,ref., NL:DK',\n",
      "       'No answer'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2022 ---\n",
      "Index(['-9. No answer; ES: Can't choose/ No answer', '-8. Can't choose',\n",
      "       '-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL',\n",
      "       '1. Always me', '2. Usually me', '3. About equal or both together',\n",
      "       '4. Usually my spouse/partner', '5. Always my spouse/partner',\n",
      "       '6. Is done by a third person'],\n",
      "      dtype='object')\n",
      "\n",
      "============================================================\n",
      "Variable: task_meals\n",
      "============================================================\n",
      "\n",
      "--- 2002 ---\n",
      "Index(['Always me,PL:the woman', 'Usually me,PL:the woman',\n",
      "       'About equal o both together', 'Usually my spouse,partner,PL:the man',\n",
      "       'Always my spouse,partner,PL:the man', 'Done by a third person'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2012 ---\n",
      "Index(['NAP, no partner (3 (AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)',\n",
      "       'Always me', 'Usually me', 'About equal or both together',\n",
      "       'Usually my spouse/ partner', 'Always my spouse/ partner',\n",
      "       'Is done by a third person', 'Can't choose, KR:DK,ref., NL:DK',\n",
      "       'No answer'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2022 ---\n",
      "Index(['-9. No answer; ES: Can't choose/ No answer; TW: NAP (e.g. never have meals together at home)',\n",
      "       '-8. Can't choose',\n",
      "       '-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL',\n",
      "       '1. Always me', '2. Usually me', '3. About equal or both together',\n",
      "       '4. Usually my spouse/partner', '5. Always my spouse/partner',\n",
      "       '6. Is done by a third person'],\n",
      "      dtype='object')\n",
      "\n",
      "============================================================\n",
      "Variable: task_fairness\n",
      "============================================================\n",
      "\n",
      "--- 2002 ---\n",
      "Index(['I do much more than my fair share',\n",
      "       'I do a bit more than my fair share', 'I do roughly my fair share',\n",
      "       'I do a bit less than my fair share',\n",
      "       'I do much less than my fair share', 'PH: None of above'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2012 ---\n",
      "Index(['NAP, no partner (3 (AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)',\n",
      "       'I do much more than my fair share',\n",
      "       'I do a bit more than my fair share', 'I do roughly my fair share',\n",
      "       'I do a bit less than my fair share',\n",
      "       'I do much less than my fair share',\n",
      "       'Don't know, BG: can't choose, KR: don't know, refused', 'No answer'],\n",
      "      dtype='object')\n",
      "\n",
      "--- 2022 ---\n",
      "Index(['-9. No answer; AT, ES, HU, SI: Can't Ch/NA; IS: NA/DK; LT: NA/DK/Hard to say; PL: Hard to say/NA',\n",
      "       '-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL',\n",
      "       '1. I do much more than my fair share',\n",
      "       '2. I do a bit more than my fair share',\n",
      "       '3. I do roughly my fair share',\n",
      "       '4. I do a bit less than my fair share',\n",
      "       '5. I do much less than my fair share'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Map original variable names to new mnemonic names across years\n",
    "variable_mapping = {\n",
    "    'hh_hrs_resp': {\n",
    "        2002: 'v36',\n",
    "        2012: 'V37',  # Fixed: uppercase V\n",
    "        2022: 'v34'\n",
    "    },\n",
    "    'hh_hrs_partner': {\n",
    "        2002: 'v37',\n",
    "        2012: 'V39',  # Fixed: uppercase V\n",
    "        2022: 'v36'\n",
    "    },\n",
    "    'task_laundry': {\n",
    "        2002: 'v30',\n",
    "        2012: 'V42',  # Fixed: uppercase V\n",
    "        2022: 'v39'\n",
    "    },\n",
    "    'task_care_sick': {\n",
    "        2002: 'v32',\n",
    "        2012: 'V44',  # Fixed: uppercase V\n",
    "        2022: 'v41'\n",
    "    },\n",
    "    'task_grocery': {\n",
    "        2002: 'v33',\n",
    "        2012: 'V45',  # Fixed: uppercase V\n",
    "        2022: 'v42'\n",
    "    },\n",
    "    'task_cleaning': {\n",
    "        2002: 'v34',\n",
    "        2012: 'V46',  # Fixed: uppercase V\n",
    "        2022: 'v43'\n",
    "    },\n",
    "    'task_meals': {\n",
    "        2002: 'v35',\n",
    "        2012: 'V47',  # Fixed: uppercase V\n",
    "        2022: 'v44'\n",
    "    },\n",
    "    'task_fairness': {\n",
    "        2002: 'v38',\n",
    "        2012: 'V48',  # Fixed: uppercase V\n",
    "        2022: 'v45'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add variables to clean dataframes with new names\n",
    "year_mapping = {\n",
    "    2002: (df_2002, df_2002_clean),\n",
    "    2012: (df_2012, df_2012_clean),\n",
    "    2022: (df_2022, df_2022_clean)\n",
    "}\n",
    "\n",
    "for new_name, year_vars in variable_mapping.items():\n",
    "    for year, old_name in year_vars.items():\n",
    "        source_df, target_df = year_mapping[year]\n",
    "        if old_name in source_df.columns:\n",
    "            target_df[new_name] = source_df[old_name]\n",
    "\n",
    "# Print categories for each variable across years\n",
    "for new_name in variable_mapping.keys():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Variable: {new_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for year in [2002, 2012, 2022]:\n",
    "        print(f\"\\n--- {year} ---\")\n",
    "        target_df = year_mapping[year][1]\n",
    "        if new_name in target_df.columns:\n",
    "            cats = target_df[new_name].dropna().unique()\n",
    "            if hasattr(target_df[new_name], 'cat'):\n",
    "                print(target_df[new_name].cat.categories)\n",
    "            else:\n",
    "                print(f\"Unique values (sample): {sorted(cats)[:10]}\")\n",
    "        else:\n",
    "            print(\"Variable not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a33a3e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned household hours variables\n",
      "\n",
      "2002 hh_hrs_resp range: 1 - 0\n",
      "2012 hh_hrs_resp range: 0.0 - 95.0\n",
      "2022 hh_hrs_resp range: 0.0 - 95.0\n",
      "\n",
      "\n",
      "Cleaned task division variables\n",
      "\n",
      "Task division categories (now uniform across all years):\n",
      "\n",
      "task_laundry:\n",
      "2002: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "2012: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "2022: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "  Value counts 2002: {'Always respondent': 11121, 'Usually respondent': 4264, 'About equal/both equally': 3475, 'Usually spouse/partner': 4589, 'Always spouse/partner': 5840, 'Third person': 860, 'NAP': 0}\n",
      "  Value counts 2012: {'Always respondent': 12763, 'Usually respondent': 5475, 'About equal/both equally': 4817, 'Usually spouse/partner': 6522, 'Always spouse/partner': 8008, 'Third person': 1370, 'NAP': 22799}\n",
      "  Value counts 2022: {'Always respondent': 7135, 'Usually respondent': 5191, 'About equal/both equally': 4909, 'Usually spouse/partner': 4835, 'Always spouse/partner': 4803, 'Third person': 431, 'NAP': 18458}\n",
      "\n",
      "task_care_sick:\n",
      "2002: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "2012: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "2022: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "  Value counts 2002: {'Always respondent': 5440, 'Usually respondent': 4339, 'About equal/both equally': 11949, 'Usually spouse/partner': 3334, 'Always spouse/partner': 2095, 'Third person': 635, 'NAP': 0}\n",
      "  Value counts 2012: {'Always respondent': 5731, 'Usually respondent': 5637, 'About equal/both equally': 13674, 'Usually spouse/partner': 4557, 'Always spouse/partner': 2860, 'Third person': 1247, 'NAP': 28048}\n",
      "  Value counts 2022: {'Always respondent': 2705, 'Usually respondent': 4491, 'About equal/both equally': 10970, 'Usually spouse/partner': 3196, 'Always spouse/partner': 1273, 'Third person': 734, 'NAP': 22393}\n",
      "\n",
      "task_grocery:\n",
      "2002: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "2012: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "2022: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "  Value counts 2002: {'Always respondent': 6024, 'Usually respondent': 4978, 'About equal/both equally': 11734, 'Usually spouse/partner': 4316, 'Always spouse/partner': 2595, 'Third person': 455, 'NAP': 0}\n",
      "  Value counts 2012: {'Always respondent': 6796, 'Usually respondent': 6704, 'About equal/both equally': 14989, 'Usually spouse/partner': 5850, 'Always spouse/partner': 3792, 'Third person': 894, 'NAP': 22729}\n",
      "  Value counts 2022: {'Always respondent': 3505, 'Usually respondent': 5927, 'About equal/both equally': 11238, 'Usually spouse/partner': 4660, 'Always spouse/partner': 1698, 'Third person': 252, 'NAP': 18482}\n",
      "\n",
      "task_cleaning:\n",
      "2002: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "2012: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "2022: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "  Value counts 2002: {'Always respondent': 7496, 'Usually respondent': 5364, 'About equal/both equally': 7360, 'Usually spouse/partner': 4699, 'Always spouse/partner': 3580, 'Third person': 1598, 'NAP': 0}\n",
      "  Value counts 2012: {'Always respondent': 8792, 'Usually respondent': 7060, 'About equal/both equally': 8918, 'Usually spouse/partner': 7053, 'Always spouse/partner': 5048, 'Third person': 2125, 'NAP': 22758}\n",
      "  Value counts 2022: {'Always respondent': 4287, 'Usually respondent': 6120, 'About equal/both equally': 8279, 'Usually spouse/partner': 5166, 'Always spouse/partner': 2247, 'Third person': 1169, 'NAP': 18494}\n",
      "\n",
      "task_meals:\n",
      "2002: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "2012: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "2022: ['Always respondent', 'Usually respondent', 'About equal/both equally', 'Usually spouse/partner', 'Always spouse/partner', 'Third person', 'NAP']\n",
      "  Value counts 2002: {'Always respondent': 8380, 'Usually respondent': 5529, 'About equal/both equally': 5981, 'Usually spouse/partner': 5125, 'Always spouse/partner': 4327, 'Third person': 768, 'NAP': 0}\n",
      "  Value counts 2012: {'Always respondent': 9935, 'Usually respondent': 7238, 'About equal/both equally': 7564, 'Usually spouse/partner': 7258, 'Always spouse/partner': 5999, 'Third person': 1043, 'NAP': 22717}\n",
      "  Value counts 2022: {'Always respondent': 5137, 'Usually respondent': 6402, 'About equal/both equally': 6598, 'Usually spouse/partner': 5635, 'Always spouse/partner': 3154, 'Third person': 340, 'NAP': 18496}\n",
      "\n",
      "\n",
      "Cleaned task fairness variable\n",
      "\n",
      "task_fairness categories:\n",
      "2002: ['Fair share', 'Much more than fair share', 'A bit more than fair share', 'A bit less than fair share', 'Much less than fair share']\n",
      "2012: ['Fair share', 'Much more than fair share', 'A bit more than fair share', 'A bit less than fair share', 'Much less than fair share']\n",
      "2022: ['Fair share', 'A bit more than fair share', 'Much more than fair share', 'A bit less than fair share', 'Much less than fair share']\n",
      "\n",
      "\n",
      " All variables cleaned and standardized!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ==================== CLEANING HOUSEHOLD HOURS VARIABLES ====================\n",
    "def clean_hours(val):\n",
    "    \"\"\"\n",
    "    Convert household hours to numeric, handling various text formats.\n",
    "    Returns None for missing/invalid values.\n",
    "    \"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle explicit missing values\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', 'dk', 'na', 'hard to say', \"can't choose\"]):\n",
    "        return None\n",
    "    \n",
    "    # Handle \"none, no hours\"\n",
    "    if 'none' in val_str or 'no hour' in val_str:\n",
    "        return 0\n",
    "    \n",
    "    # Extract numeric value\n",
    "    # Handle ranges like \"95 hours and more\"  95\n",
    "    if '95' in val_str or '96+' in val_str or '98+' in val_str:\n",
    "        return 95\n",
    "    \n",
    "    # Extract first number found\n",
    "    match = re.search(r'\\d+', val_str)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Apply to household hours variables\n",
    "for df in [df_2002_clean, df_2012_clean, df_2022_clean]:\n",
    "    df['hh_hrs_resp'] = df['hh_hrs_resp'].apply(clean_hours)\n",
    "    df['hh_hrs_partner'] = df['hh_hrs_partner'].apply(clean_hours)\n",
    "\n",
    "print(\"Cleaned household hours variables\")\n",
    "print(\"\\n2002 hh_hrs_resp range:\", df_2002_clean['hh_hrs_resp'].min(), \"-\", df_2002_clean['hh_hrs_resp'].max())\n",
    "print(\"2012 hh_hrs_resp range:\", df_2012_clean['hh_hrs_resp'].min(), \"-\", df_2012_clean['hh_hrs_resp'].max())\n",
    "print(\"2022 hh_hrs_resp range:\", df_2022_clean['hh_hrs_resp'].min(), \"-\", df_2022_clean['hh_hrs_resp'].max())\n",
    "\n",
    "\n",
    "# ==================== CLEANING TASK DIVISION VARIABLES ====================\n",
    "# Standard categories for task division (ordered from most respondent to most partner)\n",
    "TASK_CATEGORIES_ORDER = [\n",
    "    \"Always respondent\",\n",
    "    \"Usually respondent\", \n",
    "    \"About equal/both equally\",\n",
    "    \"Usually spouse/partner\",\n",
    "    \"Always spouse/partner\",\n",
    "    \"Third person\",\n",
    "    \"NAP\"\n",
    "]\n",
    "\n",
    "def clean_task_division(val):\n",
    "    \"\"\"\n",
    "    Standardize task division categories across years.\n",
    "    Returns standardized category string.\n",
    "    \"\"\"\n",
    "    if pd.isna(val):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing/refused/not applicable\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', 'not applicable']):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    # Check for NAP first (case-sensitive check for category name)\n",
    "    if val_str == 'nap':\n",
    "        return \"NAP\"\n",
    "    \n",
    "    # Third person (check before \"always\" patterns)\n",
    "    if 'third person' in val_str or 'someone else' in val_str or 'other' in val_str:\n",
    "        return \"Third person\"\n",
    "    \n",
    "    # Always respondent\n",
    "    if ('always' in val_str and ('me' in val_str or 'i do' in val_str or 'respondent' in val_str)) or \\\n",
    "       val_str in ['always me', 'always i', 'always respondent']:\n",
    "        return \"Always respondent\"\n",
    "    \n",
    "    # Always partner\n",
    "    if ('always' in val_str and ('partner' in val_str or 'spouse' in val_str)) or \\\n",
    "       val_str in ['always spouse/partner', 'always partner', 'always spouse']:\n",
    "        return \"Always spouse/partner\"\n",
    "    \n",
    "    # Usually respondent\n",
    "    if ('usually' in val_str and ('me' in val_str or 'i do' in val_str or 'respondent' in val_str)) or \\\n",
    "       val_str in ['usually me', 'usually i', 'usually respondent']:\n",
    "        return \"Usually respondent\"\n",
    "    \n",
    "    # Usually partner\n",
    "    if ('usually' in val_str and ('partner' in val_str or 'spouse' in val_str)) or \\\n",
    "       val_str in ['usually spouse/partner', 'usually partner', 'usually spouse']:\n",
    "        return \"Usually spouse/partner\"\n",
    "    \n",
    "    # About equal (check after specific \"usually\" patterns)\n",
    "    if 'about equal' in val_str or 'both equal' in val_str or 'shared equal' in val_str or \\\n",
    "       val_str in ['about equal/both equally', 'shared equally', 'both do equally']:\n",
    "        return \"About equal/both equally\"\n",
    "    \n",
    "    # If nothing matches, return NAP\n",
    "    return \"NAP\"\n",
    "\n",
    "# Apply to task division variables and convert to ordered categorical\n",
    "task_vars = ['task_laundry', 'task_care_sick', 'task_grocery', 'task_cleaning', 'task_meals']\n",
    "\n",
    "for df in [df_2002_clean, df_2012_clean, df_2022_clean]:\n",
    "    for task in task_vars:\n",
    "        # Apply cleaning function\n",
    "        df[task] = df[task].apply(clean_task_division)\n",
    "        # Convert to ordered categorical with consistent categories\n",
    "        df[task] = pd.Categorical(df[task], categories=TASK_CATEGORIES_ORDER, ordered=True)\n",
    "\n",
    "print(\"\\n\\nCleaned task division variables\")\n",
    "print(\"\\nTask division categories (now uniform across all years):\")\n",
    "for task in task_vars:\n",
    "    print(f\"\\n{task}:\")\n",
    "    print(\"2002:\", df_2002_clean[task].cat.categories.tolist())\n",
    "    print(\"2012:\", df_2012_clean[task].cat.categories.tolist())\n",
    "    print(\"2022:\", df_2022_clean[task].cat.categories.tolist())\n",
    "    print(\"  Value counts 2002:\", df_2002_clean[task].value_counts(sort=False).to_dict())\n",
    "    print(\"  Value counts 2012:\", df_2012_clean[task].value_counts(sort=False).to_dict())\n",
    "    print(\"  Value counts 2022:\", df_2022_clean[task].value_counts(sort=False).to_dict())\n",
    "\n",
    "\n",
    "# ==================== CLEANING TASK FAIRNESS VARIABLE ====================\n",
    "FAIRNESS_CATEGORIES_ORDER = [\n",
    "    \"Much more than fair share\",\n",
    "    \"A bit more than fair share\",\n",
    "    \"Fair share\",\n",
    "    \"A bit less than fair share\",\n",
    "    \"Much less than fair share\"\n",
    "]\n",
    "\n",
    "def clean_task_fairness(val):\n",
    "    \"\"\"\n",
    "    Standardize task fairness perception categories.\n",
    "    \"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing/refused\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', 'nap']):\n",
    "        return None\n",
    "    \n",
    "    # Map variations to standard categories\n",
    "    if 'much more' in val_str or 'far more' in val_str:\n",
    "        return \"Much more than fair share\"\n",
    "    \n",
    "    if ('more' in val_str or 'bit more' in val_str) and 'much' not in val_str:\n",
    "        return \"A bit more than fair share\"\n",
    "    \n",
    "    if 'fair share' in val_str and 'more' not in val_str and 'less' not in val_str:\n",
    "        return \"Fair share\"\n",
    "    \n",
    "    if ('less' in val_str or 'bit less' in val_str) and 'much' not in val_str:\n",
    "        return \"A bit less than fair share\"\n",
    "    \n",
    "    if 'much less' in val_str or 'far less' in val_str:\n",
    "        return \"Much less than fair share\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Apply to task fairness\n",
    "for df in [df_2002_clean, df_2012_clean, df_2022_clean]:\n",
    "    df['task_fairness'] = df['task_fairness'].apply(clean_task_fairness)\n",
    "\n",
    "print(\"\\n\\nCleaned task fairness variable\")\n",
    "print(\"\\ntask_fairness categories:\")\n",
    "print(\"2002:\", df_2002_clean['task_fairness'].value_counts().index.tolist())\n",
    "print(\"2012:\", df_2012_clean['task_fairness'].value_counts().index.tolist())\n",
    "print(\"2022:\", df_2022_clean['task_fairness'].value_counts().index.tolist())\n",
    "\n",
    "print(\"\\n\\n All variables cleaned and standardized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "215ab9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapping = pd.read_csv(\"../common_question_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "820ae90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urban_rural\n",
      "spouse_work_status\n",
      "sex\n",
      "code_higher_income\n",
      "code_income_control\n",
      "hh_wrk_hrs\n",
      "work_status\n",
      "marital\n",
      "wrk_hrs\n",
      "highest_education\n",
      "age\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_mapping.iterrows():\n",
    "    if row[\"COMMON_VAR\"] in df_2022_clean.columns:\n",
    "        print(row[\"COMMON_VAR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "64b121b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Variable names standardized:\n",
      "  - var_02 (2002): lowercase 'v'\n",
      "  - var_12 (2012): uppercase 'V'\n",
      "  - var_22 (2022): lowercase 'v'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for index, row in df_mapping.iterrows():\n",
    "    # Fix var_02: should start with lowercase \"v\"\n",
    "    if row[\"COMMON_VAR\"] not in df_2022_clean.columns:\n",
    "        if pd.notna(row[\"var_02\"]) and isinstance(row[\"var_02\"], str):\n",
    "            if re.match(r'^V\\d', row[\"var_02\"]):\n",
    "                df_mapping.at[index, \"var_02\"] = 'v' + row[\"var_02\"][1:]\n",
    "        \n",
    "        # Fix var_12: should start with uppercase \"V\"\n",
    "        if pd.notna(row[\"var_12\"]) and isinstance(row[\"var_12\"], str):\n",
    "            if re.match(r'^v\\d', row[\"var_12\"]):\n",
    "                df_mapping.at[index, \"var_12\"] = 'V' + row[\"var_12\"][1:]\n",
    "        \n",
    "        # Fix var_22: should start with lowercase \"v\"\n",
    "        if pd.notna(row[\"var_22\"]) and isinstance(row[\"var_22\"], str):\n",
    "            if re.match(r'^V\\d', row[\"var_22\"]):\n",
    "                df_mapping.at[index, \"var_22\"] = 'v' + row[\"var_22\"][1:]\n",
    "\n",
    "print(\" Variable names standardized:\")\n",
    "print(\"  - var_02 (2002): lowercase 'v'\")\n",
    "print(\"  - var_12 (2012): uppercase 'V'\")\n",
    "print(\"  - var_22 (2022): lowercase 'v'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8b2f5f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Added 47 common variables to all clean dataframes\n",
      "  2002: (46638, 69)\n",
      "  2012: (61754, 69)\n",
      "  2022: (45762, 69)\n"
     ]
    }
   ],
   "source": [
    "# Add common variables to clean dataframes from raw dataframes\n",
    "# Ensure all COMMON_VAR columns exist in all dataframes for consistency\n",
    "for index, row in df_mapping.iterrows():\n",
    "    common_var = row[\"COMMON_VAR\"]\n",
    "    \n",
    "    # 2002\n",
    "    if pd.notna(row[\"var_02\"]) and row[\"var_02\"] in df_2002.columns:\n",
    "        df_2002_clean[common_var] = df_2002[row[\"var_02\"]].values\n",
    "    else:\n",
    "        # Create column with NaN if variable doesn't exist for this year\n",
    "        if common_var not in df_2002_clean.columns:\n",
    "            df_2002_clean[common_var] = np.nan\n",
    "    \n",
    "    # 2012\n",
    "    if pd.notna(row[\"var_12\"]) and row[\"var_12\"] in df_2012.columns:\n",
    "        df_2012_clean[common_var] = df_2012[row[\"var_12\"]].values\n",
    "    else:\n",
    "        # Create column with NaN if variable doesn't exist for this year\n",
    "        if common_var not in df_2012_clean.columns:\n",
    "            df_2012_clean[common_var] = np.nan\n",
    "    \n",
    "    # 2022\n",
    "    if pd.notna(row[\"var_22\"]) and row[\"var_22\"] in df_2022.columns:\n",
    "        df_2022_clean[common_var] = df_2022[row[\"var_22\"]].values\n",
    "    else:\n",
    "        # Create column with NaN if variable doesn't exist for this year\n",
    "        if common_var not in df_2022_clean.columns:\n",
    "            df_2022_clean[common_var] = np.nan\n",
    "\n",
    "print(f\" Added {len(df_mapping)} common variables to all clean dataframes\")\n",
    "print(f\"  2002: {df_2002_clean.shape}\")\n",
    "print(f\"  2012: {df_2012_clean.shape}\")\n",
    "print(f\"  2022: {df_2022_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0225a92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved clean dataframes to ../clean_csv/\n"
     ]
    }
   ],
   "source": [
    "df_2002_clean.to_csv(\"../clean_csv/2002_clean.csv\", index=False)\n",
    "df_2012_clean.to_csv(\"../clean_csv/2012_clean.csv\", index=False)\n",
    "df_2022_clean.to_csv(\"../clean_csv/2022_clean.csv\", index=False)\n",
    "\n",
    "print(\" Saved clean dataframes to ../clean_csv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1fb8d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022: (45762, 69)\n",
      "2012: (61754, 69)\n",
      "2002: (46638, 69)\n"
     ]
    }
   ],
   "source": [
    "# Read the saved clean CSVs\n",
    "\n",
    "df_2002_clean = pd.read_csv(\"../clean_csv/2002_clean.csv\")\n",
    "print(f\"2022: {df_2022_clean.shape}\")\n",
    "\n",
    "df_2012_clean = pd.read_csv(\"../clean_csv/2012_clean.csv\")\n",
    "print(f\"2012: {df_2012_clean.shape}\")\n",
    "\n",
    "df_2022_clean = pd.read_csv(\"../clean_csv/2022_clean.csv\")\n",
    "print(f\"2002: {df_2002_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8021b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_vars = [\n",
    "    \"urban_rural\",\n",
    "    \"spouse_work_status\",\n",
    "    \"sex\",\n",
    "    \"code_higher_income\",\n",
    "    \"code_income_control\",\n",
    "    \"hh_wrk_hrs\",\n",
    "    \"work_status\",\n",
    "    \"marital\",\n",
    "    \"wrk_hrs\",\n",
    "    \"highest_education\",\n",
    "    \"age\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8c1df537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== TOPBOT ====================\n",
      "==================== df_2002_clean ====================\n",
      "['5.0' '8.0' '6.0' '4.0' '7.0' nan '3.0' 'Lowest' '2.0' '9.0' 'Highest']\n",
      "==================== df_2012_clean ====================\n",
      "['05' '07' '08' '03' '06' '04' 'Lowest, Bottom, 01' \"Don't know\" '02'\n",
      " 'Highest, Top, 10' '09' 'No answer' 'Refused' 'Not available: GB,US']\n",
      "==================== df_2022_clean ====================\n",
      "['4. 04' '1. Lowest, Bottom, 01' '8. 08' '5. 05' '7. 07' '6. 06'\n",
      " \"-8. Don't know\" '10. Highest, Top, 10' '9. 09' '2. 02' '3. 03'\n",
      " '-9. No answer' '-1. CZ: Not available']\n",
      "==================== SPWRKHRS ====================\n",
      "==================== df_2002_clean ====================\n",
      "[nan '40 hours' '37.0' '10 hours' '45.0' '20 hours' '12.0' '55.0' '38.0'\n",
      " '30 hours' '42.0' '48.0' '50 hours' '58.0' '44.0' '25.0' '19.0' '60.0'\n",
      " '28.0' '35.0' '39.0' '8.0' '15 hours' '22.0' '43.0' '3.0' '16.0' '72.0'\n",
      " '80.0' '24.0' '70.0' '65.0' '96 hours and more' '41.0' '11.0' '18.0'\n",
      " '17.0' '56.0' '4.0' '6.0' '36.0' '34.0' '75.0' '46.0' '54.0' '90.0'\n",
      " '32.0' '47.0' '2 hours' '33.0' '26.0' '52.0' '64.0' '13.0' '27.0' '23.0'\n",
      " '21.0' '84.0' '53.0' '66.0' '51.0' '29.0' '14.0' '49.0' '57.0' '63.0'\n",
      " '85.0' '67.0' '5 hours' '31.0' '61.0' '7.0' '76.0' '71.0' '9.0' '1 hour'\n",
      " '77.0' '68.0' '86.0' '62.0' '78.0' '95.0' '91.0' '82.0' '69.0' '88.0'\n",
      " '89.0' '74.0' '92.0' '94.0']\n",
      "==================== df_2012_clean ====================\n",
      "['50' '64' 'NAP (code 0,2,3 (AR,VE: 0,3) in SPWORK); not available: BG,GB'\n",
      " '20' '48' '30' '60' '25' '12' '24' '82' '44' '96 hours or more' '40' '28'\n",
      " \"Don't know\" '75' '45' '54' '70' '35' '42' '73' '56' '55' '43' '33' '49'\n",
      " '36' '72' '80' '5' '63' '84' '65' '10' '47' '46' '66' '78' '51' '18' '8'\n",
      " '37' 'No answer' '41' '90' '15' '16' '38' '26' '14' '9' '39' '4' '2' '22'\n",
      " '23' '53' '93' '19' '32' '3' '6' '13' '21' '34' '11' '7' '52' '58' '94'\n",
      " '91' '77' '67' '57' '62' '59' '85' '68' 'Refused; TW: time varies' '76'\n",
      " '74' '88' '69' '81' '27' '61' '31' '29' '17' '87' '95' 'One hour' '86'\n",
      " '79' '71' '89']\n",
      "==================== df_2022_clean ====================\n",
      "['-4. NAP (code -4, 2 or 3 in SPWORK)' '40' '45' '50' '65' '-9. No answer'\n",
      " '39' '26' '37' '20' '47' '44' '15' '60' '30' '80' '35' '38' '25' '54'\n",
      " '55' '42' '32' '33' '75' '36' '28' '34' '52' '41' '22' '18' '46' '10'\n",
      " '43' '24' '27' '53' '70' '23' '16' '48' '14' '21' '64' '84' '8' '56' '72'\n",
      " '5' '96. 96 hours or more' '12' '3' '17' '6' '4' '9' '2' '11' '13' '31'\n",
      " '1. One hour' '58' '29' '62' '77' '7' '66' '90' '19' '69' '91'\n",
      " \"-8. Don't know\" '68' '57' '89. 89 hours; US: 89 or more hours' '85' '63'\n",
      " '49' '59' '51' '78' '-6. IL: Invalid answers' '74' '95' '92' '76' '87'\n",
      " '61']\n",
      "==================== C_ALPHAN ====================\n",
      "==================== df_2002_clean ====================\n",
      "['AU' 'DE-W' 'DE-E' 'GB-GBN' 'GB-NIR' 'US' 'AT' 'HU' 'IE' 'NL' 'NO' 'SE'\n",
      " 'CZ' 'SI' 'PL' 'BG' 'RU' 'NZ' 'PH' 'IL' 'JP' 'ES' 'LV' 'SK' 'FR' 'CY'\n",
      " 'PT' 'CL' 'DK' 'CH' 'BE-FLA' 'BR' 'FI' 'MX' 'TW']\n",
      "==================== df_2012_clean ====================\n",
      "['AR' 'AU' 'AT' 'BG' 'CA' 'CL' 'CN' 'TW' 'HR' 'CZ' 'DK' 'FI' 'FR' 'HU'\n",
      " 'IS' 'IN' 'IE' 'IL' 'JP' 'KR' 'LV' 'LT' 'MX' 'NL' 'NO' 'PH' 'PL' 'RU'\n",
      " 'SK' 'SI' 'ZA' 'ES' 'SE' 'CH' 'TR' 'US' 'VE' 'BE' 'DE' 'PT' 'GB-GBN']\n",
      "==================== df_2022_clean ====================\n",
      "['AT' 'AU' 'BG' 'CH' 'CZ' 'DE' 'DK' 'ES' 'FI' 'FR' 'GR' 'HR' 'HU' 'IL'\n",
      " 'IN' 'IS' 'IT' 'JP' 'LT' 'NL' 'NO' 'NZ' 'PH' 'PL' 'RU' 'SE' 'SI' 'SK'\n",
      " 'TH' 'TW' 'US' 'ZA']\n",
      "==================== LIVWOMAR ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Neither agree nor disagree' 'Agree' 'Disagree' 'Strongly disagree'\n",
      " 'Strongly agree' nan]\n",
      "==================== df_2012_clean ====================\n",
      "['Agree' 'Disagree' 'Neither agree nor disagree' 'Strongly agree'\n",
      " 'Strongly disagree' \"Can't choose, CA:+NA, KR:DK,ref., NL:DK\" 'No answer'\n",
      " 'NAP: ES']\n",
      "==================== df_2022_clean ====================\n",
      "['1. Strongly agree' '2. Agree' '3. Neither agree nor disagree'\n",
      " \"-8. Can't choose\" '5. Strongly disagree' '4. Disagree' '-9. No answer']\n",
      "==================== WWYKS ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Work part-time' 'Work full-time' 'Stay at home' nan\n",
      " 'TW:women shld decide']\n",
      "==================== df_2012_clean ====================\n",
      "['Work part-time' 'Stay at home' 'Work full-time'\n",
      " \"Can't choose, CA:+NA, KR:DK,ref., NL:DK\" 'No answer'\n",
      " 'TW: women should decide']\n",
      "==================== df_2022_clean ====================\n",
      "['1. Work full-time' '2. Work part-time' '3. Stay at home'\n",
      " \"-8. Can't choose\" '-9. No answer; PL: Refused'\n",
      " '4. TW: Women should decide']\n",
      "==================== WWYKUS ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Stay at home' 'Work full-time' 'Work part-time' nan\n",
      " 'TW:women shld decide']\n",
      "==================== df_2012_clean ====================\n",
      "['Stay at home' 'Work part-time' 'Work full-time'\n",
      " \"Can't choose, CA:+NA, KR:DK,ref., NL:DK\" 'No answer'\n",
      " 'TW: women should decide']\n",
      "==================== df_2022_clean ====================\n",
      "['1. Work full-time' '2. Work part-time' '3. Stay at home'\n",
      " \"-8. Can't choose\" '-9. No answer; PL: Refused'\n",
      " '4. TW: Women should decide']\n",
      "==================== SP_DEGREE ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Lowest formal qualification' nan 'Above higher secondary level'\n",
      " 'Higher secondary completed' 'Above lowest qualification'\n",
      " 'University degree completed' 'No formal qualification']\n",
      "==================== df_2012_clean ====================\n",
      "['Lower level tertiary, first stage (also technical schools at a tertiary level)'\n",
      " 'No formal education'\n",
      " 'NAP, no partner (code 3 (AR,CZ,PT: 3,7; IS: 3,7,9) in PARTLIV; TW,US: 3-6 in MARITAL)'\n",
      " 'Primary school'\n",
      " 'Upper secondary (programs that allow entry to university'\n",
      " 'Upper level tertiary (Master, Dr.)' \"No answer, don't know, refused\"\n",
      " 'Lower secondary (secondary completed does not allow entry to university: obligatory school)'\n",
      " 'Post secondary, non-tertiary (other upper secondary programs toward labour market or technical formation)'\n",
      " 'Not available: AT,BG,CL,GB,IE,IL,LV,NO,PH,RU,ZA']\n",
      "==================== df_2022_clean ====================\n",
      "[\"-4. NAP (c. 3,-7 PARTLIV; IT, RU: c. 2,3,-7 PARTLIV; AT: c. 3-6 MARITAL); NO: sep. instruction 'If no partner, skip question\"\n",
      " '4. Post secondary, non-tertiary' '8. PhD, Post tertiary specialization'\n",
      " '5. Short-cycle tertiary' '3. Upper secondary'\n",
      " '7. Upper level tertiary, MA'\n",
      " '-9. No answer, not classifiable; AT, ES, TW: DK/NA; CH: DK/ not codable; PL: Hard to say/NA'\n",
      " '2. Lower secondary' '6. Lower level tertiary, BA' '1. Primary education'\n",
      " '0. No (formal) education, incomplete primary'\n",
      " '-1. DK, NZ, ZA: Not available']\n",
      "==================== MOMORFAF ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Neither agree nor disagree' 'Strongly agree' 'Agree' 'Strongly disagree'\n",
      " 'Disagree' nan]\n",
      "==================== df_2012_clean ====================\n",
      "[nan]\n",
      "==================== df_2022_clean ====================\n",
      "['3. Mothers and fathers are equally suited'\n",
      " '2. Mothers are somewhat better suited'\n",
      " '1. Mothers are much better suited' \"-8. Can't choose\"\n",
      " '4. Fathers are somewhat better suited'\n",
      " '5. Fathers are much better suited' '-9. No answer']\n",
      "==================== MEWH ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Neither agree nor disagree' 'Strongly disagree' 'Disagree' 'Agree'\n",
      " 'Strongly agree' nan]\n",
      "==================== df_2012_clean ====================\n",
      "['Agree' 'Disagree' 'Neither agree nor disagree' 'Strongly agree'\n",
      " \"Can't choose, CA:+NA, KR:DK,ref., NL:DK\" 'Strongly disagree' 'No answer'\n",
      " 'NAP: ES']\n",
      "==================== df_2022_clean ====================\n",
      "['5. Strongly disagree' '2. Agree' '3. Neither agree nor disagree'\n",
      " '1. Strongly agree' '4. Disagree' \"-8. Can't choose\" '-9. No answer']\n",
      "==================== HHTODD ====================\n",
      "==================== df_2002_clean ====================\n",
      "[nan '1 child' '2 children' '3 children' '4 children' '5 children'\n",
      " '8 children' '6 children' '9 children' '7 children']\n",
      "==================== df_2012_clean ====================\n",
      "['No toddlers' '2 toddlers' 'One toddler' '3' 'No answer' '4' '5'\n",
      " 'Refused' '6' '7' '10 toddlers' '8' '9'\n",
      " 'NAP (Code 0 in HOMPOP); not available: TR']\n",
      "==================== df_2022_clean ====================\n",
      "['0. No children below [age of school entry]'\n",
      " '1. One child below [age of school entry]'\n",
      " '-9. No answer; AU: No answer and no children below 5'\n",
      " '2. Two children below [age of school entry]'\n",
      " '3. Three children below [age of school entry]'\n",
      " '4. Four children below [age of school entry]'\n",
      " '-4. NAP (Not a private household)'\n",
      " '5. Five children below [age of school entry]; SE: Five or more'\n",
      " '7. Seven children below [age of school entry]' '-1. NL: Not available'\n",
      " '6. Six children below [age of school entry]']\n",
      "==================== HHCHILDR ====================\n",
      "==================== df_2002_clean ====================\n",
      "[nan '2 children' '1 child' '3 children' '4 children' '5 children'\n",
      " '6 children' '8 children' '7 children' '10 children' '9 children']\n",
      "==================== df_2012_clean ====================\n",
      "['One child' 'No children' '5' '2 children' '4' '3' '7' 'No answer'\n",
      " '21 children' '18' '8' '6' 'Refused' '10' '9' '12' '15' '14' '11'\n",
      " 'NAP (Code 0 in HOMPOP); not available: TR']\n",
      "==================== df_2022_clean ====================\n",
      "['1. One child [school entry age] to 17'\n",
      " '0. No children [school entry age] to 17'\n",
      " '2. Two children [school entry age] to 17'\n",
      " '-9. No answer; AU: No answer and no children between 5 to 17'\n",
      " '3. Three children [school entry age] to 17'\n",
      " '4. Four children [school entry age] to 17'\n",
      " '5. Five children [school entry age] to 17; SE: Five or more'\n",
      " '7. Seven children [school entry age] to 17'\n",
      " '6. Six children [school entry age] to 17'\n",
      " '-4. NAP (Not a private household)'\n",
      " '9. Nine children [school entry age] to 17'\n",
      " '8. Eight children [school entry age] to 17']\n",
      "==================== HHADULT ====================\n",
      "==================== df_2002_clean ====================\n",
      "[nan '2 persons' '1 person' '3 persons' '4 persons' '5 persons'\n",
      " '6 persons' '7 persons' '12 persons' '8 persons' '9 persons' '11 persons'\n",
      " '10 persons' '13,DK:13 or more persons' '15 persons' '17 persons']\n",
      "==================== df_2012_clean ====================\n",
      "[nan]\n",
      "==================== df_2022_clean ====================\n",
      "['1. One adult (only respondent)' '4. Four adults' '2. Two adults'\n",
      " '-9. No answer' '3. Three adults' '6. Six adults'\n",
      " '5. Five adults; SE: Five or more' '8. Eight adults' '7. Seven adults'\n",
      " '9. Nine adults' '-4. NAP (Not a private household)' '11. Eleven adults'\n",
      " '15. Fifteen adults' '22. Twenty-two adults' '10. Ten adults'\n",
      " '12. Twelve adults' '14. Fourteen adults' '16. Sixteen adults'\n",
      " '0. ZA: No adult in household']\n",
      "==================== FAM_DIF ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Once or twice a year' nan 'Several times a month' 'Never'\n",
      " 'Several times a week']\n",
      "==================== df_2012_clean ====================\n",
      "['Never'\n",
      " \"Doesn't apply: no job, no family responsibilities (HR,LT,MX,PL,RU,TW,VE: 2 or 3 in WORK)\"\n",
      " 'Several times a month' 'Once or twice' 'Several times a week'\n",
      " \"Don't know, BG: can't choose, KR: don't know, refused\" 'No answer']\n",
      "==================== df_2022_clean ====================\n",
      "['1. Several times a week' '4. Never' '3. Once or twice'\n",
      " '2. Several times a month'\n",
      " \"-4. Doesn't apply/no job; TW: NAP (code 2,3,5,6,7 in MAINSTAT)\"\n",
      " '-9. No answer; LT: NA/DK/Hard to say' \"-8. DE, TW: Can't choose\"\n",
      " '-1. DK: Not available']\n",
      "==================== SHARE_HH ====================\n",
      "==================== df_2002_clean ====================\n",
      "['I do a bit more than my fair share' 'I do roughly my fair share'\n",
      " 'I do a bit less than my fair share' 'I do much more than my fair share'\n",
      " nan 'I do much less than my fair share' 'PH: None of above']\n",
      "==================== df_2012_clean ====================\n",
      "['I do roughly my fair share' 'I do much more than my fair share'\n",
      " 'NAP, no partner (3 (AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)'\n",
      " 'I do a bit more than my fair share' 'I do a bit less than my fair share'\n",
      " \"Don't know, BG: can't choose, KR: don't know, refused\"\n",
      " 'I do much less than my fair share' 'No answer']\n",
      "==================== df_2022_clean ====================\n",
      "['-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL'\n",
      " '2. I do a bit more than my fair share'\n",
      " '1. I do much more than my fair share' '3. I do roughly my fair share'\n",
      " \"-9. No answer; AT, ES, HU, SI: Can't Ch/NA; IS: NA/DK; LT: NA/DK/Hard to say; PL: Hard to say/NA\"\n",
      " '4. I do a bit less than my fair share'\n",
      " '5. I do much less than my fair share']\n",
      "==================== HW_FULFIL ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Neither agree nor disagree' 'Strongly agree' 'Agree' 'Disagree'\n",
      " 'Strongly disagree' nan]\n",
      "==================== df_2012_clean ====================\n",
      "['Disagree' 'Agree' 'Neither agree nor disagree' 'Strongly agree'\n",
      " 'Strongly disagree' \"Can't choose, CA:+NA, KR:DK,ref., NL:DK\" 'No answer'\n",
      " 'NAP: ES']\n",
      "==================== df_2022_clean ====================\n",
      "['3. Neither agree nor disagree' '1. Strongly agree'\n",
      " '5. Strongly disagree' \"-8. Can't choose\" '4. Disagree' '2. Agree'\n",
      " '-9. No answer']\n",
      "==================== WO_WANT ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Neither agree nor disagree' 'Strongly disagree' 'Disagree' 'Agree'\n",
      " 'Strongly agree' nan]\n",
      "==================== df_2012_clean ====================\n",
      "['Agree' 'Neither agree nor disagree' 'Strongly agree' 'Disagree'\n",
      " \"Can't choose, CA:+NA, KR:DK,ref., NL:DK\" 'Strongly disagree' 'No answer'\n",
      " 'NAP: ES']\n",
      "==================== df_2022_clean ====================\n",
      "['5. Strongly disagree' '2. Agree' '1. Strongly agree' '4. Disagree'\n",
      " \"-8. Can't choose\" '3. Neither agree nor disagree' '-9. No answer']\n",
      "==================== WW_FAM_SUFFER ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Agree' 'Strongly disagree' 'Strongly agree' 'Neither agree nor disagree'\n",
      " 'Disagree' nan]\n",
      "==================== df_2012_clean ====================\n",
      "['Agree' 'Strongly agree' 'Disagree' 'Neither agree nor disagree'\n",
      " 'Strongly disagree' \"Can't choose, CA:+NA, KR:DK,ref., NL:DK\" 'No answer'\n",
      " 'NAP: ES']\n",
      "==================== df_2022_clean ====================\n",
      "['5. Strongly disagree' '2. Agree' '1. Strongly agree' '4. Disagree'\n",
      " '3. Neither agree nor disagree' \"-8. Can't choose\" '-9. No answer']\n",
      "==================== WW_CHILD_SUFFER ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Agree' 'Strongly disagree' 'Neither agree nor disagree' nan\n",
      " 'Strongly agree' 'Disagree']\n",
      "==================== df_2012_clean ====================\n",
      "['Agree' 'Neither agree nor disagree' 'Strongly agree' 'Disagree'\n",
      " 'Strongly disagree' \"Can't choose, CA:+NA, KR:DK,ref., NL:DK\" 'No answer'\n",
      " 'NAP: ES']\n",
      "==================== df_2022_clean ====================\n",
      "['5. Strongly disagree' '1. Strongly agree' '2. Agree' '4. Disagree'\n",
      " '3. Neither agree nor disagree' \"-8. Can't choose\" '-9. No answer']\n",
      "==================== WW_WARM ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Disagree' 'Strongly agree' 'Agree' 'Neither agree nor disagree'\n",
      " 'Strongly disagree' nan]\n",
      "==================== df_2012_clean ====================\n",
      "['Disagree' 'Agree' 'Strongly agree' 'Neither agree nor disagree'\n",
      " 'Strongly disagree' \"Can't choose, CA:+NA, KR:DK,ref., NL:DK\" 'No answer'\n",
      " 'NAP: ES']\n",
      "==================== df_2022_clean ====================\n",
      "['1. Strongly agree' '4. Disagree' '5. Strongly disagree'\n",
      " '3. Neither agree nor disagree' \"-8. Can't choose\" '2. Agree'\n",
      " '-9. No answer']\n",
      "==================== DIV_HH_COOK ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Always me,PL:the woman' 'About equal o both together'\n",
      " 'Usually my spouse,partner,PL:the man'\n",
      " 'Always my spouse,partner,PL:the man' nan 'Usually me,PL:the woman'\n",
      " 'Done by a third person']\n",
      "==================== df_2012_clean ====================\n",
      "['About equal or both together' 'Always me'\n",
      " 'NAP, no partner (3 (AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)'\n",
      " 'Usually my spouse/ partner' 'Is done by a third person'\n",
      " 'Always my spouse/ partner' 'Usually me'\n",
      " \"Can't choose, KR:DK,ref., NL:DK\" 'No answer']\n",
      "==================== df_2022_clean ====================\n",
      "['-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL'\n",
      " '3. About equal or both together' '2. Usually me'\n",
      " '4. Usually my spouse/partner' '1. Always me'\n",
      " '5. Always my spouse/partner' \"-8. Can't choose\"\n",
      " '6. Is done by a third person'\n",
      " \"-9. No answer; ES: Can't choose/ No answer; TW: NAP (e.g. never have meals together at home)\"]\n",
      "==================== DIV_HH_CLEAN ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Usually me,PL:the woman' 'About equal o both together'\n",
      " 'Usually my spouse,partner,PL:the man' 'Always me,PL:the woman'\n",
      " 'Always my spouse,partner,PL:the man' nan 'Done by a third person']\n",
      "==================== df_2012_clean ====================\n",
      "['About equal or both together' 'Always me'\n",
      " 'NAP, no partner (3 (AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)'\n",
      " 'Usually my spouse/ partner' 'Is done by a third person'\n",
      " 'Always my spouse/ partner' 'Usually me'\n",
      " \"Can't choose, KR:DK,ref., NL:DK\" 'No answer']\n",
      "==================== df_2022_clean ====================\n",
      "['-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL'\n",
      " '2. Usually me' '3. About equal or both together'\n",
      " '6. Is done by a third person' '1. Always me'\n",
      " '4. Usually my spouse/partner' '5. Always my spouse/partner'\n",
      " \"-8. Can't choose\" \"-9. No answer; ES: Can't choose/ No answer\"]\n",
      "==================== DIV_HH_GROC ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Always me,PL:the woman' 'About equal o both together'\n",
      " 'Usually me,PL:the woman' 'Usually my spouse,partner,PL:the man' nan\n",
      " 'Always my spouse,partner,PL:the man' 'Done by a third person']\n",
      "==================== df_2012_clean ====================\n",
      "['Always me'\n",
      " 'NAP, no partner (3 (AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)'\n",
      " 'About equal or both together' 'Usually me' 'Usually my spouse/ partner'\n",
      " 'Always my spouse/ partner' 'Is done by a third person'\n",
      " \"Can't choose, KR:DK,ref., NL:DK\" 'No answer']\n",
      "==================== df_2022_clean ====================\n",
      "['-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL'\n",
      " '1. Always me' '4. Usually my spouse/partner'\n",
      " '3. About equal or both together' '2. Usually me' \"-8. Can't choose\"\n",
      " '5. Always my spouse/partner' '6. Is done by a third person'\n",
      " \"-9. No answer; ES: Can't choose/ No answer\"]\n",
      "==================== DIV_HH_CARE ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Always me,PL:the woman' 'About equal o both together'\n",
      " 'Usually my spouse,partner,PL:the man' nan 'Usually me,PL:the woman'\n",
      " 'Done by a third person' 'Always my spouse,partner,PL:the man']\n",
      "==================== df_2012_clean ====================\n",
      "['About equal or both together' 'Always me'\n",
      " 'NAP, no partner (3 (AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)'\n",
      " 'Always my spouse/ partner' \"Can't choose, KR:DK,ref., NL:DK\"\n",
      " 'Usually me' 'Usually my spouse/ partner' 'Is done by a third person'\n",
      " 'No answer']\n",
      "==================== df_2022_clean ====================\n",
      "['-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL'\n",
      " '4. Usually my spouse/partner' '1. Always me'\n",
      " '3. About equal or both together' '2. Usually me' \"-8. Can't choose\"\n",
      " '6. Is done by a third person' '5. Always my spouse/partner'\n",
      " \"-9. No answer; ES: Can't choose/ No answer; TW: NAP (e.g. no sick people to be cared for)\"]\n",
      "==================== DIV_HH_LAUND ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Always me,PL:the woman' 'About equal o both together'\n",
      " 'Always my spouse,partner,PL:the man'\n",
      " 'Usually my spouse,partner,PL:the man' nan 'Usually me,PL:the woman'\n",
      " 'Done by a third person']\n",
      "==================== df_2012_clean ====================\n",
      "['About equal or both together' 'Always me'\n",
      " 'NAP, no partner (3 (AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3, AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)'\n",
      " 'Usually my spouse/ partner' 'Always my spouse/ partner' 'Usually me'\n",
      " 'Is done by a third person' \"Can't choose, KR:DK,ref., NL:DK\" 'No answer']\n",
      "==================== df_2022_clean ====================\n",
      "['-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL'\n",
      " '2. Usually me' '1. Always me' '4. Usually my spouse/partner'\n",
      " '3. About equal or both together' '5. Always my spouse/partner'\n",
      " '6. Is done by a third person' \"-8. Can't choose\"\n",
      " \"-9. No answer; ES: Can't choose/ No answer\"]\n",
      "==================== SP_HH_FAM ====================\n",
      "==================== df_2002_clean ====================\n",
      "[nan]\n",
      "==================== df_2012_clean ====================\n",
      "['56' 'None, no hour'\n",
      " 'NAP, no partner (3 (AR,AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)'\n",
      " '84' '7' '30' '14' '28' '70' '10' '95 hours and more' '45' '50'\n",
      " 'No answer, CA: no answer, refused' '35' '80' '21' '12' '2 hours' '20'\n",
      " \"Don't know, BG: can't choose, KR: don't know, refused\" '15' '18' '38'\n",
      " '25' '22' '4' '40' '42' '8' '60' '6' '3' '24' '36' '9' '54' '5' '16' '32'\n",
      " '48' '1 hour or less than 1 hour' '44' '53' '19' '27' '68' '90' '72' '26'\n",
      " '65' '89' '49' '46' '52' '13' '55' '34' '58' '39' '17' '11' '23' '47'\n",
      " '64' '88' '31' '63' '43' '33' '74' '78' '73' '62' '37' '29' '94' '91'\n",
      " '77' '69' '41' '76' '75' '59' '83' '57' '51' '82' '85' '86' '66' '92'\n",
      " '61']\n",
      "==================== df_2022_clean ====================\n",
      "['-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL'\n",
      " '2' '20' '28' '9' '30' '3' '75' '6' '5' '0. None, no hours' '1. 1 hour'\n",
      " '7' '35' '10' '95. 95 hours and more' '50' '15' '40' '4' '21' '24' '70'\n",
      " '14' '16' '60' '12' '80' '8' '25' '23' '55' '18' '56' '36' '90' '59' '45'\n",
      " '37' '32' '41' '13' '38' '46'\n",
      " \"-9. No answer; HR, IS: DK/NA; ES, HU, TW: Can't Ch/NA; LT: NA/DK/Hard to say; PL: Hard to say/NA\"\n",
      " '22' '58' '34' '11' '44' '48' '29' '27' '84' '65' '53' '17' '64' '54'\n",
      " '85' '57' '19' '52' '39' '73' '42' '26' '72' '68' '43' '76' '49' '78'\n",
      " '61' '63' '33' '31' '62' '88' '91' '74' '77' '82' '66' '86' '47' '87'\n",
      " '79']\n",
      "==================== SP_HH ====================\n",
      "==================== df_2002_clean ====================\n",
      "['2 hrs' '5.0' '14.0' '28.0' '4.0' '24.0' '30.0' '10.0' nan '16.0' '15.0'\n",
      " '7.0' '50.0' '12.0' '56.0' '8.0' '20.0' '11.0' '18.0' '25.0' '3.0' '21.0'\n",
      " '40.0' '6.0' '35.0' 'None, no hour' '17.0' '1 hour or less than 1 hr'\n",
      " '70.0' '45.0' '60.0' '42.0' '9.0' '36.0' '54.0' '48.0' '49.0' '32.0'\n",
      " '55.0' '46.0' '26.0' '80.0' '90.0' '22.0' '19.0' '13.0' '65.0' '33.0'\n",
      " '63.0' '84.0' '44.0' '23.0' '38.0' '29.0' '34.0' '72.0'\n",
      " '95 hrs a more,US:96+,BR:98+' '64.0' '76.0' '66.0' '85.0' '27.0' '41.0'\n",
      " '75.0' '37.0' '39.0' '43.0' '58.0' '51.0' '91.0' '31.0' '59.0' '71.0'\n",
      " '52.0' '47.0' '74.0' '77.0' '93.0' '73.0' '69.0' '62.0' '68.0' '88.0']\n",
      "==================== df_2012_clean ====================\n",
      "['56' 'None, no hours'\n",
      " 'NAP, no partner (3 (AR,AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)'\n",
      " '84' '20' '40' '14' '28' '15' '16' '70' '10' '35' '36' '4' '34' '7' '5'\n",
      " '30' '12' '21' '2 hours' '3 hours'\n",
      " \"Don't know, BG: can't choose, KR: don't know, refused\"\n",
      " '1 hour or less than 1 hour' 'No answer, CA: no answer, refused' '22' '8'\n",
      " '17' '18' '25' '50' '48' '24' '42' '6' '60' '80' '45' '95 hours and more'\n",
      " '9' '54' '94' '65' '32' '49' '46' '90' '26' '38' '13' '11' '58' '55' '29'\n",
      " '33' '23' '27' '64' '63' '52' '47' '68' '31' '72' '37' '77' '51' '43'\n",
      " '69' '19' '62' '71' '75' '44' '74' '85' '86' '66' '92' '78' '76' '91'\n",
      " '81' '57' '41' '39' '61']\n",
      "==================== df_2022_clean ====================\n",
      "['-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL'\n",
      " '2.0' '8.0' '5.0' '16.0' '1. 1 hour' '20.0' '4.0' '25.0'\n",
      " '0. None, no hours' '24.0' '14.0' '42.0' '3.0' '15.0' '12.0' '30.0'\n",
      " '35.0' '7.0' '45.0' '40.0' '10.0' '6.0' '11.0' '21.0' '18.0' '22.0' '9.0'\n",
      " '59.0' '13.0' '28.0' '32.0' '50.0' '60.0'\n",
      " \"-9. No answer; HR, IS: DK/NA; ES, HU, TW: Can't Ch/NA; LT: NA/DK/Hard to say; PL: Hard to say/NA\"\n",
      " '19.0' '29.0' '65.0' '36.0' '80.0' '90.0' '72.0' '48.0' '26.0' '56.0'\n",
      " '27.0' '23.0' '17.0' '54.0' '95. 95 hours and more' '55.0' '34.0' '69.0'\n",
      " '70.0' '44.0' '49.0' '52.0' '46.0' '38.0' '37.0' '31.0' '84.0' '68.0'\n",
      " '64.0' '88.0' '66.0' '75.0' '58.0' '43.0' '63.0' '41.0' '62.0' '51.0'\n",
      " '74.0' '33.0' '39.0' '82.0' '3.5' '61.0' '47.0' '76.0']\n",
      "==================== LIFE_HAP ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Neither happy nor unhappy' 'Very happy' 'Fairly happy'\n",
      " 'Completely happy' 'Very unhappy' 'Fairly unhappy' nan\n",
      " 'Completely unhappy']\n",
      "==================== df_2012_clean ====================\n",
      "['Very happy' 'Fairly unhappy' 'Completely happy' 'Fairly happy'\n",
      " 'Very unhappy' 'Neither happy nor unhappy' \"Can't choose, NL:Don't know\"\n",
      " 'No answer' 'Completely unhappy']\n",
      "==================== df_2022_clean ====================\n",
      "['3. Fairly happy' '1. Completely happy' '4. Neither happy nor unhappy'\n",
      " '2. Very happy' '6. Very unhappy' \"-8. Can't choose\" '5. Fairly unhappy'\n",
      " '7. Completely unhappy' '-9. No answer']\n",
      "==================== DIFF_CONC_WORK ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Several times a month' nan 'Never' 'Once or twice a year'\n",
      " 'Several times a week']\n",
      "==================== df_2012_clean ====================\n",
      "['Several times a month'\n",
      " \"Doesn't apply: no job, no family responsibilities (HR,LT,MX,PL,RU,TW,VE: 2 or 3 in WORK)\"\n",
      " 'Never' 'Once or twice' 'Several times a week'\n",
      " \"Don't know, BG: can't choose, KR: don't know, refused\" 'No answer']\n",
      "==================== df_2022_clean ====================\n",
      "['2. Several times a month' '4. Never' '3. Once or twice'\n",
      " \"-4. Doesn't apply/no job; TW: NAP (code 2,3,5,6,7 in MAINSTAT)\"\n",
      " '1. Several times a week' '-9. No answer; LT: NA/DK/Hard to say'\n",
      " \"-8. DE: Can't choose\"\n",
      " '-1. DK: Not available; US: Not available for respondents who used the Spanish questionnaire version']\n",
      "==================== HH_TIRED ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Never' nan 'Once or twice a year' 'Several times a month'\n",
      " 'Several times a week']\n",
      "==================== df_2012_clean ====================\n",
      "['Never'\n",
      " \"Doesn't apply: no job, no family responsibilities (HR,LT,MX,PL,RU,TW,VE: 2 or 3 in WORK)\"\n",
      " 'Several times a month' 'Once or twice' 'Several times a week'\n",
      " \"Don't know, BG: can't choose, KR: don't know, refused\" 'No answer']\n",
      "==================== df_2022_clean ====================\n",
      "['3. Once or twice' '4. Never'\n",
      " \"-4. Doesn't apply/no job; TW: NAP (code 2,3,5,6,7 in MAINSTAT)\"\n",
      " '2. Several times a month' '1. Several times a week'\n",
      " '-9. No answer; LT: NA/DK/Hard to say' \"-8. DE: Can't choose\"\n",
      " '-1. DK: Not available']\n",
      "==================== HH_FAM ====================\n",
      "==================== df_2002_clean ====================\n",
      "[nan]\n",
      "==================== df_2012_clean ====================\n",
      "['14' '84' 'None, no hours, does not apply, IN: no hours, no partner' '30'\n",
      " '48' '56' '22' '40' '21' '28' '70' '10' '95 hours and more' '20'\n",
      " 'No answer, CA: no answer, refused' '42' '16' '36' '12' '15' '50' '63'\n",
      " \"Don't know, BG: can't choose, KR: don't know, refused\" '24' '8' '60' '6'\n",
      " '25' '5' '3 hours' '4' '18' '7' '35' '49' '80' '54' '9' '13' '77'\n",
      " '2 hours' '46' '75' '57' '1 hour or less than 1 hour' '72' '52' '34' '45'\n",
      " '38' '90' '26' '44' '11' '66' '68' '89' '78' '65' '64' '69' '94' '53'\n",
      " '74' '81' '29' '51' '39' '92' '59' '55' '88' '33' '32' '17' '58' '31'\n",
      " '85' '27' '37' '19' '82' '62' '91' '86' '43' '23' '76' '47' '41' '73'\n",
      " '67' '83' '61']\n",
      "==================== df_2022_clean ====================\n",
      "['30' '0. None, no hours' '3' '4' '20' '9' '1. 1 hour' '75' '5' '10' '2'\n",
      " '40' '70' '7' '63' '8' '95. 95 hours and more' '49' '25' '21' '80' '90'\n",
      " '6' '14' '17' '65' '60' '24' '36' '18' '84' '50' '15' '45' '16' '32' '68'\n",
      " '44' '48' '55' '12' '42' '35' '54' '64' '51' '77' '72' '56' '28' '26'\n",
      " \"-9. No answer; HR, IS: DK/NA; ES, HU, TW: Can't Ch/NA; LT: NA/DK/Hard to say; PL: Hard to say/NA\"\n",
      " '22' '29' '41' '11' '19' '66' '34' '38' '27' '13' '53' '85' '62' '31'\n",
      " '78' '39' '33' '47' '61' '46' '57' '91' '52' '74' '37' '88' '23' '82'\n",
      " '58' '73' '43' '71' '92' '69' '94' '93' '59' '76' '81' '86' '87' '83'\n",
      " '67']\n",
      "==================== WORK_TIRED ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Several times a month' nan 'Never' 'Once or twice a year'\n",
      " 'Several times a week']\n",
      "==================== df_2012_clean ====================\n",
      "['Once or twice'\n",
      " \"Doesn't apply: no job, no family responsibilities (HR,LT,MX,PL,RU,TW,VE: 2 or 3 in WORK)\"\n",
      " 'Several times a month' 'Never' 'Several times a week'\n",
      " \"Don't know, BG: can't choose, KR: don't know, refused\" 'No answer']\n",
      "==================== df_2022_clean ====================\n",
      "['1. Several times a week' '3. Once or twice' '2. Several times a month'\n",
      " \"-4. Doesn't apply/no job; TW: NAP (code 2,3,5,6,7 in MAINSTAT)\"\n",
      " '4. Never' '-9. No answer; LT: NA/DK/Hard to say' \"-8. DE: Can't choose\"\n",
      " '-1. DK: Not available']\n",
      "==================== HH_WEEKEND ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Mostly me' 'We decide together' nan 'Sometimes me,sometimes spouse'\n",
      " 'Mostly my spouse,partner' 'Someone else']\n",
      "==================== df_2012_clean ====================\n",
      "['We decide together'\n",
      " 'NAP, no partner (3 (AT,BE,CH,CL,ES,IS,KR,NL,NO,PL,SK,US:2,3; AR,BG,CZ,PT:2,3,7;IL:3,7) in PARTLIV;TW:3-6 in MARITAL)'\n",
      " 'Mostly my spouse/ partner' 'Sometimes me/ sometimes spouse, partner'\n",
      " 'Mostly me' 'Someone else'\n",
      " \"Don't know, BG: can't choose, KR: don't know, refused\" 'No answer']\n",
      "==================== df_2022_clean ====================\n",
      "['-4. NAP, no partn. or not liv. with part. (c.2,3,-7 PARTLIV; US: c.2 (if neither married nor cohabit. with partner), 3 PARTL'\n",
      " '1. Always me' '3. About equal or both together' '2. Usually me'\n",
      " '4. Usually my spouse/partner' '5. Always my spouse/partner'\n",
      " \"-8. Can't choose\" \"-9. No answer; ES: Can't choose/ No answer\"\n",
      " '6. Is done by a third person']\n",
      "==================== COHAB ====================\n",
      "==================== df_2002_clean ====================\n",
      "[nan 'Yes' 'No']\n",
      "==================== df_2012_clean ====================\n",
      "['Yes, have partner; live in same household' 'No partner'\n",
      " \"Yes, have partner; don't live in same household\" 'Refused' 'No answer'\n",
      " 'Not available: DK,GB,TW']\n",
      "==================== df_2022_clean ====================\n",
      "['3. No partner' '1. Yes, have partner; live in same household'\n",
      " \"2. Yes, have partner; don't live in same household\" '-9. No answer'\n",
      " '-7. Refused']\n",
      "==================== HOMPOP ====================\n",
      "==================== df_2002_clean ====================\n",
      "['2 persons' '1 person' '5 persons' '4 persons' '3 persons' '6 persons'\n",
      " '8 persons or more' '7 persons' '10 persons' '9 persons' nan '15.0'\n",
      " '23.0' '12 persons' '11 persons' '14.0' '13, DK:13 or more persons'\n",
      " '20.0' '16.0' '17.0' '21.0' '18.0' '19.0' '24.0']\n",
      "==================== df_2012_clean ====================\n",
      "['3' '5' '4' '2 persons' '7' '8' '6' '9' '10'\n",
      " 'One person (only respondent)' '11' '12' 'No answer' '25' '35' '14' '13'\n",
      " '16' '15' '18' 'Not a private household; not available: TR' '20' '19'\n",
      " '17' '22' '37' '23' '21' '26' '24' '27' '32']\n",
      "==================== df_2022_clean ====================\n",
      "['2. Two persons' '1. One person (only respondent)' '4. Four persons'\n",
      " '3. Three persons' '-9. No answer' '5. Five persons' '6. Six persons'\n",
      " '7. Seven persons' '9. Nine persons' '8. Eight persons'\n",
      " '21. Twenty-one persons' '-4. NAP (Not a private household)'\n",
      " '15. Fifteen persons' '10. Ten persons' '12. Twelve persons'\n",
      " '17. Seventeen persons' '14. Fourteen persons' '11. Eleven persons'\n",
      " '13. Thirteen persons' '20. Eighteen persons' '16. Sixteen persons'\n",
      " '28. Twenty-eight persons' '22. Twenty-two persons'\n",
      " '18. Eighteen persons']\n",
      "==================== COUNTRY ====================\n",
      "==================== df_2002_clean ====================\n",
      "['Australia (AU)' 'Germany (West) (DE-W)' 'Germany (East) (DE-E)'\n",
      " 'Great Britain (GB-GBN)' 'Northern Ireland (GB-NIR)' 'United States (US)'\n",
      " 'Austria (AT)' 'Hungary (HU)' 'Ireland (IE)' 'Netherlands (NL)'\n",
      " 'Norway (NO)' 'Sweden (SE)' 'Czech Republic (CZ)' 'Slovenia (SI)'\n",
      " 'Poland (PL)' 'Bulgaria (BG)' 'Russia (RU)' 'New Zealand (NZ)'\n",
      " 'Philippines (PH)' 'Israel (IL)' 'Japan (JP)' 'Spain (ES)' 'Latvia (LV)'\n",
      " 'Slovak Republic (SK)' 'France (FR)' 'Cyprus (CY)' 'Portugal (PT)'\n",
      " 'Chile (CL)' 'Denmark (DK)' 'Switzerland (CH)'\n",
      " 'Belgium/ Flanders (BE-FLA)' 'Brazil (BR)' 'Finland (FI)' 'Mexico (MX)'\n",
      " 'Taiwan (TW)']\n",
      "==================== df_2012_clean ====================\n",
      "['AR-Argentina' 'AU-Australia' 'AT-Austria' 'BG-Bulgaria' 'CA-Canada'\n",
      " 'CL-Chile' 'CN-China' 'TW-Taiwan' 'HR-Croatia' 'CZ-Czech Republic'\n",
      " 'DK-Denmark' 'FI-Finland' 'FR-France' 'HU-Hungary' 'IS-Iceland'\n",
      " 'IN-India' 'IE-Ireland' 'IL-Israel' 'JP-Japan' 'KR-Korea (South)'\n",
      " 'LV-Latvia' 'LT-Lithuania' 'MX-Mexico' 'NL-Netherlands' 'NO-Norway'\n",
      " 'PH-Philippines' 'PL-Poland' 'RU-Russia' 'SK-Slovakia' 'SI-Slovenia'\n",
      " 'ZA-South Africa' 'ES-Spain' 'SE-Sweden' 'CH-Switzerland' 'TR-Turkey'\n",
      " 'US-United States' 'VE-Venezuela' 'BE-FLA-Belgium/ Flanders'\n",
      " 'BE-WAL-Belgium/ Wallonia' 'BE-BRU-Belgium/ Brussels' 'DE-W-Germany-West'\n",
      " 'DE-E-Germany-East'\n",
      " 'PT-Portugal 2012: first fieldwork round (main sample)'\n",
      " 'PT-Portugal 2012: second fieldwork round (complementary sample)'\n",
      " 'GB-GBN-Great Britain']\n",
      "==================== df_2022_clean ====================\n",
      "['40. AT-Austria' '36. AU-Australia' '100. BG-Bulgaria'\n",
      " '756. CH-Switzerland' '203. CZ-Czech Republic' '27601. DE-W-Germany-West'\n",
      " '27602. DE-E-Germany-East' '208. DK-Denmark' '724. ES-Spain'\n",
      " '246. FI-Finland' '250. FR-France' '300. GR-Greece' '191. HR-Croatia'\n",
      " '348. HU-Hungary' '37601. IL-J-Israel, Jews' '37602. IL-A-Israel, Arabs'\n",
      " '356. IN-India' '352. IS-Iceland' '380. IT-Italy' '392. JP-Japan'\n",
      " '440. LT-Lithuania' '528. NL-Netherlands' '578. NO-Norway'\n",
      " '554. NZ-New Zealand' '608. PH-Philippines' '616. PL-Poland'\n",
      " '643. RU-Russia' '752. SE-Sweden' '705. SI-Slovenia' '703. SK-Slovakia'\n",
      " '764. TH-Thailand' '158. TW-Taiwan' '840. US-United States'\n",
      " '710. ZA-South Africa']\n",
      "==================== CASEID ====================\n",
      "==================== df_2002_clean ====================\n",
      "[ 1000001  1000002  1000003 ... 39093341 39093342 39093344]\n",
      "==================== df_2012_clean ====================\n",
      "[2.01200032e+15 2.01200032e+15 2.01200032e+15 ... 2.01282601e+15\n",
      " 2.01282601e+15 2.01282601e+15]\n",
      "==================== df_2022_clean ====================\n",
      "[2.02200040e+15 2.02200040e+15 2.02200040e+15 ... 2.02271018e+15\n",
      " 2.02271018e+15 2.02271018e+15]\n"
     ]
    }
   ],
   "source": [
    "dfs = [df_2002_clean, df_2012_clean, df_2022_clean]\n",
    "year = [2002, 2012, 2022]\n",
    "count = 0\n",
    "for col_name in df_mapping[\"COMMON_VAR\"]:\n",
    "    if col_name not in cleaned_vars:\n",
    "        count+=1\n",
    "        print(\"=\"*20,col_name, \"=\"*20)\n",
    "        for df, yr in zip(dfs, year):\n",
    "            print(\"=\"*20, f\"df_{yr}_clean\", \"=\"*20)\n",
    "            print(df[col_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d0b07d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "56cbd0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Defined cleaning functions for all common variables\n",
      "\n",
      "Function categories:\n",
      "  - Likert scales (5-point)\n",
      "  - Income deciles\n",
      "  - Work hours\n",
      "  - Work preferences\n",
      "  - Education levels\n",
      "  - Parent suitability\n",
      "  - Household counts\n",
      "  - Frequency scales\n",
      "  - Task fairness\n",
      "  - Task division\n",
      "  - Happiness scale\n",
      "  - Weekend decisions\n",
      "  - Cohabitation status\n",
      "  - Country codes\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ==================== CLEANING FUNCTIONS FOR ALL COMMON VARIABLES ====================\n",
    "\n",
    "# 1. LIKERT SCALE (5-point: Strongly Agree to Strongly Disagree)\n",
    "def clean_likert_5(val):\n",
    "    \"\"\"Standardize 5-point Likert scale responses.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing values\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', 'nap', \"can't choose\", 'not available']):\n",
    "        return None\n",
    "    \n",
    "    # Map to standard categories\n",
    "    if 'strongly agree' in val_str or val_str.startswith('1.'):\n",
    "        return \"Strongly agree\"\n",
    "    if ('agree' in val_str and 'disagree' not in val_str and 'neither' not in val_str) or val_str.startswith('2.'):\n",
    "        return \"Agree\"\n",
    "    if 'neither' in val_str or val_str.startswith('3.'):\n",
    "        return \"Neither agree nor disagree\"\n",
    "    if ('disagree' in val_str and 'strongly' not in val_str) or val_str.startswith('4.'):\n",
    "        return \"Disagree\"\n",
    "    if 'strongly disagree' in val_str or val_str.startswith('5.'):\n",
    "        return \"Strongly disagree\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 2. INCOME DECILE (TOPBOT)\n",
    "def clean_income_decile(val):\n",
    "    \"\"\"Extract numeric decile from income scale (1-10).\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing values\n",
    "    if any(x in val_str for x in [\"don't know\", 'no answer', 'refused', 'not available']):\n",
    "        return None\n",
    "    \n",
    "    # Handle text labels\n",
    "    if 'lowest' in val_str or 'bottom' in val_str or '01' in val_str or val_str.startswith('1.'):\n",
    "        return 1\n",
    "    if 'highest' in val_str or 'top' in val_str or '10' in val_str:\n",
    "        return 10\n",
    "    \n",
    "    # Extract numeric value\n",
    "    match = re.search(r'(\\d+)', val_str)\n",
    "    if match:\n",
    "        num = int(match.group(1))\n",
    "        if 1 <= num <= 10:\n",
    "            return num\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 3. WORK HOURS (SPWRKHRS, SP_HH_FAM, SP_HH, HH_FAM)\n",
    "def clean_work_hours(val):\n",
    "    \"\"\"Extract numeric work hours (0-95+).\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing/NAP\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', 'nap', 'not available']):\n",
    "        return None\n",
    "    \n",
    "    # Handle \"none\"\n",
    "    if 'none' in val_str or 'no hour' in val_str:\n",
    "        return 0\n",
    "    \n",
    "    # Handle \"one hour\"\n",
    "    if 'one hour' in val_str or val_str == '1. 1 hour':\n",
    "        return 1\n",
    "    \n",
    "    # Handle 95+ \n",
    "    if '95' in val_str or '96' in val_str:\n",
    "        return 95\n",
    "    \n",
    "    # Extract numeric value (handle floats too)\n",
    "    match = re.search(r'(\\d+\\.?\\d*)', val_str)\n",
    "    if match:\n",
    "        num = float(match.group(1))\n",
    "        return int(num) if num <= 95 else 95\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 4. WORK PREFERENCE (WWYKS, WWYKUS)\n",
    "def clean_work_preference(val):\n",
    "    \"\"\"Standardize work preference categories.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", \"can't choose\"]):\n",
    "        return None\n",
    "    \n",
    "    # Women should decide\n",
    "    if 'women should decide' in val_str or 'women shld decide' in val_str or val_str.startswith('4.'):\n",
    "        return \"Women should decide\"\n",
    "    \n",
    "    # Work full-time\n",
    "    if 'full-time' in val_str or 'full time' in val_str or val_str.startswith('1.'):\n",
    "        return \"Work full-time\"\n",
    "    \n",
    "    # Work part-time\n",
    "    if 'part-time' in val_str or 'part time' in val_str or val_str.startswith('2.'):\n",
    "        return \"Work part-time\"\n",
    "    \n",
    "    # Stay at home\n",
    "    if 'stay at home' in val_str or val_str.startswith('3.'):\n",
    "        return \"Stay at home\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 5. EDUCATION LEVEL (SP_DEGREE)\n",
    "def clean_education(val):\n",
    "    \"\"\"Standardize education levels.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing/NAP\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', 'nap', 'not available', 'not classifiable']):\n",
    "        return None\n",
    "    \n",
    "    # Map to standardized categories\n",
    "    if 'no formal' in val_str or 'no (formal) education' in val_str or val_str.startswith('0.'):\n",
    "        return \"No formal education\"\n",
    "    \n",
    "    if 'primary' in val_str and 'incomplete' not in val_str or val_str.startswith('1.'):\n",
    "        return \"Primary\"\n",
    "    \n",
    "    if 'lower secondary' in val_str or val_str.startswith('2.'):\n",
    "        return \"Lower secondary\"\n",
    "    \n",
    "    if 'upper secondary' in val_str or 'higher secondary' in val_str or val_str.startswith('3.'):\n",
    "        return \"Upper secondary\"\n",
    "    \n",
    "    if 'post secondary' in val_str or val_str.startswith('4.'):\n",
    "        return \"Post secondary\"\n",
    "    \n",
    "    if ('short-cycle tertiary' in val_str or 'lower level tertiary' in val_str or \n",
    "        'above lowest qualification' in val_str or val_str.startswith('5.') or val_str.startswith('6.')):\n",
    "        return \"Tertiary (Bachelor level)\"\n",
    "    \n",
    "    if ('upper level tertiary' in val_str or 'university degree' in val_str or \n",
    "        'above higher secondary' in val_str or val_str.startswith('7.')):\n",
    "        return \"Tertiary (Master level)\"\n",
    "    \n",
    "    if 'phd' in val_str or 'post tertiary' in val_str or val_str.startswith('8.'):\n",
    "        return \"Tertiary (Doctoral level)\"\n",
    "    \n",
    "    if 'lowest formal qualification' in val_str:\n",
    "        return \"Primary\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 6. PARENT SUITABILITY (MOMORFAF)\n",
    "def clean_parent_suit(val):\n",
    "    \"\"\"Standardize parent suitability scale.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", \"can't choose\"]):\n",
    "        return None\n",
    "    \n",
    "    # 2002 uses Likert, 2022 uses specific scale\n",
    "    if 'strongly agree' in val_str or 'mothers and fathers are equally' in val_str or val_str.startswith('3.'):\n",
    "        return \"Equally suited\"\n",
    "    \n",
    "    if ('agree' in val_str and 'strongly' not in val_str and 'neither' not in val_str and 'disagree' not in val_str) or \\\n",
    "       'mothers are somewhat better' in val_str or val_str.startswith('2.'):\n",
    "        return \"Mothers somewhat better\"\n",
    "    \n",
    "    if 'mothers are much better' in val_str or val_str.startswith('1.'):\n",
    "        return \"Mothers much better\"\n",
    "    \n",
    "    if 'fathers are somewhat better' in val_str or val_str.startswith('4.'):\n",
    "        return \"Fathers somewhat better\"\n",
    "    \n",
    "    if 'strongly disagree' in val_str or 'fathers are much better' in val_str or val_str.startswith('5.'):\n",
    "        return \"Fathers much better\"\n",
    "    \n",
    "    if 'neither' in val_str or 'disagree' in val_str:\n",
    "        return \"Equally suited\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 7. HOUSEHOLD COUNTS (HHTODD, HHCHILDR, HHADULT, HOMPOP)\n",
    "def clean_household_count(val):\n",
    "    \"\"\"Extract numeric count from household composition variables.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing/NAP\n",
    "    if any(x in val_str for x in ['no answer', 'refused', 'nap', 'not available']):\n",
    "        return None\n",
    "    \n",
    "    # Handle \"no children/adults/toddlers/persons\"\n",
    "    if any(x in val_str for x in ['no children', 'no toddlers', 'no adults', 'no persons']):\n",
    "        return 0\n",
    "    \n",
    "    # Handle \"one\"\n",
    "    if 'one child' in val_str or 'one toddler' in val_str or 'one adult' in val_str or 'one person' in val_str:\n",
    "        return 1\n",
    "    \n",
    "    # Extract numeric value\n",
    "    match = re.search(r'(\\d+)', val_str)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 8. FREQUENCY SCALE (FAM_DIF, DIFF_CONC_WORK, HH_TIRED, WORK_TIRED)\n",
    "FREQUENCY_ORDER = [\n",
    "    \"Several times a week\",\n",
    "    \"Several times a month\",\n",
    "    \"Once or twice\",\n",
    "    \"Never\",\n",
    "    \"NAP\"\n",
    "]\n",
    "\n",
    "def clean_frequency(val):\n",
    "    \"\"\"Standardize frequency scale.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing/NAP\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', \"doesn't apply\", 'nap', 'not available', \"can't choose\"]):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    if 'several times a week' in val_str or val_str.startswith('1.'):\n",
    "        return \"Several times a week\"\n",
    "    \n",
    "    if 'several times a month' in val_str or val_str.startswith('2.'):\n",
    "        return \"Several times a month\"\n",
    "    \n",
    "    if 'once or twice' in val_str or val_str.startswith('3.'):\n",
    "        return \"Once or twice\"\n",
    "    \n",
    "    if 'never' in val_str or val_str.startswith('4.'):\n",
    "        return \"Never\"\n",
    "    \n",
    "    return \"NAP\"\n",
    "\n",
    "# 9. TASK FAIRNESS SHARE (SHARE_HH)\n",
    "FAIRNESS_SHARE_ORDER = [\n",
    "    \"Much more than fair share\",\n",
    "    \"Bit more than fair share\",\n",
    "    \"Fair share\",\n",
    "    \"Bit less than fair share\",\n",
    "    \"Much less than fair share\",\n",
    "    \"NAP\"\n",
    "]\n",
    "\n",
    "def clean_fairness_share(val):\n",
    "    \"\"\"Standardize task fairness perception.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing/NAP\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', 'nap', \"can't choose\"]):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    if 'much more' in val_str or val_str.startswith('1.'):\n",
    "        return \"Much more than fair share\"\n",
    "    \n",
    "    if ('bit more' in val_str or 'a bit more' in val_str) or val_str.startswith('2.'):\n",
    "        return \"Bit more than fair share\"\n",
    "    \n",
    "    if 'roughly my fair share' in val_str or ('fair share' in val_str and 'more' not in val_str and 'less' not in val_str) or val_str.startswith('3.'):\n",
    "        return \"Fair share\"\n",
    "    \n",
    "    if ('bit less' in val_str or 'a bit less' in val_str) or val_str.startswith('4.'):\n",
    "        return \"Bit less than fair share\"\n",
    "    \n",
    "    if 'much less' in val_str or val_str.startswith('5.'):\n",
    "        return \"Much less than fair share\"\n",
    "    \n",
    "    return \"NAP\"\n",
    "\n",
    "# 10. TASK DIVISION (DIV_HH_* variables)\n",
    "TASK_DIV_ORDER = [\n",
    "    \"Always respondent\",\n",
    "    \"Usually respondent\",\n",
    "    \"About equal\",\n",
    "    \"Usually partner\",\n",
    "    \"Always partner\",\n",
    "    \"Third person\",\n",
    "    \"NAP\"\n",
    "]\n",
    "\n",
    "def clean_task_div(val):\n",
    "    \"\"\"Standardize task division categories.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing/NAP\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', 'nap', \"can't choose\"]):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    # Third person first\n",
    "    if 'third person' in val_str or val_str.startswith('6.'):\n",
    "        return \"Third person\"\n",
    "    \n",
    "    # Always respondent/me\n",
    "    if ('always me' in val_str or 'always respondent' in val_str) or val_str.startswith('1.'):\n",
    "        return \"Always respondent\"\n",
    "    \n",
    "    # Usually respondent/me\n",
    "    if ('usually me' in val_str or 'usually respondent' in val_str) or val_str.startswith('2.'):\n",
    "        return \"Usually respondent\"\n",
    "    \n",
    "    # About equal\n",
    "    if 'about equal' in val_str or 'both together' in val_str or 'both equally' in val_str or val_str.startswith('3.'):\n",
    "        return \"About equal\"\n",
    "    \n",
    "    # Usually partner\n",
    "    if ('usually' in val_str and ('spouse' in val_str or 'partner' in val_str)) or val_str.startswith('4.'):\n",
    "        return \"Usually partner\"\n",
    "    \n",
    "    # Always partner\n",
    "    if ('always' in val_str and ('spouse' in val_str or 'partner' in val_str)) or val_str.startswith('5.'):\n",
    "        return \"Always partner\"\n",
    "    \n",
    "    return \"NAP\"\n",
    "\n",
    "# 11. HAPPINESS SCALE (LIFE_HAP)\n",
    "HAPPINESS_ORDER = [\n",
    "    \"Completely happy\",\n",
    "    \"Very happy\",\n",
    "    \"Fairly happy\",\n",
    "    \"Neither happy nor unhappy\",\n",
    "    \"Fairly unhappy\",\n",
    "    \"Very unhappy\",\n",
    "    \"Completely unhappy\"\n",
    "]\n",
    "\n",
    "def clean_happiness(val):\n",
    "    \"\"\"Standardize happiness scale.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", \"can't choose\"]):\n",
    "        return None\n",
    "    \n",
    "    if 'completely happy' in val_str or val_str.startswith('1.'):\n",
    "        return \"Completely happy\"\n",
    "    if 'very happy' in val_str or val_str.startswith('2.'):\n",
    "        return \"Very happy\"\n",
    "    if 'fairly happy' in val_str or val_str.startswith('3.'):\n",
    "        return \"Fairly happy\"\n",
    "    if 'neither' in val_str or val_str.startswith('4.'):\n",
    "        return \"Neither happy nor unhappy\"\n",
    "    if 'fairly unhappy' in val_str or val_str.startswith('5.'):\n",
    "        return \"Fairly unhappy\"\n",
    "    if 'very unhappy' in val_str or val_str.startswith('6.'):\n",
    "        return \"Very unhappy\"\n",
    "    if 'completely unhappy' in val_str or val_str.startswith('7.'):\n",
    "        return \"Completely unhappy\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 12. WEEKEND DECISION (HH_WEEKEND)\n",
    "def clean_weekend_decision(val):\n",
    "    \"\"\"Standardize weekend activity decision variable.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing/NAP\n",
    "    if any(x in val_str for x in ['no answer', \"don't know\", 'refused', 'nap', \"can't choose\"]):\n",
    "        return \"NAP\"\n",
    "    \n",
    "    # Map to task division categories for consistency\n",
    "    if 'always me' in val_str or 'mostly me' in val_str or val_str.startswith('1.'):\n",
    "        return \"Always respondent\"\n",
    "    \n",
    "    if 'usually me' in val_str or val_str.startswith('2.'):\n",
    "        return \"Usually respondent\"\n",
    "    \n",
    "    if 'we decide together' in val_str or 'about equal' in val_str or 'both together' in val_str or val_str.startswith('3.'):\n",
    "        return \"About equal\"\n",
    "    \n",
    "    if ('usually' in val_str and ('spouse' in val_str or 'partner' in val_str)) or val_str.startswith('4.'):\n",
    "        return \"Usually partner\"\n",
    "    \n",
    "    if ('always' in val_str and ('spouse' in val_str or 'partner' in val_str)) or 'mostly my spouse' in val_str or val_str.startswith('5.'):\n",
    "        return \"Always partner\"\n",
    "    \n",
    "    if 'third person' in val_str or 'someone else' in val_str or val_str.startswith('6.'):\n",
    "        return \"Third person\"\n",
    "    \n",
    "    if 'sometimes' in val_str:\n",
    "        return \"About equal\"\n",
    "    \n",
    "    return \"NAP\"\n",
    "\n",
    "# 13. COHABITATION (COHAB)\n",
    "def clean_cohab(val):\n",
    "    \"\"\"Standardize cohabitation status.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).lower()\n",
    "    \n",
    "    # Handle missing\n",
    "    if any(x in val_str for x in ['no answer', 'refused', 'not available']):\n",
    "        return None\n",
    "    \n",
    "    if 'yes' in val_str and 'same household' in val_str or val_str.startswith('1.'):\n",
    "        return \"Partner, same household\"\n",
    "    \n",
    "    if 'yes' in val_str and \"don't live\" in val_str or val_str.startswith('2.'):\n",
    "        return \"Partner, different household\"\n",
    "    \n",
    "    if 'no partner' in val_str or val_str.startswith('3.'):\n",
    "        return \"No partner\"\n",
    "    \n",
    "    # Legacy coding\n",
    "    if val_str == 'yes':\n",
    "        return \"Partner, same household\"\n",
    "    if val_str == 'no':\n",
    "        return \"No partner\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 14. COUNTRY CODE (C_ALPHAN)\n",
    "def clean_country(val):\n",
    "    \"\"\"Extract standardized country code.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    \n",
    "    val_str = str(val).upper()\n",
    "    \n",
    "    # Extract 2-letter ISO code at start or after dash\n",
    "    match = re.match(r'(\\d+\\.\\s*)?([A-Z]{2})', val_str)\n",
    "    if match:\n",
    "        return match.group(2)\n",
    "    \n",
    "    return val_str[:2] if len(val_str) >= 2 else None\n",
    "\n",
    "print(\" Defined cleaning functions for all common variables\")\n",
    "print(\"\\nFunction categories:\")\n",
    "print(\"  - Likert scales (5-point)\")\n",
    "print(\"  - Income deciles\")\n",
    "print(\"  - Work hours\")\n",
    "print(\"  - Work preferences\")\n",
    "print(\"  - Education levels\")\n",
    "print(\"  - Parent suitability\")\n",
    "print(\"  - Household counts\")\n",
    "print(\"  - Frequency scales\")\n",
    "print(\"  - Task fairness\")\n",
    "print(\"  - Task division\")\n",
    "print(\"  - Happiness scale\")\n",
    "print(\"  - Weekend decisions\")\n",
    "print(\"  - Cohabitation status\")\n",
    "print(\"  - Country codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d97f36b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Applied cleaning to 34 variables across all years\n",
      " Converted 12 variables to ordered categorical\n",
      "\n",
      "================================================================================\n",
      "SAMPLE OF CLEANED DATA\n",
      "================================================================================\n",
      "\n",
      "TOPBOT:\n",
      "  2002: {5.0: 6270, 6.0: 6125, 7.0: 4077}\n",
      "  2012: {5.0: 14677, 6.0: 10766, 7.0: 8080}\n",
      "  2022: {5.0: 10932, 6.0: 8891, 7.0: 7294}\n",
      "\n",
      "SPWRKHRS:\n",
      "  2002: {40.0: 5034, 50.0: 1285, 48.0: 1087}\n",
      "  2012: {40.0: 6698, 50.0: 1735, 45.0: 1450}\n",
      "  2022: {40.0: 5852, 50.0: 1358, 45.0: 1050}\n",
      "\n",
      "LIVWOMAR:\n",
      "  2002: {'Agree': 17856, 'Strongly agree': 11321, 'Disagree': 7154}\n",
      "  2012: {'Agree': 19334, 'Strongly agree': 12071, 'Disagree': 11740}\n",
      "  2022: {'Strongly agree': 15414, 'Agree': 14343, 'Neither agree nor disagree': 6579}\n",
      "\n",
      "WWYKS:\n",
      "  2002: {'Work part-time': 23770, 'Work full-time': 12451, 'Stay at home': 6377}\n",
      "  2012: {'Work part-time': 24981, 'Work full-time': 24783, 'Stay at home': 5960}\n",
      "  2022: {'Work full-time': 21289, 'Work part-time': 16511, 'Stay at home': 2766}\n",
      "\n",
      "SP_DEGREE:\n",
      "  2002: {'Upper secondary': 9193, 'Tertiary (Bachelor level)': 5139, 'Primary': 4372}\n",
      "  2012: {'Upper secondary': 10319, 'Lower secondary': 7419, 'Tertiary (Bachelor level)': 4809}\n",
      "  2022: {'Upper secondary': 9449, 'Tertiary (Bachelor level)': 6565, 'Tertiary (Master level)': 3321}\n",
      "\n",
      "FAM_DIF:\n",
      "  2002: {'NAP': 19342, 'Never': 10780, 'Once or twice': 8010}\n",
      "  2012: {'NAP': 25995, 'Never': 14269, 'Once or twice': 9442}\n",
      "  2022: {'NAP': 15837, 'Never': 10859, 'Once or twice': 8170}\n",
      "\n",
      "SHARE_HH:\n",
      "  2002: {'NAP': 17261, 'Fair share': 13163, 'Much more than fair share': 4983}\n",
      "  2012: {'NAP': 23547, 'Fair share': 15509, 'Much more than fair share': 7128}\n",
      "  2022: {'NAP': 18829, 'Fair share': 11795, 'Bit more than fair share': 5090}\n",
      "\n",
      "DIV_HH_COOK:\n",
      "  2002: {'NAP': 16528, 'Always respondent': 8380, 'About equal': 5981}\n",
      "  2012: {'NAP': 22717, 'Always respondent': 9935, 'About equal': 7564}\n",
      "  2022: {'NAP': 18496, 'About equal': 6598, 'Usually respondent': 6402}\n",
      "\n",
      "LIFE_HAP:\n",
      "  2002: {'Fairly happy': 18972, 'Very happy': 14301, 'Neither happy nor unhappy': 5930}\n",
      "  2012: {'Fairly happy': 24441, 'Very happy': 17829, 'Neither happy nor unhappy': 8373}\n",
      "  2022: {'Fairly happy': 18416, 'Very happy': 12618, 'Neither happy nor unhappy': 6615}\n",
      "\n",
      "COHAB:\n",
      "  2002: {'No partner': 15408, 'Partner, same household': 3806}\n",
      "  2012: {'Partner, same household': 38812, 'No partner': 18026}\n",
      "  2022: {'Partner, same household': 30403, 'No partner': 14813}\n"
     ]
    }
   ],
   "source": [
    "# ==================== APPLY CLEANING TO ALL VARIABLES ====================\n",
    "\n",
    "# Variable mapping: column_name -> cleaning_function\n",
    "cleaning_map = {\n",
    "    # Income decile\n",
    "    'TOPBOT': clean_income_decile,\n",
    "    \n",
    "    # Work hours\n",
    "    'SPWRKHRS': clean_work_hours,\n",
    "    'SP_HH_FAM': clean_work_hours,\n",
    "    'SP_HH': clean_work_hours,\n",
    "    'HH_FAM': clean_work_hours,\n",
    "    \n",
    "    # Work preferences\n",
    "    'WWYKS': clean_work_preference,\n",
    "    'WWYKUS': clean_work_preference,\n",
    "    \n",
    "    # Education\n",
    "    'SP_DEGREE': clean_education,\n",
    "    \n",
    "    # Parent suitability\n",
    "    'MOMORFAF': clean_parent_suit,\n",
    "    \n",
    "    # Household counts\n",
    "    'HHTODD': clean_household_count,\n",
    "    'HHCHILDR': clean_household_count,\n",
    "    'HHADULT': clean_household_count,\n",
    "    'HOMPOP': clean_household_count,\n",
    "    \n",
    "    # Likert scales\n",
    "    'LIVWOMAR': clean_likert_5,\n",
    "    'MEWH': clean_likert_5,\n",
    "    'HW_FULFIL': clean_likert_5,\n",
    "    'WO_WANT': clean_likert_5,\n",
    "    'WW_FAM_SUFFER': clean_likert_5,\n",
    "    'WW_CHILD_SUFFER': clean_likert_5,\n",
    "    'WW_WARM': clean_likert_5,\n",
    "    \n",
    "    # Frequency scales\n",
    "    'FAM_DIF': clean_frequency,\n",
    "    'DIFF_CONC_WORK': clean_frequency,\n",
    "    'HH_TIRED': clean_frequency,\n",
    "    'WORK_TIRED': clean_frequency,\n",
    "    \n",
    "    # Task fairness share\n",
    "    'SHARE_HH': clean_fairness_share,\n",
    "    \n",
    "    # Task division\n",
    "    'DIV_HH_COOK': clean_task_div,\n",
    "    'DIV_HH_CLEAN': clean_task_div,\n",
    "    'DIV_HH_GROC': clean_task_div,\n",
    "    'DIV_HH_CARE': clean_task_div,\n",
    "    'DIV_HH_LAUND': clean_task_div,\n",
    "    'HH_WEEKEND': clean_weekend_decision,\n",
    "    \n",
    "    # Happiness\n",
    "    'LIFE_HAP': clean_happiness,\n",
    "    \n",
    "    # Cohabitation\n",
    "    'COHAB': clean_cohab,\n",
    "    \n",
    "    # Country\n",
    "    'C_ALPHAN': clean_country,\n",
    "}\n",
    "\n",
    "# Apply cleaning functions to all dataframes\n",
    "for col_name, clean_func in cleaning_map.items():\n",
    "    for df in [df_2002_clean, df_2012_clean, df_2022_clean]:\n",
    "        if col_name in df.columns:\n",
    "            df[col_name] = df[col_name].apply(clean_func)\n",
    "\n",
    "print(f\" Applied cleaning to {len(cleaning_map)} variables across all years\")\n",
    "\n",
    "# Convert categorical variables to ordered categories where appropriate\n",
    "categorical_mappings = {\n",
    "    'frequency': {\n",
    "        'columns': ['FAM_DIF', 'DIFF_CONC_WORK', 'HH_TIRED', 'WORK_TIRED'],\n",
    "        'order': FREQUENCY_ORDER\n",
    "    },\n",
    "    'task_division': {\n",
    "        'columns': ['DIV_HH_COOK', 'DIV_HH_CLEAN', 'DIV_HH_GROC', 'DIV_HH_CARE', 'DIV_HH_LAUND', 'HH_WEEKEND'],\n",
    "        'order': TASK_DIV_ORDER\n",
    "    },\n",
    "    'fairness_share': {\n",
    "        'columns': ['SHARE_HH'],\n",
    "        'order': FAIRNESS_SHARE_ORDER\n",
    "    },\n",
    "    'happiness': {\n",
    "        'columns': ['LIFE_HAP'],\n",
    "        'order': HAPPINESS_ORDER\n",
    "    }\n",
    "}\n",
    "\n",
    "for cat_type, info in categorical_mappings.items():\n",
    "    for col in info['columns']:\n",
    "        for df in [df_2002_clean, df_2012_clean, df_2022_clean]:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.Categorical(df[col], categories=info['order'], ordered=True)\n",
    "\n",
    "print(f\" Converted {sum(len(v['columns']) for v in categorical_mappings.values())} variables to ordered categorical\")\n",
    "\n",
    "# Display sample of cleaned data\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE OF CLEANED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sample_vars = ['TOPBOT', 'SPWRKHRS', 'LIVWOMAR', 'WWYKS', 'SP_DEGREE', 'FAM_DIF', 'SHARE_HH', 'DIV_HH_COOK', 'LIFE_HAP', 'COHAB']\n",
    "for var in sample_vars:\n",
    "    if var in df_2022_clean.columns:\n",
    "        print(f\"\\n{var}:\")\n",
    "        print(f\"  2002: {df_2002_clean[var].value_counts().head(3).to_dict() if var in df_2002_clean.columns else 'N/A'}\")\n",
    "        print(f\"  2012: {df_2012_clean[var].value_counts().head(3).to_dict() if var in df_2012_clean.columns else 'N/A'}\")\n",
    "        print(f\"  2022: {df_2022_clean[var].value_counts().head(3).to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a89ccd5",
   "metadata": {},
   "source": [
    "## Save Cleaned Data\n",
    "\n",
    "All variables have been cleaned and standardized across years. Now saving to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e80061f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved all cleaned dataframes to ../clean_csv/\n",
      "\n",
      "2002: (46638, 69)\n",
      "2012: (61754, 69)\n",
      "2022: (45762, 69)\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataframes to CSV\n",
    "df_2002_clean.to_csv(\"../clean_csv/2002_clean.csv\", index=False)\n",
    "df_2012_clean.to_csv(\"../clean_csv/2012_clean.csv\", index=False)\n",
    "df_2022_clean.to_csv(\"../clean_csv/2022_clean.csv\", index=False)\n",
    "\n",
    "print(\" Saved all cleaned dataframes to ../clean_csv/\")\n",
    "print(f\"\\n2002: {df_2002_clean.shape}\")\n",
    "print(f\"2012: {df_2012_clean.shape}\")\n",
    "print(f\"2022: {df_2022_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6747c7d0",
   "metadata": {},
   "source": [
    "## Verify Data Consistency Across Years\n",
    "\n",
    "Check that cleaned variables have consistent values across all three years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5f51d9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VERIFICATION OF DATA CONSISTENCY\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TOPBOT\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0)]\n",
      "  Non-null count: 26626\n",
      "\n",
      "2012: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0)]\n",
      "  Non-null count: 56907\n",
      "\n",
      "2022: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0)]\n",
      "  Non-null count: 42193\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "SPWRKHRS\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: 88 unique values\n",
      "  Sample: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0)]\n",
      "  Non-null count: 17534\n",
      "\n",
      "2012: 93 unique values\n",
      "  Sample: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0)]\n",
      "  Non-null count: 22283\n",
      "\n",
      "2022: 84 unique values\n",
      "  Sample: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0)]\n",
      "  Non-null count: 17638\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "SP_HH_FAM\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: []\n",
      "  Non-null count: 0\n",
      "\n",
      "2012: 90 unique values\n",
      "  Sample: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0)]\n",
      "  Non-null count: 36016\n",
      "\n",
      "2022: 86 unique values\n",
      "  Sample: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0)]\n",
      "  Non-null count: 25256\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "SP_HH\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: 82 unique values\n",
      "  Sample: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0)]\n",
      "  Non-null count: 28212\n",
      "\n",
      "2012: 85 unique values\n",
      "  Sample: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0)]\n",
      "  Non-null count: 37069\n",
      "\n",
      "2022: 78 unique values\n",
      "  Sample: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0)]\n",
      "  Non-null count: 26091\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "HH_FAM\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: []\n",
      "  Non-null count: 0\n",
      "\n",
      "2012: 92 unique values\n",
      "  Sample: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0)]\n",
      "  Non-null count: 57019\n",
      "\n",
      "2022: 94 unique values\n",
      "  Sample: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0)]\n",
      "  Non-null count: 42009\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "WWYKS\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: ['Stay at home', 'Women should decide', 'Work full-time', 'Work part-time']\n",
      "  Non-null count: 43042\n",
      "\n",
      "2012: ['Stay at home', 'Women should decide', 'Work full-time', 'Work part-time']\n",
      "  Non-null count: 56248\n",
      "\n",
      "2022: ['Stay at home', 'Women should decide', 'Work full-time', 'Work part-time']\n",
      "  Non-null count: 40630\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "WWYKUS\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: ['Stay at home', 'Women should decide', 'Work full-time', 'Work part-time']\n",
      "  Non-null count: 43065\n",
      "\n",
      "2012: ['Stay at home', 'Women should decide', 'Work full-time', 'Work part-time']\n",
      "  Non-null count: 56134\n",
      "\n",
      "2022: ['Stay at home', 'Women should decide', 'Work full-time', 'Work part-time']\n",
      "  Non-null count: 40414\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "SP_DEGREE\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: ['No formal education', 'Primary', 'Tertiary (Bachelor level)', 'Tertiary (Master level)', 'Upper secondary']\n",
      "  Non-null count: 24169\n",
      "\n",
      "2012: ['Lower secondary', 'No formal education', 'Primary', 'Tertiary (Bachelor level)', 'Tertiary (Master level)', 'Upper secondary']\n",
      "  Non-null count: 31572\n",
      "\n",
      "2022: ['Lower secondary', 'No formal education', 'Post secondary', 'Primary', 'Tertiary (Bachelor level)', 'Tertiary (Doctoral level)', 'Tertiary (Master level)', 'Upper secondary']\n",
      "  Non-null count: 26060\n",
      "\n",
      "Status:  CHECK NEEDED\n",
      "\n",
      "================================================================================\n",
      "MOMORFAF\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: ['Equally suited', 'Fathers much better', 'Mothers somewhat better']\n",
      "  Non-null count: 43605\n",
      "\n",
      "2012: []\n",
      "  Non-null count: 0\n",
      "\n",
      "2022: ['Equally suited', 'Fathers much better', 'Fathers somewhat better', 'Mothers much better', 'Mothers somewhat better']\n",
      "  Non-null count: 44744\n",
      "\n",
      "Status:  CHECK NEEDED\n",
      "\n",
      "================================================================================\n",
      "HHTODD\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0)]\n",
      "  Non-null count: 7207\n",
      "\n",
      "2012: 11 unique values\n",
      "  Sample: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0)]\n",
      "  Non-null count: 58959\n",
      "\n",
      "2022: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0)]\n",
      "  Non-null count: 41701\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "HHCHILDR\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0), np.float64(10.0)]\n",
      "  Non-null count: 13917\n",
      "\n",
      "2012: 17 unique values\n",
      "  Sample: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0)]\n",
      "  Non-null count: 58988\n",
      "\n",
      "2022: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0), np.float64(7.0), np.float64(8.0), np.float64(9.0)]\n",
      "  Non-null count: 43473\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "HHADULT\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: 15 unique values\n",
      "  Sample: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0)]\n",
      "  Non-null count: 42583\n",
      "\n",
      "2012: []\n",
      "  Non-null count: 0\n",
      "\n",
      "2022: 17 unique values\n",
      "  Sample: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0)]\n",
      "  Non-null count: 44242\n",
      "\n",
      "Status:  CHECK NEEDED\n",
      "\n",
      "================================================================================\n",
      "HOMPOP\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: 23 unique values\n",
      "  Sample: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0)]\n",
      "  Non-null count: 46202\n",
      "\n",
      "2012: 30 unique values\n",
      "  Sample: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0)]\n",
      "  Non-null count: 58990\n",
      "\n",
      "2022: 21 unique values\n",
      "  Sample: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0)]\n",
      "  Non-null count: 44836\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "LIVWOMAR\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 45270\n",
      "\n",
      "2012: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 57817\n",
      "\n",
      "2022: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 44905\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "MEWH\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 45475\n",
      "\n",
      "2012: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 58078\n",
      "\n",
      "2022: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 45045\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "HW_FULFIL\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 43720\n",
      "\n",
      "2012: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 55612\n",
      "\n",
      "2022: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 43029\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "WO_WANT\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 44089\n",
      "\n",
      "2012: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 56379\n",
      "\n",
      "2022: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 43742\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "WW_FAM_SUFFER\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 45120\n",
      "\n",
      "2012: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 57631\n",
      "\n",
      "2022: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 44784\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "WW_CHILD_SUFFER\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 45028\n",
      "\n",
      "2012: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 57551\n",
      "\n",
      "2022: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 44626\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "WW_WARM\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 45484\n",
      "\n",
      "2012: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 57860\n",
      "\n",
      "2022: ['Agree', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Strongly disagree']\n",
      "  Non-null count: 45008\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "FAM_DIF\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002 (categorical): ['Several times a week', 'Several times a month', 'Once or twice', 'Never', 'NAP']\n",
      "  Non-null count: 46638\n",
      "\n",
      "2012 (categorical): ['Several times a week', 'Several times a month', 'Once or twice', 'Never', 'NAP']\n",
      "  Non-null count: 61754\n",
      "\n",
      "2022 (categorical): ['Several times a week', 'Several times a month', 'Once or twice', 'Never', 'NAP']\n",
      "  Non-null count: 45762\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "DIFF_CONC_WORK\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002 (categorical): ['Several times a week', 'Several times a month', 'Once or twice', 'Never', 'NAP']\n",
      "  Non-null count: 46638\n",
      "\n",
      "2012 (categorical): ['Several times a week', 'Several times a month', 'Once or twice', 'Never', 'NAP']\n",
      "  Non-null count: 61754\n",
      "\n",
      "2022 (categorical): ['Several times a week', 'Several times a month', 'Once or twice', 'Never', 'NAP']\n",
      "  Non-null count: 45762\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "HH_TIRED\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002 (categorical): ['Several times a week', 'Several times a month', 'Once or twice', 'Never', 'NAP']\n",
      "  Non-null count: 46638\n",
      "\n",
      "2012 (categorical): ['Several times a week', 'Several times a month', 'Once or twice', 'Never', 'NAP']\n",
      "  Non-null count: 61754\n",
      "\n",
      "2022 (categorical): ['Several times a week', 'Several times a month', 'Once or twice', 'Never', 'NAP']\n",
      "  Non-null count: 45762\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "WORK_TIRED\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002 (categorical): ['Several times a week', 'Several times a month', 'Once or twice', 'Never', 'NAP']\n",
      "  Non-null count: 46638\n",
      "\n",
      "2012 (categorical): ['Several times a week', 'Several times a month', 'Once or twice', 'Never', 'NAP']\n",
      "  Non-null count: 61754\n",
      "\n",
      "2022 (categorical): ['Several times a week', 'Several times a month', 'Once or twice', 'Never', 'NAP']\n",
      "  Non-null count: 45762\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "SHARE_HH\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002 (categorical): ['Much more than fair share', 'Bit more than fair share', 'Fair share', 'Bit less than fair share', 'Much less than fair share', 'NAP']\n",
      "  Non-null count: 46638\n",
      "\n",
      "2012 (categorical): ['Much more than fair share', 'Bit more than fair share', 'Fair share', 'Bit less than fair share', 'Much less than fair share', 'NAP']\n",
      "  Non-null count: 61754\n",
      "\n",
      "2022 (categorical): ['Much more than fair share', 'Bit more than fair share', 'Fair share', 'Bit less than fair share', 'Much less than fair share', 'NAP']\n",
      "  Non-null count: 45762\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "DIV_HH_COOK\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 46638\n",
      "\n",
      "2012 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 61754\n",
      "\n",
      "2022 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 45762\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "DIV_HH_CLEAN\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 46638\n",
      "\n",
      "2012 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 61754\n",
      "\n",
      "2022 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 45762\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "DIV_HH_GROC\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 46638\n",
      "\n",
      "2012 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 61754\n",
      "\n",
      "2022 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 45762\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "DIV_HH_CARE\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 46638\n",
      "\n",
      "2012 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 61754\n",
      "\n",
      "2022 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 45762\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "DIV_HH_LAUND\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 46638\n",
      "\n",
      "2012 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 61754\n",
      "\n",
      "2022 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 45762\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "HH_WEEKEND\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 46638\n",
      "\n",
      "2012 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 61754\n",
      "\n",
      "2022 (categorical): ['Always respondent', 'Usually respondent', 'About equal', 'Usually partner', 'Always partner', 'Third person', 'NAP']\n",
      "  Non-null count: 45762\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "LIFE_HAP\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002 (categorical): ['Completely happy', 'Very happy', 'Fairly happy', 'Neither happy nor unhappy', 'Fairly unhappy', 'Very unhappy', 'Completely unhappy']\n",
      "  Non-null count: 45800\n",
      "\n",
      "2012 (categorical): ['Completely happy', 'Very happy', 'Fairly happy', 'Neither happy nor unhappy', 'Fairly unhappy', 'Very unhappy', 'Completely unhappy']\n",
      "  Non-null count: 60844\n",
      "\n",
      "2022 (categorical): ['Completely happy', 'Very happy', 'Fairly happy', 'Neither happy nor unhappy', 'Fairly unhappy', 'Very unhappy', 'Completely unhappy']\n",
      "  Non-null count: 45018\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "COHAB\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: ['No partner', 'Partner, same household']\n",
      "  Non-null count: 19214\n",
      "\n",
      "2012: ['No partner', 'Partner, same household']\n",
      "  Non-null count: 56838\n",
      "\n",
      "2022: ['No partner', 'Partner, same household']\n",
      "  Non-null count: 45216\n",
      "\n",
      "Status:  CONSISTENT\n",
      "\n",
      "================================================================================\n",
      "C_ALPHAN\n",
      "================================================================================\n",
      "Available in years: [2002, 2012, 2022]\n",
      "\n",
      "2002: 33 unique values\n",
      "  Sample: ['AT', 'AU', 'BE', 'BG', 'BR']\n",
      "  Non-null count: 46638\n",
      "\n",
      "2012: 41 unique values\n",
      "  Sample: ['AR', 'AT', 'AU', 'BE', 'BG']\n",
      "  Non-null count: 61754\n",
      "\n",
      "2022: 32 unique values\n",
      "  Sample: ['AT', 'AU', 'BG', 'CH', 'CZ']\n",
      "  Non-null count: 45762\n",
      "\n",
      "Status:  CHECK NEEDED\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Total variables checked: 34\n",
      "Consistent: 30\n",
      "Need review: 4\n"
     ]
    }
   ],
   "source": [
    "# Verification: Check consistency of cleaned variables across years\n",
    "print(\"=\"*80)\n",
    "print(\"VERIFICATION OF DATA CONSISTENCY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Variables to verify (sample from each type)\n",
    "verify_vars = [\n",
    "    'TOPBOT', 'SPWRKHRS', 'SP_HH_FAM', 'SP_HH', 'HH_FAM',\n",
    "    'WWYKS', 'WWYKUS', 'SP_DEGREE', 'MOMORFAF',\n",
    "    'HHTODD', 'HHCHILDR', 'HHADULT', 'HOMPOP',\n",
    "    'LIVWOMAR', 'MEWH', 'HW_FULFIL', 'WO_WANT', \n",
    "    'WW_FAM_SUFFER', 'WW_CHILD_SUFFER', 'WW_WARM',\n",
    "    'FAM_DIF', 'DIFF_CONC_WORK', 'HH_TIRED', 'WORK_TIRED',\n",
    "    'SHARE_HH', 'DIV_HH_COOK', 'DIV_HH_CLEAN', 'DIV_HH_GROC',\n",
    "    'DIV_HH_CARE', 'DIV_HH_LAUND', 'HH_WEEKEND',\n",
    "    'LIFE_HAP', 'COHAB', 'C_ALPHAN'\n",
    "]\n",
    "\n",
    "dfs_dict = {\n",
    "    2002: df_2002_clean,\n",
    "    2012: df_2012_clean,\n",
    "    2022: df_2022_clean\n",
    "}\n",
    "\n",
    "consistency_report = []\n",
    "\n",
    "for var in verify_vars:\n",
    "    # Check if variable exists in at least one df\n",
    "    exists_in = [year for year, df in dfs_dict.items() if var in df.columns]\n",
    "    \n",
    "    if not exists_in:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{var}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Available in years: {exists_in}\")\n",
    "    \n",
    "    # Get unique values from each year\n",
    "    for year in [2002, 2012, 2022]:\n",
    "        df = dfs_dict[year]\n",
    "        if var in df.columns:\n",
    "            unique_vals = df[var].dropna().unique()\n",
    "            \n",
    "            # For categorical, show categories\n",
    "            if hasattr(df[var], 'cat'):\n",
    "                print(f\"\\n{year} (categorical): {df[var].cat.categories.tolist()}\")\n",
    "                print(f\"  Non-null count: {df[var].notna().sum()}\")\n",
    "            else:\n",
    "                # Show sample of unique values\n",
    "                if len(unique_vals) <= 10:\n",
    "                    print(f\"\\n{year}: {sorted(unique_vals)}\")\n",
    "                else:\n",
    "                    print(f\"\\n{year}: {len(unique_vals)} unique values\")\n",
    "                    print(f\"  Sample: {sorted(unique_vals)[:5]}\")\n",
    "                print(f\"  Non-null count: {df[var].notna().sum()}\")\n",
    "        else:\n",
    "            print(f\"\\n{year}: Not available\")\n",
    "    \n",
    "    # Check consistency\n",
    "    all_values = []\n",
    "    for year, df in dfs_dict.items():\n",
    "        if var in df.columns:\n",
    "            if hasattr(df[var], 'cat'):\n",
    "                all_values.extend(df[var].cat.categories.tolist())\n",
    "            else:\n",
    "                all_values.extend(df[var].dropna().unique().tolist())\n",
    "    \n",
    "    unique_across_years = len(set(str(v) for v in all_values))\n",
    "    \n",
    "    # Determine if consistent\n",
    "    is_consistent = True\n",
    "    if len(exists_in) > 1:\n",
    "        # Compare value types across years\n",
    "        value_sets = []\n",
    "        for year, df in dfs_dict.items():\n",
    "            if var in df.columns:\n",
    "                if hasattr(df[var], 'cat'):\n",
    "                    value_sets.append(set(df[var].cat.categories.tolist()))\n",
    "                else:\n",
    "                    vals = df[var].dropna().unique()\n",
    "                    value_sets.append(set(str(v) for v in vals))\n",
    "        \n",
    "        if len(value_sets) > 1:\n",
    "            # Check if there's significant overlap or if they're all numeric\n",
    "            if all(df[var].dtype in ['int64', 'float64'] for year, df in dfs_dict.items() if var in df.columns):\n",
    "                is_consistent = True  # Numeric variables are consistent\n",
    "            elif len(value_sets[0]) > 0:\n",
    "                # For categorical, check if categories are similar\n",
    "                all_cats = set()\n",
    "                for vs in value_sets:\n",
    "                    all_cats.update(vs)\n",
    "                # If all years share same categories, consistent\n",
    "                is_consistent = all(vs == value_sets[0] for vs in value_sets)\n",
    "    \n",
    "    status = \" CONSISTENT\" if is_consistent else \" CHECK NEEDED\"\n",
    "    print(f\"\\nStatus: {status}\")\n",
    "    consistency_report.append((var, status, exists_in))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "consistent_count = sum(1 for _, status, _ in consistency_report if \"CONSISTENT\" in status)\n",
    "print(f\"Total variables checked: {len(consistency_report)}\")\n",
    "print(f\"Consistent: {consistent_count}\")\n",
    "print(f\"Need review: {len(consistency_report) - consistent_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cdf0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
