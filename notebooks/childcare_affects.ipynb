{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47992120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "warnings.filterwarnings('ignore')\n",
    "# from reportlab.lib.pagesizes import A4, landscape\n",
    "# from reportlab.lib import colors\n",
    "# from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, PageBreak\n",
    "# from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "# from reportlab.lib.units import inch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb2620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002 = pd.read_csv('data/final_csv/2002.csv')\n",
    "df_2012 = pd.read_csv('data/final_csv/2012.csv')\n",
    "df_2022 = pd.read_csv('data/final_csv/2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1173637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002[\"HHCHILDR\"] = pd.to_numeric(df_2002[\"HHCHILDR\"], errors=\"coerce\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d77c0bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  1.,  3.,  4.,  5.,  6.,  8.,  7., 10.,  9.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2002[\"HHCHILDR\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11872919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'V5_egal', 'V6_egal', 'V7_egal', 'V8_egal', 'V9_egal',\n",
       "       'V11_egal', 'V5_egal_z', 'V6_egal_z', 'V7_egal_z', 'V8_egal_z',\n",
       "       'V9_egal_z', 'V11_egal_z', 'eg_score', 'sex', 'hh_wrk_hrs', 'wrk_hrs',\n",
       "       'country', 'age', 'age_bin', 'high_egal', 'low_housework',\n",
       "       'highest_education', 'educ_4', 'educ_4_label', 'code_income_control',\n",
       "       'code_higher_income', 'marital', 'work_status_std',\n",
       "       'spouse_work_status_std', 'work_status', 'spouse_work_status',\n",
       "       'urban_rural', 'eg_score_norm', 'TOPBOT', 'SPWRKHRS', 'C_ALPHAN',\n",
       "       'LIVWOMAR', 'WWYKS', 'WWYKUS', 'SP_DEGREE', 'MOMORFAF', 'MEWH',\n",
       "       'HHTODD', 'HHCHILDR', 'HHADULT', 'FAM_DIF', 'SHARE_HH', 'HW_FULFIL',\n",
       "       'WO_WANT', 'WW_FAM_SUFFER', 'WW_CHILD_SUFFER', 'WW_WARM', 'DIV_HH_COOK',\n",
       "       'DIV_HH_CLEAN', 'DIV_HH_GROC', 'DIV_HH_CARE', 'DIV_HH_LAUND',\n",
       "       'SP_HH_FAM', 'SP_HH', 'LIFE_HAP', 'DIFF_CONC_WORK', 'HH_TIRED',\n",
       "       'HH_FAM', 'WORK_TIRED', 'HH_WEEKEND', 'COHAB', 'HOMPOP', 'COUNTRY',\n",
       "       'CASEID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2012.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fe4b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(series):\n",
    "    \"\"\"\n",
    "    Normalize a numeric series to 0-1 range using min-max scaling.\n",
    "    \"\"\"\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "# Applying to eg_score columns\n",
    "df_2002['eg_score_norm'] = normalize_column(df_2002['eg_score'])\n",
    "df_2012['eg_score_norm'] = normalize_column(df_2012['eg_score'])\n",
    "df_2022['eg_score_norm'] = normalize_column(df_2022['eg_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65b1fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after merging: 154154\n",
      "\n",
      "Rows per year:\n",
      "year\n",
      "2002    46638\n",
      "2012    61754\n",
      "2022    45762\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataframe info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 154154 entries, 0 to 154153\n",
      "Data columns (total 89 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   Unnamed: 0              154154 non-null  int64  \n",
      " 1   v4_egal                 89226 non-null   float64\n",
      " 2   v5_egal                 88057 non-null   float64\n",
      " 3   v6_egal                 90165 non-null   float64\n",
      " 4   v7_egal                 44089 non-null   float64\n",
      " 5   v8_egal                 43720 non-null   float64\n",
      " 6   v11_egal                45475 non-null   float64\n",
      " 7   v4_egal_z               89226 non-null   float64\n",
      " 8   v5_egal_z               88057 non-null   float64\n",
      " 9   v6_egal_z               90165 non-null   float64\n",
      " 10  v7_egal_z               44089 non-null   float64\n",
      " 11  v8_egal_z               43720 non-null   float64\n",
      " 12  v11_egal_z              45475 non-null   float64\n",
      " 13  eg_score                150803 non-null  float64\n",
      " 14  sex                     153982 non-null  object \n",
      " 15  hh_wrk_hrs              133333 non-null  float64\n",
      " 16  wrk_hrs                 84019 non-null   float64\n",
      " 17  country                 154154 non-null  object \n",
      " 18  age                     153797 non-null  float64\n",
      " 19  age_bin                 153795 non-null  object \n",
      " 20  high_egal               154154 non-null  bool   \n",
      " 21  low_housework           154154 non-null  bool   \n",
      " 22  highest_education       153634 non-null  object \n",
      " 23  educ_4                  152109 non-null  float64\n",
      " 24  educ_4_label            152109 non-null  object \n",
      " 25  code_income_control     94590 non-null   object \n",
      " 26  code_higher_income      52628 non-null   object \n",
      " 27  marital                 152285 non-null  object \n",
      " 28  work_status_std         154154 non-null  object \n",
      " 29  spouse_work_status_std  154154 non-null  object \n",
      " 30  work_status             154154 non-null  object \n",
      " 31  spouse_work_status      154154 non-null  object \n",
      " 32  urban_rural             146105 non-null  object \n",
      " 33  eg_score_norm           150803 non-null  float64\n",
      " 34  TOPBOT                  125726 non-null  float64\n",
      " 35  SPWRKHRS                57455 non-null   float64\n",
      " 36  C_ALPHAN                154154 non-null  object \n",
      " 37  LIVWOMAR                147992 non-null  object \n",
      " 38  WWYKS                   139920 non-null  object \n",
      " 39  WWYKUS                  139613 non-null  object \n",
      " 40  SP_DEGREE               81801 non-null   object \n",
      " 41  MOMORFAF                88349 non-null   object \n",
      " 42  MEWH                    148598 non-null  object \n",
      " 43  HHTODD                  107867 non-null  float64\n",
      " 44  HHCHILDR                149099 non-null  float64\n",
      " 45  HHADULT                 86825 non-null   float64\n",
      " 46  FAM_DIF                 154154 non-null  object \n",
      " 47  SHARE_HH                154154 non-null  object \n",
      " 48  HW_FULFIL               142361 non-null  object \n",
      " 49  WO_WANT                 144210 non-null  object \n",
      " 50  WW_FAM_SUFFER           147535 non-null  object \n",
      " 51  WW_CHILD_SUFFER         147205 non-null  object \n",
      " 52  WW_WARM                 148352 non-null  object \n",
      " 53  DIV_HH_COOK             154154 non-null  object \n",
      " 54  DIV_HH_CLEAN            154154 non-null  object \n",
      " 55  DIV_HH_GROC             154154 non-null  object \n",
      " 56  DIV_HH_CARE             154154 non-null  object \n",
      " 57  DIV_HH_LAUND            154154 non-null  object \n",
      " 58  SP_HH_FAM               61272 non-null   float64\n",
      " 59  SP_HH                   91372 non-null   float64\n",
      " 60  LIFE_HAP                151662 non-null  object \n",
      " 61  DIFF_CONC_WORK          154154 non-null  object \n",
      " 62  HH_TIRED                154154 non-null  object \n",
      " 63  HH_FAM                  99028 non-null   float64\n",
      " 64  WORK_TIRED              154154 non-null  object \n",
      " 65  HH_WEEKEND              154154 non-null  object \n",
      " 66  COHAB                   121268 non-null  object \n",
      " 67  HOMPOP                  150028 non-null  float64\n",
      " 68  COUNTRY                 154154 non-null  object \n",
      " 69  CASEID                  154154 non-null  float64\n",
      " 70  year                    154154 non-null  int64  \n",
      " 71  V5_egal                 57860 non-null   float64\n",
      " 72  V6_egal                 57551 non-null   float64\n",
      " 73  V7_egal                 57631 non-null   float64\n",
      " 74  V8_egal                 56379 non-null   float64\n",
      " 75  V9_egal                 55612 non-null   float64\n",
      " 76  V11_egal                58078 non-null   float64\n",
      " 77  V5_egal_z               57860 non-null   float64\n",
      " 78  V6_egal_z               57551 non-null   float64\n",
      " 79  V7_egal_z               57631 non-null   float64\n",
      " 80  V8_egal_z               56379 non-null   float64\n",
      " 81  V9_egal_z               55612 non-null   float64\n",
      " 82  V11_egal_z              58078 non-null   float64\n",
      " 83  v1_egal                 45008 non-null   float64\n",
      " 84  v2_egal                 44626 non-null   float64\n",
      " 85  v3_egal                 44784 non-null   float64\n",
      " 86  v1_egal_z               45008 non-null   float64\n",
      " 87  v2_egal_z               44626 non-null   float64\n",
      " 88  v3_egal_z               44784 non-null   float64\n",
      "dtypes: bool(2), float64(46), int64(2), object(39)\n",
      "memory usage: 102.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_2002 = df_2002.copy()\n",
    "df_2012 = df_2012.copy()\n",
    "df_2022 = df_2022.copy()\n",
    "\n",
    "# Adding a 'year' column to see from which year each row comes\n",
    "df_2002['year'] = 2002\n",
    "df_2012['year'] = 2012\n",
    "df_2022['year'] = 2022\n",
    "\n",
    "# Combining all three datasets\n",
    "combined_df = pd.concat([df_2002, df_2012, df_2022], ignore_index=True)\n",
    "\n",
    "\n",
    "combined_df = combined_df.drop_duplicates(subset=combined_df.columns.difference(['year']))\n",
    "\n",
    "print(f\"Total rows after merging: {len(combined_df)}\")\n",
    "print(f\"\\nRows per year:\")\n",
    "print(combined_df['year'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nDataframe info:\")\n",
    "print(combined_df.info())\n",
    "os.makedirs('./data/extras', exist_ok=True)\n",
    "combined_df.to_csv('./data/extras/combined_dataset_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e913d6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>v4_egal</th>\n",
       "      <th>v5_egal</th>\n",
       "      <th>v6_egal</th>\n",
       "      <th>v7_egal</th>\n",
       "      <th>v8_egal</th>\n",
       "      <th>v11_egal</th>\n",
       "      <th>v4_egal_z</th>\n",
       "      <th>v5_egal_z</th>\n",
       "      <th>v6_egal_z</th>\n",
       "      <th>...</th>\n",
       "      <th>V7_egal_z</th>\n",
       "      <th>V8_egal_z</th>\n",
       "      <th>V9_egal_z</th>\n",
       "      <th>V11_egal_z</th>\n",
       "      <th>v1_egal</th>\n",
       "      <th>v2_egal</th>\n",
       "      <th>v3_egal</th>\n",
       "      <th>v1_egal_z</th>\n",
       "      <th>v2_egal_z</th>\n",
       "      <th>v3_egal_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.357029</td>\n",
       "      <td>-0.614036</td>\n",
       "      <td>-0.676980</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.105198</td>\n",
       "      <td>1.788120</td>\n",
       "      <td>1.680397</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.284456</td>\n",
       "      <td>0.186683</td>\n",
       "      <td>-0.676980</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.357029</td>\n",
       "      <td>-0.614036</td>\n",
       "      <td>-1.462772</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.536287</td>\n",
       "      <td>-0.614036</td>\n",
       "      <td>-0.676980</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  v4_egal  v5_egal  v6_egal  v7_egal  v8_egal  v11_egal  \\\n",
       "0           0      2.0      2.0      2.0      3.0      3.0       3.0   \n",
       "1           1      5.0      5.0      5.0      5.0      1.0       5.0   \n",
       "2           2      4.0      3.0      2.0      3.0      2.0       4.0   \n",
       "3           3      2.0      2.0      1.0      4.0      4.0       4.0   \n",
       "4           4      3.0      2.0      2.0      3.0      2.0       3.0   \n",
       "\n",
       "   v4_egal_z  v5_egal_z  v6_egal_z  ...  V7_egal_z  V8_egal_z  V9_egal_z  \\\n",
       "0  -1.357029  -0.614036  -0.676980  ...        NaN        NaN        NaN   \n",
       "1   1.105198   1.788120   1.680397  ...        NaN        NaN        NaN   \n",
       "2   0.284456   0.186683  -0.676980  ...        NaN        NaN        NaN   \n",
       "3  -1.357029  -0.614036  -1.462772  ...        NaN        NaN        NaN   \n",
       "4  -0.536287  -0.614036  -0.676980  ...        NaN        NaN        NaN   \n",
       "\n",
       "   V11_egal_z v1_egal  v2_egal  v3_egal v1_egal_z  v2_egal_z v3_egal_z  \n",
       "0         NaN     NaN      NaN      NaN       NaN        NaN       NaN  \n",
       "1         NaN     NaN      NaN      NaN       NaN        NaN       NaN  \n",
       "2         NaN     NaN      NaN      NaN       NaN        NaN       NaN  \n",
       "3         NaN     NaN      NaN      NaN       NaN        NaN       NaN  \n",
       "4         NaN     NaN      NaN      NaN       NaN        NaN       NaN  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aebb425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neither agree nor disagree', 'Strongly disagree', 'Disagree',\n",
       "       'Agree', 'Strongly agree', nan], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['WO_WANT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1742165",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = combined_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa27bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  1.,  3.,  4.,  5.,  6.,  8.,  7., 10.,  9., nan, 21.,\n",
       "       18., 12., 15., 14., 11.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis['HHCHILDR'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0a2ce1",
   "metadata": {},
   "source": [
    "MAPPING OF ALL CATEGORICAL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b3985ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_map = {\n",
    "    'Strongly disagree': 1,\n",
    "    'Disagree': 2,\n",
    "    'Neither agree nor disagree': 3,\n",
    "    'Agree': 4,\n",
    "    'Strongly agree': 5\n",
    "}\n",
    "\n",
    "\n",
    "employment_mapping = {\n",
    "    'Paid work': 'Employed',\n",
    "    'Apprentice/Trainee': 'Employed',\n",
    "    'Education': 'Employed',\n",
    "    'Military/Community service': 'Employed',\n",
    "    'Unemployed': 'Unemployed',\n",
    "    'Retired': 'Unemployed',\n",
    "    'Domestic work': 'Unemployed',\n",
    "    'Sick/Disabled': 'Unemployed',\n",
    "    'Other': 'Unemployed',\n",
    "    'DK/No answer': 'Unemployed'\n",
    "}\n",
    "\n",
    "\n",
    "spouse_employment_map = {\n",
    "    \"Paid work\": \"Employed\",\n",
    "    \"Apprentice/Trainee\": \"Employed\",\n",
    "    \"Education\": \"Employed\",\n",
    "    \"Unemployed\": \"Unemployed\",\n",
    "    \"Domestic work\": \"Unemployed\",\n",
    "    \"Retired\": \"Unemployed\",\n",
    "    \"Sick/Disabled\": \"Unemployed\",\n",
    "    \"Help family member\": \"Unemployed\",\n",
    "    \"Military/Community service\": \"Unemployed\",\n",
    "    \"Other\": \"Unemployed\",\n",
    "    \"DK/No answer\": \"Unemployed\",\n",
    "    \"NAP\": \"Unemployed\"\n",
    "}\n",
    "\n",
    "\n",
    "momorfaf_mapping = {\n",
    "    'Fathers much better': -2,\n",
    "    'Fathers somewhat better': -1,\n",
    "    'Equally suited': 0,\n",
    "    'Mothers somewhat better': 1,\n",
    "    'Mothers much better': 2\n",
    "}\n",
    "\n",
    "work_status_mapping = {\n",
    "'Paid work': 1,\n",
    "    'Apprentice/Trainee': 1,\n",
    "    'Education': 1,\n",
    "    'Military/Community service': 1,\n",
    "    'Unemployed': 0,\n",
    "    'Retired': 0,\n",
    "    'Domestic work': 0,\n",
    "    'Sick/Disabled': 0,\n",
    "    'Other': 0,\n",
    "    'DK/No answer': 0\n",
    "}\n",
    "\n",
    "spouse_work_status_mapping = {\n",
    "    'Paid work': 1,\n",
    "    'Apprentice/Trainee': 1,\n",
    "    'Education': 1,\n",
    "    'Military/Community service': 1,\n",
    "    'Retired': 0,\n",
    "    'Domestic work': 0,\n",
    "    'Unemployed': 0,\n",
    "    'Sick/Disabled': 0,\n",
    "    'Help family member': 0,\n",
    "    'Other': 0,\n",
    "    'DK/No answer': 0,\n",
    "    'NAP': 0  \n",
    "}\n",
    "\n",
    "div_hh_care_mapping = {\n",
    "    'Always partner': -2,\n",
    "    'Usually partner': -1,\n",
    "    'About equal': 0,\n",
    "    'Usually respondent': 1,\n",
    "    'Always respondent': 2,\n",
    "    'Third person': None,  \n",
    "    'NAP': None\n",
    "}\n",
    "\n",
    "sex_mapping = {\n",
    "    'Male' : 0,\n",
    "    'Female' : 1\n",
    "}\n",
    "\n",
    "edu_map = {\n",
    "    \"No/Primary\": 1,\n",
    "    \"Secondary\": 2,\n",
    "    \"Post-sec / Short tertiary\": 3,\n",
    "    \"University+\": 4\n",
    "}\n",
    "\n",
    "warm_opinion_map = {\n",
    "    'Strongly disagree': 5,\n",
    "    'Disagree': 4,\n",
    "    'Neither agree nor disagree': 3,\n",
    "    'Agree': 2,\n",
    "    'Strongly agree': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d624460",
   "metadata": {},
   "source": [
    "Mapping all the ordinal/binary values to the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1919c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['WW_CHILD_SUFFER'] = df_analysis['WW_CHILD_SUFFER'].map(opinion_map)\n",
    "df_analysis['WW_FAM_SUFFER'] = df_analysis['WW_FAM_SUFFER'].map(opinion_map)\n",
    "df_analysis['WO_WANT'] = df_analysis['WO_WANT'].map(opinion_map)\n",
    "df_analysis['HW_FULFIL'] = df_analysis['HW_FULFIL'].map(opinion_map)\n",
    "df_analysis['MEWH'] = df_analysis['MEWH'].map(opinion_map)\n",
    "df_analysis['MEWH'] = df_analysis['MEWH'].map(opinion_map)\n",
    "df_analysis['WW_WARM'] = df_analysis['WW_WARM'].map(warm_opinion_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7ec3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['MOMORFAF'] = df_analysis['MOMORFAF'].map(momorfaf_mapping)\n",
    "df_analysis['DIV_HH_CARE'] = df_analysis['DIV_HH_CARE'].map(div_hh_care_mapping)\n",
    "df_analysis['sex'] = df_analysis['sex'].map(sex_mapping)\n",
    "df_analysis['work_status_std'] = df_analysis['work_status_std'].map(work_status_mapping)\n",
    "df_analysis['spouse_work_status_std'] = df_analysis['spouse_work_status_std'].map(spouse_work_status_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ca2f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['educ_4_encoded'] = df_analysis['educ_4_label'].map(edu_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a98cc2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total respondents: 154154\n",
      "Males: 70134, Females: 83776\n"
     ]
    }
   ],
   "source": [
    "# Dependent variables\n",
    "PILLARS = ['WW_WARM', 'WW_CHILD_SUFFER', 'WW_FAM_SUFFER', 'WO_WANT', 'HW_FULFIL', 'MEWH']\n",
    "ALL_OUTCOMES = ['eg_score_norm'] + PILLARS\n",
    "# Controls (for testing both the hypotheses)\n",
    "CONTROLS = ['age', 'work_status_std', 'spouse_work_status_std', 'educ_4_encoded']\n",
    "# This variable is the centered year variable\n",
    "df_analysis['year_c'] = df_analysis['year'] - 2002\n",
    "# Splitting by gender\n",
    "df_male = df_analysis[df_analysis['sex'] == 0].copy()\n",
    "df_female = df_analysis[df_analysis['sex'] == 1].copy()\n",
    "print(f\"Total respondents: {len(df_analysis)}\")\n",
    "print(f\"Males: {len(df_male)}, Females: {len(df_female)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e87db5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are calculating sample mean of each control variable per year\n",
    "def get_sample_means(df, controls, years=[0, 10, 20]):\n",
    "    means = {}\n",
    "    for y in years:\n",
    "        subset = df[df['year_c'] == y]\n",
    "        means[y] = {ctrl: subset[ctrl].mean() for ctrl in controls}\n",
    "    return means\n",
    "# OLS Regression\n",
    "def run_regression(df, outcome, focus_var, controls, interaction=True):\n",
    "    ctrl_str = ' + '.join(controls)\n",
    "    if interaction:\n",
    "        formula = f\"{outcome} ~ {focus_var} + year_c + {focus_var}:year_c + {ctrl_str}\"\n",
    "    else:\n",
    "        formula = f\"{outcome} ~ {focus_var} + year_c + {ctrl_str}\"\n",
    "    vars_in_model = [outcome, focus_var, 'year_c'] + controls\n",
    "    df_clean = df[vars_in_model].dropna()\n",
    "    model = smf.ols(formula, data=df_clean).fit(cov_type='HC1')\n",
    "    return model\n",
    "\n",
    "# function for prediction\n",
    "def predict_scores(model, focus_var, focus_values, sample_means, controls):\n",
    "    predictions = []\n",
    "    for year_c in [0, 10, 20]:  \n",
    "        for val in focus_values:\n",
    "            row = {\n",
    "                focus_var: val,\n",
    "                'year_c': year_c\n",
    "            }\n",
    "            for ctrl in controls:\n",
    "                row[ctrl] = sample_means[year_c][ctrl]\n",
    "            \n",
    "            pred = model.predict(pd.DataFrame([row]))[0]\n",
    "            predictions.append({\n",
    "                'Year': 2002 + year_c,\n",
    "                focus_var: val,\n",
    "                'Predicted_Score': round(pred, 4)\n",
    "            })\n",
    "    return pd.DataFrame(predictions)\n",
    "def extract_results(model, focus_var):\n",
    "    results = {}\n",
    "    # Key terms to extract\n",
    "    terms = [focus_var, 'year_c', f'{focus_var}:year_c']\n",
    "    for term in terms:\n",
    "        if term in model.params.index:\n",
    "            coef = model.params[term]\n",
    "            pval = model.pvalues[term]\n",
    "            ci = model.conf_int().loc[term]\n",
    "            \n",
    "            results[term] = {\n",
    "                'Coefficient': round(coef, 4),\n",
    "                'p_value': pval,\n",
    "                'CI_lower': round(ci[0], 4),\n",
    "                'CI_upper': round(ci[1], 4),\n",
    "            }\n",
    "    results['R_squared'] = round(model.rsquared, 4)\n",
    "    results['N'] = int(model.nobs)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52f99115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[0 1]\n",
      "[ 3.  4.  2.  1. nan]\n"
     ]
    }
   ],
   "source": [
    "print(df_analysis['work_status_std'].unique())\n",
    "print(df_analysis['spouse_work_status_std'].unique())\n",
    "print(df_analysis['educ_4_encoded'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac68fcd",
   "metadata": {},
   "source": [
    "MAIN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e17a18a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total respondents: 154,154\n",
      "Males: 70,134, Females: 83,776\n"
     ]
    }
   ],
   "source": [
    "# Dependent variables\n",
    "PILLARS = ['WW_WARM', 'WW_CHILD_SUFFER', 'WW_FAM_SUFFER', 'WO_WANT', 'HW_FULFIL', 'MEWH']\n",
    "ALL_OUTCOMES = ['eg_score_norm'] + PILLARS\n",
    "# Controls that will be used in the regression models\n",
    "CONTROLS = ['age', 'work_status_std', 'spouse_work_status_std', 'educ_4_encoded']\n",
    "# Sex mapping\n",
    "SEX_FEMALE = 1\n",
    "SEX_MALE   = 0\n",
    "# # This variable is the centered year variable\n",
    "df_analysis['year'] = pd.to_numeric(df_analysis['year'], errors='coerce')\n",
    "df_analysis['year_c'] = df_analysis['year'] - 2002\n",
    "df_analysis['kids_cat'] = pd.to_numeric(df_analysis['HHCHILDR'], errors='coerce').clip(upper=3)\n",
    "# Splitting by gender\n",
    "df_male   = df_analysis[df_analysis['sex'] == SEX_MALE].copy()\n",
    "df_female = df_analysis[df_analysis['sex'] == SEX_FEMALE].copy()\n",
    "print(f\"Total respondents: {len(df_analysis):,}\")\n",
    "print(f\"Males: {len(df_male):,}, Females: {len(df_female):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37c05a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns mode for categorical or mean for continuous data.\n",
    "def _mode_or_mean(series: pd.Series, treat_as_categorical: bool):\n",
    "    s = series.dropna()\n",
    "    if s.empty:\n",
    "        return np.nan\n",
    "    if treat_as_categorical:\n",
    "        m = s.mode()\n",
    "        return m.iloc[0] if not m.empty else s.iloc[0]\n",
    "    return s.mean()\n",
    "\n",
    "def get_control_values_by_year(df, controls, years=(0, 10, 20), continuous_controls=('age', 'educ_4_encoded')):\n",
    "    out = {}\n",
    "    for y in years:\n",
    "        subset = df[df['year_c'] == y]\n",
    "        out[y] = {}\n",
    "        for ctrl in controls:\n",
    "            treat_as_cat = (ctrl not in continuous_controls)\n",
    "            out[y][ctrl] = _mode_or_mean(subset[ctrl], treat_as_cat)\n",
    "    return out\n",
    "\n",
    "def run_regression(df, outcome, focus_var, controls, interaction=True):\n",
    "    ctrl_str = ' + '.join(controls)\n",
    "    if interaction:\n",
    "        formula = f\"{outcome} ~ {focus_var} + year_c + {focus_var}:year_c + {ctrl_str}\"\n",
    "    else:\n",
    "        formula = f\"{outcome} ~ {focus_var} + year_c + {ctrl_str}\"\n",
    "\n",
    "    vars_in_model = [outcome, focus_var, 'year_c', 'year'] + controls\n",
    "    df_clean = df[vars_in_model].dropna()\n",
    "\n",
    "    if df_clean['year'].nunique() >= 2:\n",
    "        model = smf.ols(formula, data=df_clean).fit(\n",
    "            cov_type='cluster',\n",
    "            cov_kwds={'groups': df_clean['year']}\n",
    "        )\n",
    "    else:\n",
    "        model = smf.ols(formula, data=df_clean).fit(cov_type='HC1')\n",
    "\n",
    "    return model, df_clean\n",
    "\n",
    "def predict_scores(model, focus_var, focus_values, control_values_by_year, controls, years=(0,10,20)):\n",
    "    preds = []\n",
    "    for year_c in years:\n",
    "        for val in focus_values:\n",
    "            row = {focus_var: val, 'year_c': year_c}\n",
    "            for ctrl in controls:\n",
    "                row[ctrl] = control_values_by_year[year_c][ctrl]\n",
    "\n",
    "            pred = float(model.predict(pd.DataFrame([row]))[0])\n",
    "            preds.append({\n",
    "                'Year': int(2002 + year_c),\n",
    "                focus_var: val,\n",
    "                'Predicted_Score': round(pred, 4)\n",
    "            })\n",
    "    return pd.DataFrame(preds)\n",
    "\n",
    "def extract_results(model, focus_var):\n",
    "    results = {}\n",
    "    terms = [focus_var, 'year_c', f'{focus_var}:year_c']\n",
    "    for term in terms:\n",
    "        if term in model.params.index:\n",
    "            coef = float(model.params[term])\n",
    "            pval = float(model.pvalues[term])\n",
    "            ci = model.conf_int().loc[term]\n",
    "            if pval < 0.001:\n",
    "                stars = '***'\n",
    "            elif pval < 0.01:\n",
    "                stars = '**'\n",
    "            elif pval < 0.05:\n",
    "                stars = '*'\n",
    "            else:\n",
    "                stars = ''\n",
    "            results[term] = {\n",
    "                'Coefficient': round(coef, 4),\n",
    "                'p_value': pval,\n",
    "                'CI_lower': round(float(ci[0]), 4),\n",
    "                'CI_upper': round(float(ci[1]), 4),\n",
    "                'stars': stars,\n",
    "                'display': f\"{round(coef, 4)}{stars}\"\n",
    "            }\n",
    "    results['R_squared'] = round(float(model.rsquared), 4)\n",
    "    results['N'] = int(model.nobs)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0649818c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTROLS: ['age', 'work_status_std', 'spouse_work_status_std', 'educ_4_encoded']\n",
      "\n",
      "df_male columns: ['Unnamed: 0', 'v4_egal', 'v5_egal', 'v6_egal', 'v7_egal', 'v8_egal', 'v11_egal', 'v4_egal_z', 'v5_egal_z', 'v6_egal_z', 'v7_egal_z', 'v8_egal_z', 'v11_egal_z', 'eg_score', 'sex', 'hh_wrk_hrs', 'wrk_hrs', 'country', 'age', 'age_bin', 'high_egal', 'low_housework', 'highest_education', 'educ_4', 'educ_4_label', 'code_income_control', 'code_higher_income', 'marital', 'work_status_std', 'spouse_work_status_std', 'work_status', 'spouse_work_status', 'urban_rural', 'eg_score_norm', 'TOPBOT', 'SPWRKHRS', 'C_ALPHAN', 'LIVWOMAR', 'WWYKS', 'WWYKUS', 'SP_DEGREE', 'MOMORFAF', 'MEWH', 'HHTODD', 'HHCHILDR', 'HHADULT', 'FAM_DIF', 'SHARE_HH', 'HW_FULFIL', 'WO_WANT', 'WW_FAM_SUFFER', 'WW_CHILD_SUFFER', 'WW_WARM', 'DIV_HH_COOK', 'DIV_HH_CLEAN', 'DIV_HH_GROC', 'DIV_HH_CARE', 'DIV_HH_LAUND', 'SP_HH_FAM', 'SP_HH', 'LIFE_HAP', 'DIFF_CONC_WORK', 'HH_TIRED', 'HH_FAM', 'WORK_TIRED', 'HH_WEEKEND', 'COHAB', 'HOMPOP', 'COUNTRY', 'CASEID', 'year', 'V5_egal', 'V6_egal', 'V7_egal', 'V8_egal', 'V9_egal', 'V11_egal', 'V5_egal_z', 'V6_egal_z', 'V7_egal_z', 'V8_egal_z', 'V9_egal_z', 'V11_egal_z', 'v1_egal', 'v2_egal', 'v3_egal', 'v1_egal_z', 'v2_egal_z', 'v3_egal_z', 'educ_4_encoded', 'year_c', 'kids_cat']\n",
      "\n",
      "NaN counts:\n",
      " kids_cat                  2307\n",
      "age                        113\n",
      "work_status_std              0\n",
      "spouse_work_status_std       0\n",
      "educ_4_encoded             850\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"CONTROLS:\", CONTROLS)\n",
    "print(\"\\ndf_male columns:\", df_male.columns.tolist())\n",
    "print(\"\\nNaN counts:\\n\", df_male[['kids_cat'] + list(CONTROLS)].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f2dee",
   "metadata": {},
   "source": [
    "HYPOTHESIS TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78a02421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hypothesis(results, focus_var, hypothesis_type, outcome):\n",
    "    STANDARD_SCALE = ['eg_score_norm', 'WW_WARM']\n",
    "    is_standard = outcome in STANDARD_SCALE\n",
    "    interaction_key = f\"{focus_var}:year_c\"\n",
    "    main_coef = results[focus_var]['Coefficient']\n",
    "    main_pval = results[focus_var]['p_value']\n",
    "    int_coef  = results[interaction_key]['Coefficient']\n",
    "    int_pval  = results[interaction_key]['p_value']\n",
    "    if hypothesis_type == 'H1':\n",
    "        if is_standard:\n",
    "            main_supported = (main_coef < 0) and (main_pval < 0.05)\n",
    "            int_supported  = (int_coef  > 0) and (int_pval  < 0.05)\n",
    "        else:\n",
    "            main_supported = (main_coef > 0) and (main_pval < 0.05)\n",
    "            int_supported  = (int_coef  < 0) and (int_pval  < 0.05)\n",
    "    else:  # Hypothesis 2\n",
    "        if is_standard:\n",
    "            main_supported = (main_coef > 0) and (main_pval < 0.05)\n",
    "            int_supported  = (int_coef  > 0) and (int_pval  < 0.05)\n",
    "        else:\n",
    "            main_supported = (main_coef < 0) and (main_pval < 0.05)\n",
    "            int_supported  = (int_coef  < 0) and (int_pval  < 0.05)\n",
    "    overall = (\n",
    "        \"Supported\" if (main_supported and int_supported) else\n",
    "        \"Partially Supported\" if (main_supported or int_supported) else\n",
    "        \"Not Supported\"\n",
    "    )\n",
    "    return {\n",
    "        'main_supported': main_supported,\n",
    "        'int_supported': int_supported,\n",
    "        'overall': overall,\n",
    "        'main_coef': main_coef,\n",
    "        'main_pval': main_pval,\n",
    "        'int_coef': int_coef,\n",
    "        'int_pval': int_pval\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b0abb7",
   "metadata": {},
   "source": [
    "SPEARMAN CORRELATION FOR CHECKING THE EFFECT OF NO. OF KIDS IN THE FAMILY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "738c682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlations | Female (sex=0) | kids = HHCHILDR\n",
      "        Outcome     N    rho   p_value\n",
      "  WW_FAM_SUFFER 64744 0.0343 2.547e-18\n",
      "WW_CHILD_SUFFER 64498 0.0228 7.324e-09\n",
      "        WW_WARM 64942 0.0018    0.6392\n",
      "Spearman correlations | Male (sex=1) | kids = HHCHILDR\n",
      "        Outcome     N    rho   p_value\n",
      "  WW_FAM_SUFFER 77856 0.0531 1.059e-49\n",
      "WW_CHILD_SUFFER 77775 0.0335 1.038e-20\n",
      "        WW_WARM 78418 0.0070   0.04888\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "SEX_COL = \"sex\"         \n",
    "KIDS_COL = \"HHCHILDR\"\n",
    "OUTCOMES = [\"WW_FAM_SUFFER\", \"WW_CHILD_SUFFER\", \"WW_WARM\"]\n",
    "USE_TOPCODED_KIDS = False\n",
    "\n",
    "df = df_analysis.copy()\n",
    "\n",
    "if USE_TOPCODED_KIDS:\n",
    "    df[\"kids_cat\"] = pd.to_numeric(df[KIDS_COL], errors=\"coerce\").clip(upper=3)\n",
    "    kids_var = \"kids_cat\"\n",
    "else:\n",
    "    df[KIDS_COL] = pd.to_numeric(df[KIDS_COL], errors=\"coerce\")\n",
    "    kids_var = KIDS_COL\n",
    "\n",
    "\n",
    "# speaman correlation table\n",
    "def spearman_table(df_sub, kids_var, outcomes):\n",
    "    rows = []\n",
    "    for y in outcomes:\n",
    "        tmp = df_sub[[kids_var, y]].dropna()\n",
    "        if len(tmp) < 10:\n",
    "            rows.append({\"Outcome\": y, \"N\": len(tmp), \"rho\": None, \"p_value\": None})\n",
    "            continue\n",
    "        rho, p = spearmanr(tmp[kids_var], tmp[y])\n",
    "        rows.append({\"Outcome\": y, \"N\": len(tmp), \"rho\": rho, \"p_value\": p})\n",
    "    return pd.DataFrame(rows)\n",
    "results = {}\n",
    "\n",
    "for sex_value, label in [(0, \"Female\"), (1, \"Male\")]:\n",
    "    df_sub = df[df[SEX_COL] == sex_value].copy()\n",
    "    print(f\"Spearman correlations | {label} (sex={sex_value}) | kids = {kids_var}\")\n",
    "    tab = spearman_table(df_sub, kids_var, OUTCOMES)\n",
    "    tab[\"rho\"] = tab[\"rho\"].round(4)\n",
    "    tab[\"p_value\"] = tab[\"p_value\"].apply(lambda x: f\"{x:.4g}\" if pd.notnull(x) else None)\n",
    "    print(tab.to_string(index=False))\n",
    "    results[sex_value] = tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cb5ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_analysis.copy()\n",
    "df[\"HHCHILDR\"] = pd.to_numeric(df[\"HHCHILDR\"], errors=\"coerce\")\n",
    "df[\"HHTODD\"]   = pd.to_numeric(df[\"HHTODD\"], errors=\"coerce\")\n",
    "df[[\"HHCHILDR\", \"HHTODD\"]] = df[[\"HHCHILDR\", \"HHTODD\"]].fillna(0)\n",
    "df[\"TOTAL_KIDS\"] = df[\"HHCHILDR\"] + df[\"HHTODD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3c124a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlations | Female | TOTAL_KIDS\n",
      "        Outcome     N    rho   p_value\n",
      "  WW_FAM_SUFFER 66927 0.0377 1.894e-22\n",
      "WW_CHILD_SUFFER 66686 0.0193 5.944e-07\n",
      "        WW_WARM 67157 0.0037    0.3313\n",
      "Spearman correlations | Male | TOTAL_KIDS\n",
      "        Outcome     N    rho   p_value\n",
      "  WW_FAM_SUFFER 80383 0.0673 1.904e-81\n",
      "WW_CHILD_SUFFER 80293 0.0381 3.272e-27\n",
      "        WW_WARM 80965 0.0187 1.056e-07\n"
     ]
    }
   ],
   "source": [
    "SEX_COL = \"sex\"\n",
    "KIDS_COL = \"TOTAL_KIDS\"\n",
    "\n",
    "OUTCOMES = [\"WW_FAM_SUFFER\", \"WW_CHILD_SUFFER\", \"WW_WARM\"]\n",
    "\n",
    "def spearman_table(df_sub, kids_var, outcomes):\n",
    "    rows = []\n",
    "    for y in outcomes:\n",
    "        tmp = df_sub[[kids_var, y]].dropna()\n",
    "        if len(tmp) < 10:\n",
    "            rows.append({\"Outcome\": y, \"N\": len(tmp), \"rho\": None, \"p_value\": None})\n",
    "            continue\n",
    "        rho, p = spearmanr(tmp[kids_var], tmp[y])\n",
    "        rows.append({\n",
    "            \"Outcome\": y,\n",
    "            \"N\": len(tmp),\n",
    "            \"rho\": round(rho, 4),\n",
    "            \"p_value\": f\"{p:.4g}\"\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Separate matrices based on gender\n",
    "for sex_value, label in [(0, \"Female\"), (1, \"Male\")]:\n",
    "    df_sub = df[df[SEX_COL] == sex_value].copy()\n",
    "    print(f\"Spearman correlations | {label} | TOTAL_KIDS\")\n",
    "    res = spearman_table(df_sub, KIDS_COL, OUTCOMES)\n",
    "    print(res.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-lit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
